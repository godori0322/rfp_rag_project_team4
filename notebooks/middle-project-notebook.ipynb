{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf easyocr opencv-python pillow # easy ocr\n",
        "!pip install pymupdf4llm\n",
        "!pip install pyhwp beautifulsoup4\n",
        "!pip install langchain_community langchain_google_genai langchain_openai faiss-cpu\n",
        "\n",
        "# llamaindex\n",
        "!pip install llama-index llama-index-vector-stores-faiss llama-index-embeddings-huggingface llama-index-embeddings-openai llama-index-llms-gemini llama-index-llms-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MaHL93Id3w5J",
        "outputId": "a45730e4-0337-450e-900b-ae16fbec05c9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T07:06:15.957108Z",
          "iopub.execute_input": "2025-09-16T07:06:15.957800Z",
          "iopub.status.idle": "2025-09-16T07:06:16.169408Z",
          "shell.execute_reply.started": "2025-09-16T07:06:15.957758Z",
          "shell.execute_reply": "2025-09-16T07:06:16.168107Z"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (10.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.23.0+cu126)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from easyocr) (4.12.0.88)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.16.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.6.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.1.1)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.4.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2025.8.28)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Requirement already satisfied: pymupdf4llm in /usr/local/lib/python3.12/dist-packages (0.0.27)\n",
            "Requirement already satisfied: pymupdf>=1.26.3 in /usr/local/lib/python3.12/dist-packages (from pymupdf4llm) (1.26.4)\n",
            "Requirement already satisfied: pyhwp in /usr/local/lib/python3.12/dist-packages (0.1b15)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from pyhwp) (43.0.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from pyhwp) (5.4.0)\n",
            "Requirement already satisfied: olefile>=0.43 in /usr/local/lib/python3.12/dist-packages (from pyhwp) (0.47)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->pyhwp) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->pyhwp) (2.22)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.12/dist-packages (2.1.11)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (0.3.33)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.24)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain_google_genai)\n",
            "  Using cached google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.11.7)\n",
            "Requirement already satisfied: filetype<2,>=1.2 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.106.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.6.1)\n",
            "Using cached google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "38034cc154c14f4ca93022a95f40b517"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.12/dist-packages (0.14.2)\n",
            "Requirement already satisfied: llama-index-vector-stores-faiss in /usr/local/lib/python3.12/dist-packages (0.5.1)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
            "Requirement already satisfied: llama-index-embeddings-openai in /usr/local/lib/python3.12/dist-packages (0.5.1)\n",
            "Requirement already satisfied: llama-index-llms-gemini in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
            "Requirement already satisfied: llama-index-llms-openai in /usr/local/lib/python3.12/dist-packages (0.5.6)\n",
            "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.14.2 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.14.2)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.9.4)\n",
            "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.4)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.34.4)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-huggingface) (5.1.0)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai) (1.106.1)\n",
            "Requirement already satisfied: google-generativeai>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-gemini) (0.8.5)\n",
            "Requirement already satisfied: pillow<11,>=10.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-gemini) (10.4.0)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.181.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.26.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.1.9)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (2.2.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (2.0.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (4.4.0)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.2->llama-index) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (0.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.2->llama-index) (1.17.3)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.12/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.8.3)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<7,>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.0.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.56.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.16.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (3.10)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.2->llama-index) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.2->llama-index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.14.2->llama-index) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.14.2->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows<3,>=2->llama-index-core<0.15,>=0.14.2->llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.12/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.2->llama-index) (3.2.4)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.4.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.6.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.14.2->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.14.2->llama-index) (3.26.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.30.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (3.2.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.2->llama-index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.2->llama-index) (3.0.2)\n",
            "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.7.0\n",
            "    Uninstalling google-ai-generativelanguage-0.7.0:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.11 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "c2533267af174cc7a428aad754ff22ee"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# 필수 빌드 도구 & 라이브러리 설치\n",
        "!apt-get update\n",
        "!apt-get install -y build-essential libgsf-1-dev libxml2-dev libglib2.0-dev libiconv-hook-dev\n",
        "\n",
        "# 소스코드 clone\n",
        "!git clone https://github.com/mete0r/pyhwp.git\n",
        "%cd pyhwp\n",
        "\n",
        "# 설치\n",
        "!python setup.py install\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T04:03:41.133862Z",
          "iopub.execute_input": "2025-09-16T04:03:41.134103Z",
          "iopub.status.idle": "2025-09-16T04:04:04.097332Z",
          "shell.execute_reply.started": "2025-09-16T04:03:41.134081Z",
          "shell.execute_reply": "2025-09-16T04:04:04.096242Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xPvR2lPgWv3M",
        "outputId": "ec5aa8c8-8869-4561-bfe0-0968e16dc981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://cli.github.com/packages stable/main amd64 Packages [346 B]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,006 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,267 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,795 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,441 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,274 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,311 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,581 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [80.3 kB]\n",
            "Get:21 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [43.2 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,624 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,624 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,627 kB]\n",
            "Fetched 26.3 MB in 6s (4,147 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libglib2.0-dev is already the newest version (2.72.4-0ubuntu2.6).\n",
            "libglib2.0-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  gir1.2-gsf-1 libgsf-1-114 libgsf-1-common libiconv-hook1 libxml2\n",
            "The following NEW packages will be installed:\n",
            "  gir1.2-gsf-1 libgsf-1-114 libgsf-1-common libgsf-1-dev libiconv-hook-dev\n",
            "  libiconv-hook1\n",
            "The following packages will be upgraded:\n",
            "  libxml2 libxml2-dev\n",
            "2 upgraded, 6 newly installed, 0 to remove and 48 not upgraded.\n",
            "Need to get 1,997 kB of archives.\n",
            "After this operation, 2,774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxml2-dev amd64 2.9.13+dfsg-1ubuntu0.9 [804 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxml2 amd64 2.9.13+dfsg-1ubuntu0.9 [764 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgsf-1-common all 1.14.47-1ubuntu0.1 [13.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgsf-1-114 amd64 1.14.47-1ubuntu0.1 [111 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gir1.2-gsf-1 amd64 1.14.47-1ubuntu0.1 [14.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgsf-1-dev amd64 1.14.47-1ubuntu0.1 [228 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libiconv-hook1 amd64 0.0.20021209-12 [59.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libiconv-hook-dev amd64 0.0.20021209-12 [3,094 B]\n",
            "Fetched 1,997 kB in 1s (1,368 kB/s)\n",
            "(Reading database ... 126374 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libxml2-dev_2.9.13+dfsg-1ubuntu0.9_amd64.deb ...\n",
            "Unpacking libxml2-dev:amd64 (2.9.13+dfsg-1ubuntu0.9) over (2.9.13+dfsg-1ubuntu0.8) ...\n",
            "Preparing to unpack .../1-libxml2_2.9.13+dfsg-1ubuntu0.9_amd64.deb ...\n",
            "Unpacking libxml2:amd64 (2.9.13+dfsg-1ubuntu0.9) over (2.9.13+dfsg-1ubuntu0.8) ...\n",
            "Selecting previously unselected package libgsf-1-common.\n",
            "Preparing to unpack .../2-libgsf-1-common_1.14.47-1ubuntu0.1_all.deb ...\n",
            "Unpacking libgsf-1-common (1.14.47-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libgsf-1-114:amd64.\n",
            "Preparing to unpack .../3-libgsf-1-114_1.14.47-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgsf-1-114:amd64 (1.14.47-1ubuntu0.1) ...\n",
            "Selecting previously unselected package gir1.2-gsf-1:amd64.\n",
            "Preparing to unpack .../4-gir1.2-gsf-1_1.14.47-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking gir1.2-gsf-1:amd64 (1.14.47-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libgsf-1-dev:amd64.\n",
            "Preparing to unpack .../5-libgsf-1-dev_1.14.47-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgsf-1-dev:amd64 (1.14.47-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libiconv-hook1.\n",
            "Preparing to unpack .../6-libiconv-hook1_0.0.20021209-12_amd64.deb ...\n",
            "Unpacking libiconv-hook1 (0.0.20021209-12) ...\n",
            "Selecting previously unselected package libiconv-hook-dev.\n",
            "Preparing to unpack .../7-libiconv-hook-dev_0.0.20021209-12_amd64.deb ...\n",
            "Unpacking libiconv-hook-dev (0.0.20021209-12) ...\n",
            "Setting up libgsf-1-common (1.14.47-1ubuntu0.1) ...\n",
            "Setting up libiconv-hook1 (0.0.20021209-12) ...\n",
            "Setting up libxml2:amd64 (2.9.13+dfsg-1ubuntu0.9) ...\n",
            "Setting up libiconv-hook-dev (0.0.20021209-12) ...\n",
            "Setting up libgsf-1-114:amd64 (1.14.47-1ubuntu0.1) ...\n",
            "Setting up libxml2-dev:amd64 (2.9.13+dfsg-1ubuntu0.9) ...\n",
            "Setting up gir1.2-gsf-1:amd64 (1.14.47-1ubuntu0.1) ...\n",
            "Setting up libgsf-1-dev:amd64 (1.14.47-1ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Cloning into 'pyhwp'...\n",
            "remote: Enumerating objects: 12379, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 12379 (delta 38), reused 30 (delta 30), pack-reused 12333 (from 3)\u001b[K\n",
            "Receiving objects: 100% (12379/12379), 4.46 MiB | 16.14 MiB/s, done.\n",
            "Resolving deltas: 100% (7571/7571), done.\n",
            "/content/pyhwp\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/__init__.py:92: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "\n",
            "        By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
            "        or your builds will no longer be supported.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "\n",
            "        License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self._finalize_license_expression()\n",
            "running install\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
            "        or your builds will no longer be supported.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running build\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/__init__.py:92: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "\n",
            "        By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
            "        or your builds will no longer be supported.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "\n",
            "        License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self._finalize_license_expression()\n",
            "running compile_catalog\n",
            "compiling catalog src/hwp5/locale/ko/LC_MESSAGES/hwp5proc.po to src/hwp5/locale/ko/LC_MESSAGES/hwp5proc.mo\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/__init__.py:92: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "\n",
            "        By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
            "        or your builds will no longer be supported.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "\n",
            "        License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self._finalize_license_expression()\n",
            "running compile_catalog\n",
            "compiling catalog src/hwp5/locale/ko/LC_MESSAGES/hwp5html.po to src/hwp5/locale/ko/LC_MESSAGES/hwp5html.mo\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/__init__.py:92: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "\n",
            "        By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
            "        or your builds will no longer be supported.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "\n",
            "        License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self._finalize_license_expression()\n",
            "running compile_catalog\n",
            "compiling catalog src/hwp5/locale/ko/LC_MESSAGES/hwp5odt.po to src/hwp5/locale/ko/LC_MESSAGES/hwp5odt.mo\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/__init__.py:92: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "\n",
            "        By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
            "        or your builds will no longer be supported.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "\n",
            "        License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self._finalize_license_expression()\n",
            "running compile_catalog\n",
            "compiling catalog src/hwp5/locale/ko/LC_MESSAGES/hwp5txt.po to src/hwp5/locale/ko/LC_MESSAGES/hwp5txt.mo\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/__init__.py:92: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "\n",
            "        By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
            "        or your builds will no longer be supported.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "\n",
            "        License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self._finalize_license_expression()\n",
            "running compile_catalog\n",
            "compiling catalog src/hwp5/locale/ko/LC_MESSAGES/hwp5view.po to src/hwp5/locale/ko/LC_MESSAGES/hwp5view.mo\n",
            "running build_py\n",
            "creating build/lib/hwp5\n",
            "copying src/hwp5/hwp5txt.py -> build/lib/hwp5\n",
            "copying src/hwp5/tagids.py -> build/lib/hwp5\n",
            "copying src/hwp5/errors.py -> build/lib/hwp5\n",
            "copying src/hwp5/importhelper.py -> build/lib/hwp5\n",
            "copying src/hwp5/hwp5odt.py -> build/lib/hwp5\n",
            "copying src/hwp5/binspec.py -> build/lib/hwp5\n",
            "copying src/hwp5/xmldump_flat.py -> build/lib/hwp5\n",
            "copying src/hwp5/compressed.py -> build/lib/hwp5\n",
            "copying src/hwp5/hwp5view.py -> build/lib/hwp5\n",
            "copying src/hwp5/recordstream.py -> build/lib/hwp5\n",
            "copying src/hwp5/bintype.py -> build/lib/hwp5\n",
            "copying src/hwp5/treeop.py -> build/lib/hwp5\n",
            "copying src/hwp5/utils.py -> build/lib/hwp5\n",
            "copying src/hwp5/filestructure.py -> build/lib/hwp5\n",
            "copying src/hwp5/charsets.py -> build/lib/hwp5\n",
            "copying src/hwp5/zlib_raw_codec.py -> build/lib/hwp5\n",
            "copying src/hwp5/distdoc.py -> build/lib/hwp5\n",
            "copying src/hwp5/xmlmodel.py -> build/lib/hwp5\n",
            "copying src/hwp5/dataio.py -> build/lib/hwp5\n",
            "copying src/hwp5/msoleprops.py -> build/lib/hwp5\n",
            "copying src/hwp5/summaryinfo.py -> build/lib/hwp5\n",
            "copying src/hwp5/cli.py -> build/lib/hwp5\n",
            "copying src/hwp5/xmlformat.py -> build/lib/hwp5\n",
            "copying src/hwp5/hwp5html.py -> build/lib/hwp5\n",
            "copying src/hwp5/hwp5proc.py -> build/lib/hwp5\n",
            "copying src/hwp5/__init__.py -> build/lib/hwp5\n",
            "creating build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid56_list_header.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid75_form_object.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid55_ctrl_header.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid51_para_text.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid31_layout_compatibility.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid69_shape_component_picture.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid64_shape_component_ellipse.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid57_page_def.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid74_shape_component_textart.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid32_unknown.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid50_para_header.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid60_shape_component.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid19_face_name.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid59_page_border_fill.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid28_distribute_doc_data.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid16_document_properties.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid76_memo_shape.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid71_ctrl_data.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid20_border_fill.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid22_tab_def.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid24_bullet.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid23_numbering.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid78_forbidden_char.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/controlchar.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid72_ctrl_eqedit.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid68_shape_component_ole.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid58_footnote_shape.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid99_shape_component_unknown.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/_shared.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid25_para_shape.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid61_table.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid53_para_line_seg.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid27_doc_data.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid66_shape_component_polygon.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid26_style.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid54_para_range_tag.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid63_shape_component_rectangle.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid79_chart_data.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid52_para_char_shape.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid65_shape_component_arc.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid18_bin_data.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid67_shape_component_curve.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid62_shape_component_line.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid70_shape_component_container.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid21_char_shape.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid17_id_mappings.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/__init__.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid30_compatible_document.py -> build/lib/hwp5/binmodel\n",
            "copying src/hwp5/binmodel/tagid77_memo_list.py -> build/lib/hwp5/binmodel\n",
            "creating build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/table_control.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/header_footer.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/note.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/index_marker.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/hidden_comment.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/tcps_control.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/bookmark_control.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/common_controls.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/_shared.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/field.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/columns_def.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/gshape_object_control.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/page_odd_even.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/numbering.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/page_number_position.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/page_hide.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/dutmal.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/section_def.py -> build/lib/hwp5/binmodel/controls\n",
            "copying src/hwp5/binmodel/controls/__init__.py -> build/lib/hwp5/binmodel/controls\n",
            "creating build/lib/hwp5/plat\n",
            "copying src/hwp5/plat/gir_gsf.py -> build/lib/hwp5/plat\n",
            "copying src/hwp5/plat/javax_transform.py -> build/lib/hwp5/plat\n",
            "copying src/hwp5/plat/xsltproc.py -> build/lib/hwp5/plat\n",
            "copying src/hwp5/plat/xmllint.py -> build/lib/hwp5/plat\n",
            "copying src/hwp5/plat/_lxml.py -> build/lib/hwp5/plat\n",
            "copying src/hwp5/plat/jython_poifs.py -> build/lib/hwp5/plat\n",
            "copying src/hwp5/plat/olefileio.py -> build/lib/hwp5/plat\n",
            "copying src/hwp5/plat/__init__.py -> build/lib/hwp5/plat\n",
            "creating build/lib/hwp5/plat/_uno\n",
            "copying src/hwp5/plat/_uno/services.py -> build/lib/hwp5/plat/_uno\n",
            "copying src/hwp5/plat/_uno/ucb.py -> build/lib/hwp5/plat/_uno\n",
            "copying src/hwp5/plat/_uno/adapters.py -> build/lib/hwp5/plat/_uno\n",
            "copying src/hwp5/plat/_uno/__init__.py -> build/lib/hwp5/plat/_uno\n",
            "creating build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/cat.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/xml.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/models.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/rawunz.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/diststream.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/ls.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/version.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/header.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/summaryinfo.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/records.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/unpack.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/find.py -> build/lib/hwp5/proc\n",
            "copying src/hwp5/proc/__init__.py -> build/lib/hwp5/proc\n",
            "creating build/lib/hwp5/storage\n",
            "copying src/hwp5/storage/ole.py -> build/lib/hwp5/storage\n",
            "copying src/hwp5/storage/fs.py -> build/lib/hwp5/storage\n",
            "copying src/hwp5/storage/__init__.py -> build/lib/hwp5/storage\n",
            "creating build/lib/hwp5/transforms\n",
            "copying src/hwp5/transforms/__init__.py -> build/lib/hwp5/transforms\n",
            "copying src/hwp5/README -> build/lib/hwp5\n",
            "copying src/hwp5/COPYING -> build/lib/hwp5\n",
            "copying src/hwp5/VERSION.txt -> build/lib/hwp5\n",
            "creating build/lib/hwp5/xsl\n",
            "copying src/hwp5/xsl/hwp5fodt.xsl -> build/lib/hwp5/xsl\n",
            "copying src/hwp5/xsl/plaintext.xsl -> build/lib/hwp5/xsl\n",
            "copying src/hwp5/xsl/hwp5html.xsl -> build/lib/hwp5/xsl\n",
            "copying src/hwp5/xsl/hwp5css-common.xsl -> build/lib/hwp5/xsl\n",
            "copying src/hwp5/xsl/binspec2html.xsl -> build/lib/hwp5/xsl\n",
            "copying src/hwp5/xsl/hwp5css.xsl -> build/lib/hwp5/xsl\n",
            "creating build/lib/hwp5/xsl/odt\n",
            "copying src/hwp5/xsl/odt/common.xsl -> build/lib/hwp5/xsl/odt\n",
            "copying src/hwp5/xsl/odt/content.xsl -> build/lib/hwp5/xsl/odt\n",
            "copying src/hwp5/xsl/odt/document.xsl -> build/lib/hwp5/xsl/odt\n",
            "copying src/hwp5/xsl/odt/styles.xsl -> build/lib/hwp5/xsl/odt\n",
            "creating build/lib/hwp5/odf-relaxng\n",
            "copying src/hwp5/odf-relaxng/OpenDocument-v1.2-os-manifest-schema.rng -> build/lib/hwp5/odf-relaxng\n",
            "copying src/hwp5/odf-relaxng/OpenDocument-v1.2-os-schema.rng -> build/lib/hwp5/odf-relaxng\n",
            "copying src/hwp5/odf-relaxng/OpenDocument-v1.2-os-dsig-schema.rng -> build/lib/hwp5/odf-relaxng\n",
            "creating build/lib/hwp5/locale/ko/LC_MESSAGES\n",
            "copying src/hwp5/locale/ko/LC_MESSAGES/hwp5odt.mo -> build/lib/hwp5/locale/ko/LC_MESSAGES\n",
            "copying src/hwp5/locale/ko/LC_MESSAGES/hwp5proc.mo -> build/lib/hwp5/locale/ko/LC_MESSAGES\n",
            "copying src/hwp5/locale/ko/LC_MESSAGES/hwp5html.mo -> build/lib/hwp5/locale/ko/LC_MESSAGES\n",
            "copying src/hwp5/locale/ko/LC_MESSAGES/hwp5view.mo -> build/lib/hwp5/locale/ko/LC_MESSAGES\n",
            "copying src/hwp5/locale/ko/LC_MESSAGES/hwp5txt.mo -> build/lib/hwp5/locale/ko/LC_MESSAGES\n",
            "running install_lib\n",
            "copying build/lib/hwp5/hwp5txt.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/tagids.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/errors.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/importhelper.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/storage/ole.py -> /usr/local/lib/python3.12/dist-packages/hwp5/storage\n",
            "copying build/lib/hwp5/storage/fs.py -> /usr/local/lib/python3.12/dist-packages/hwp5/storage\n",
            "copying build/lib/hwp5/storage/__init__.py -> /usr/local/lib/python3.12/dist-packages/hwp5/storage\n",
            "copying build/lib/hwp5/xsl/hwp5fodt.xsl -> /usr/local/lib/python3.12/dist-packages/hwp5/xsl\n",
            "copying build/lib/hwp5/xsl/plaintext.xsl -> /usr/local/lib/python3.12/dist-packages/hwp5/xsl\n",
            "copying build/lib/hwp5/xsl/hwp5html.xsl -> /usr/local/lib/python3.12/dist-packages/hwp5/xsl\n",
            "copying build/lib/hwp5/xsl/hwp5css-common.xsl -> /usr/local/lib/python3.12/dist-packages/hwp5/xsl\n",
            "copying build/lib/hwp5/xsl/binspec2html.xsl -> /usr/local/lib/python3.12/dist-packages/hwp5/xsl\n",
            "copying build/lib/hwp5/xsl/hwp5css.xsl -> /usr/local/lib/python3.12/dist-packages/hwp5/xsl\n",
            "copying build/lib/hwp5/xsl/odt/common.xsl -> /usr/local/lib/python3.12/dist-packages/hwp5/xsl/odt\n",
            "copying build/lib/hwp5/xsl/odt/content.xsl -> /usr/local/lib/python3.12/dist-packages/hwp5/xsl/odt\n",
            "copying build/lib/hwp5/xsl/odt/document.xsl -> /usr/local/lib/python3.12/dist-packages/hwp5/xsl/odt\n",
            "copying build/lib/hwp5/xsl/odt/styles.xsl -> /usr/local/lib/python3.12/dist-packages/hwp5/xsl/odt\n",
            "copying build/lib/hwp5/proc/cat.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/xml.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/models.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/rawunz.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/diststream.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/ls.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/version.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/header.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/summaryinfo.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/records.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/unpack.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/find.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/proc/__init__.py -> /usr/local/lib/python3.12/dist-packages/hwp5/proc\n",
            "copying build/lib/hwp5/hwp5odt.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/README -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/binspec.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/xmldump_flat.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/binmodel/tagid56_list_header.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid75_form_object.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid55_ctrl_header.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid51_para_text.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid31_layout_compatibility.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid69_shape_component_picture.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid64_shape_component_ellipse.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid57_page_def.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid74_shape_component_textart.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid32_unknown.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid50_para_header.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid60_shape_component.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid19_face_name.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/controls/table_control.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/header_footer.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/note.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/index_marker.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/hidden_comment.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/tcps_control.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/bookmark_control.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/common_controls.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/_shared.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/field.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/columns_def.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/gshape_object_control.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/page_odd_even.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/numbering.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/page_number_position.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/page_hide.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/dutmal.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/section_def.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/controls/__init__.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls\n",
            "copying build/lib/hwp5/binmodel/tagid59_page_border_fill.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid28_distribute_doc_data.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid16_document_properties.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid76_memo_shape.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid71_ctrl_data.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid20_border_fill.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid22_tab_def.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid24_bullet.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid23_numbering.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid78_forbidden_char.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/controlchar.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid72_ctrl_eqedit.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid68_shape_component_ole.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid58_footnote_shape.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid99_shape_component_unknown.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/_shared.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid25_para_shape.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid61_table.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid53_para_line_seg.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid27_doc_data.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid66_shape_component_polygon.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid26_style.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid54_para_range_tag.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid63_shape_component_rectangle.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid79_chart_data.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid52_para_char_shape.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid65_shape_component_arc.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid18_bin_data.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid67_shape_component_curve.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid62_shape_component_line.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid70_shape_component_container.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid21_char_shape.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid17_id_mappings.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/__init__.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid30_compatible_document.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/binmodel/tagid77_memo_list.py -> /usr/local/lib/python3.12/dist-packages/hwp5/binmodel\n",
            "copying build/lib/hwp5/compressed.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/locale/ko/LC_MESSAGES/hwp5odt.mo -> /usr/local/lib/python3.12/dist-packages/hwp5/locale/ko/LC_MESSAGES\n",
            "copying build/lib/hwp5/locale/ko/LC_MESSAGES/hwp5proc.mo -> /usr/local/lib/python3.12/dist-packages/hwp5/locale/ko/LC_MESSAGES\n",
            "copying build/lib/hwp5/locale/ko/LC_MESSAGES/hwp5html.mo -> /usr/local/lib/python3.12/dist-packages/hwp5/locale/ko/LC_MESSAGES\n",
            "copying build/lib/hwp5/locale/ko/LC_MESSAGES/hwp5view.mo -> /usr/local/lib/python3.12/dist-packages/hwp5/locale/ko/LC_MESSAGES\n",
            "copying build/lib/hwp5/locale/ko/LC_MESSAGES/hwp5txt.mo -> /usr/local/lib/python3.12/dist-packages/hwp5/locale/ko/LC_MESSAGES\n",
            "copying build/lib/hwp5/VERSION.txt -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/hwp5view.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/odf-relaxng/OpenDocument-v1.2-os-manifest-schema.rng -> /usr/local/lib/python3.12/dist-packages/hwp5/odf-relaxng\n",
            "copying build/lib/hwp5/odf-relaxng/OpenDocument-v1.2-os-schema.rng -> /usr/local/lib/python3.12/dist-packages/hwp5/odf-relaxng\n",
            "copying build/lib/hwp5/odf-relaxng/OpenDocument-v1.2-os-dsig-schema.rng -> /usr/local/lib/python3.12/dist-packages/hwp5/odf-relaxng\n",
            "copying build/lib/hwp5/recordstream.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/bintype.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/treeop.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/utils.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/filestructure.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/charsets.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/zlib_raw_codec.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/distdoc.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/transforms/__init__.py -> /usr/local/lib/python3.12/dist-packages/hwp5/transforms\n",
            "copying build/lib/hwp5/xmlmodel.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/plat/gir_gsf.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat\n",
            "copying build/lib/hwp5/plat/javax_transform.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat\n",
            "copying build/lib/hwp5/plat/_uno/services.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat/_uno\n",
            "copying build/lib/hwp5/plat/_uno/ucb.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat/_uno\n",
            "copying build/lib/hwp5/plat/_uno/adapters.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat/_uno\n",
            "copying build/lib/hwp5/plat/_uno/__init__.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat/_uno\n",
            "copying build/lib/hwp5/plat/xsltproc.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat\n",
            "copying build/lib/hwp5/plat/xmllint.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat\n",
            "copying build/lib/hwp5/plat/_lxml.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat\n",
            "copying build/lib/hwp5/plat/jython_poifs.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat\n",
            "copying build/lib/hwp5/plat/olefileio.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat\n",
            "copying build/lib/hwp5/plat/__init__.py -> /usr/local/lib/python3.12/dist-packages/hwp5/plat\n",
            "copying build/lib/hwp5/dataio.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/msoleprops.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/summaryinfo.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/cli.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/xmlformat.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/hwp5html.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/COPYING -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/hwp5proc.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "copying build/lib/hwp5/__init__.py -> /usr/local/lib/python3.12/dist-packages/hwp5\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/hwp5txt.py to hwp5txt.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/tagids.py to tagids.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/errors.py to errors.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/importhelper.py to importhelper.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/storage/ole.py to ole.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/storage/fs.py to fs.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/storage/__init__.py to __init__.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/cat.py to cat.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/xml.py to xml.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/models.py to models.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/rawunz.py to rawunz.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/diststream.py to diststream.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/ls.py to ls.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/version.py to version.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/header.py to header.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/summaryinfo.py to summaryinfo.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/records.py to records.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/unpack.py to unpack.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/find.py to find.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/proc/__init__.py to __init__.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/hwp5odt.py to hwp5odt.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binspec.py to binspec.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/xmldump_flat.py to xmldump_flat.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid56_list_header.py to tagid56_list_header.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid75_form_object.py to tagid75_form_object.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid55_ctrl_header.py to tagid55_ctrl_header.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid51_para_text.py to tagid51_para_text.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid31_layout_compatibility.py to tagid31_layout_compatibility.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid69_shape_component_picture.py to tagid69_shape_component_picture.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid64_shape_component_ellipse.py to tagid64_shape_component_ellipse.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid57_page_def.py to tagid57_page_def.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid74_shape_component_textart.py to tagid74_shape_component_textart.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid32_unknown.py to tagid32_unknown.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid50_para_header.py to tagid50_para_header.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid60_shape_component.py to tagid60_shape_component.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid19_face_name.py to tagid19_face_name.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/table_control.py to table_control.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/header_footer.py to header_footer.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/note.py to note.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/index_marker.py to index_marker.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/hidden_comment.py to hidden_comment.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/tcps_control.py to tcps_control.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/bookmark_control.py to bookmark_control.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/common_controls.py to common_controls.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/_shared.py to _shared.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/field.py to field.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/columns_def.py to columns_def.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/gshape_object_control.py to gshape_object_control.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/page_odd_even.py to page_odd_even.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/numbering.py to numbering.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/page_number_position.py to page_number_position.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/page_hide.py to page_hide.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/dutmal.py to dutmal.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/section_def.py to section_def.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controls/__init__.py to __init__.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid59_page_border_fill.py to tagid59_page_border_fill.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid28_distribute_doc_data.py to tagid28_distribute_doc_data.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid16_document_properties.py to tagid16_document_properties.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid76_memo_shape.py to tagid76_memo_shape.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid71_ctrl_data.py to tagid71_ctrl_data.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid20_border_fill.py to tagid20_border_fill.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid22_tab_def.py to tagid22_tab_def.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid24_bullet.py to tagid24_bullet.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid23_numbering.py to tagid23_numbering.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid78_forbidden_char.py to tagid78_forbidden_char.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/controlchar.py to controlchar.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid72_ctrl_eqedit.py to tagid72_ctrl_eqedit.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid68_shape_component_ole.py to tagid68_shape_component_ole.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid58_footnote_shape.py to tagid58_footnote_shape.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid99_shape_component_unknown.py to tagid99_shape_component_unknown.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/_shared.py to _shared.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid25_para_shape.py to tagid25_para_shape.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid61_table.py to tagid61_table.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid53_para_line_seg.py to tagid53_para_line_seg.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid27_doc_data.py to tagid27_doc_data.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid66_shape_component_polygon.py to tagid66_shape_component_polygon.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid26_style.py to tagid26_style.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid54_para_range_tag.py to tagid54_para_range_tag.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid63_shape_component_rectangle.py to tagid63_shape_component_rectangle.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid79_chart_data.py to tagid79_chart_data.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid52_para_char_shape.py to tagid52_para_char_shape.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid65_shape_component_arc.py to tagid65_shape_component_arc.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid18_bin_data.py to tagid18_bin_data.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid67_shape_component_curve.py to tagid67_shape_component_curve.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid62_shape_component_line.py to tagid62_shape_component_line.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid70_shape_component_container.py to tagid70_shape_component_container.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid21_char_shape.py to tagid21_char_shape.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid17_id_mappings.py to tagid17_id_mappings.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/__init__.py to __init__.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid30_compatible_document.py to tagid30_compatible_document.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/binmodel/tagid77_memo_list.py to tagid77_memo_list.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/compressed.py to compressed.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/hwp5view.py to hwp5view.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/recordstream.py to recordstream.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/bintype.py to bintype.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/treeop.py to treeop.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/utils.py to utils.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/filestructure.py to filestructure.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/charsets.py to charsets.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/zlib_raw_codec.py to zlib_raw_codec.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/distdoc.py to distdoc.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/transforms/__init__.py to __init__.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/xmlmodel.py to xmlmodel.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/gir_gsf.py to gir_gsf.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/javax_transform.py to javax_transform.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/_uno/services.py to services.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/_uno/ucb.py to ucb.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/_uno/adapters.py to adapters.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/_uno/__init__.py to __init__.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/xsltproc.py to xsltproc.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/xmllint.py to xmllint.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/_lxml.py to _lxml.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/jython_poifs.py to jython_poifs.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/olefileio.py to olefileio.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/plat/__init__.py to __init__.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/dataio.py to dataio.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/msoleprops.py to msoleprops.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/summaryinfo.py to summaryinfo.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/cli.py to cli.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/xmlformat.py to xmlformat.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/hwp5html.py to hwp5html.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/hwp5proc.py to hwp5proc.cpython-312.pyc\n",
            "byte-compiling /usr/local/lib/python3.12/dist-packages/hwp5/__init__.py to __init__.cpython-312.pyc\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating src/pyhwp.egg-info\n",
            "writing src/pyhwp.egg-info/PKG-INFO\n",
            "writing dependency_links to src/pyhwp.egg-info/dependency_links.txt\n",
            "writing entry points to src/pyhwp.egg-info/entry_points.txt\n",
            "writing requirements to src/pyhwp.egg-info/requires.txt\n",
            "writing top-level names to src/pyhwp.egg-info/top_level.txt\n",
            "writing manifest file 'src/pyhwp.egg-info/SOURCES.txt'\n",
            "reading manifest file 'src/pyhwp.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no previously-included files found matching 'notebooks'\n",
            "warning: no previously-included files found matching 'samples'\n",
            "no previously-included directories found matching 'buildouts'\n",
            "no previously-included directories found matching 'docs'\n",
            "no previously-included directories found matching 'etc'\n",
            "no previously-included directories found matching 'misc'\n",
            "no previously-included directories found matching 'oxt'\n",
            "no previously-included directories found matching 'release-hooks'\n",
            "no previously-included directories found matching 'tests'\n",
            "no previously-included directories found matching 'tools'\n",
            "no previously-included directories found matching 'unokit'\n",
            "no previously-included directories found matching 'pyhwp_uno'\n",
            "adding license file 'LICENSE'\n",
            "adding license file 'COPYING'\n",
            "writing manifest file 'src/pyhwp.egg-info/SOURCES.txt'\n",
            "Copying src/pyhwp.egg-info to /usr/local/lib/python3.12/dist-packages/pyhwp-0.1b16.dev0-py3.12.egg-info\n",
            "running install_scripts\n",
            "Installing hwp5html script to /usr/local/bin\n",
            "Installing hwp5odt script to /usr/local/bin\n",
            "Installing hwp5proc script to /usr/local/bin\n",
            "Installing hwp5spec script to /usr/local/bin\n",
            "Installing hwp5txt script to /usr/local/bin\n",
            "Installing hwp5view script to /usr/local/bin\n",
            "/content\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import time\n",
        "import fitz  # PyMuPDF\n",
        "import pyhwp\n",
        "import gdown\n",
        "import torch\n",
        "import easyocr\n",
        "import zipfile\n",
        "import pickle\n",
        "import easyocr\n",
        "import subprocess\n",
        "import pymupdf4llm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup, NavigableString, Comment\n",
        "\n",
        "from langchain.schema import Document"
      ],
      "metadata": {
        "id": "yl8S1YbQ9d6v",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T04:04:04.098386Z",
          "iopub.execute_input": "2025-09-16T04:04:04.098592Z",
          "iopub.status.idle": "2025-09-16T04:04:15.980036Z",
          "shell.execute_reply.started": "2025-09-16T04:04:04.098570Z",
          "shell.execute_reply": "2025-09-16T04:04:15.979224Z"
        }
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 기본 Utils (basic_utils.py)"
      ],
      "metadata": {
        "id": "k0oP4cew5n4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_secret(key_name: str):\n",
        "\n",
        "    # 1) Kaggle 환경: os.environ 또는 파일에서 읽기\n",
        "    if key_name in os.environ:\n",
        "        return os.environ[key_name]\n",
        "\n",
        "    try:\n",
        "        from kaggle_secrets import UserSecretsClient\n",
        "        user_secrets = UserSecretsClient()\n",
        "        return user_secrets.get_secret(key_name)\n",
        "    except ImportError:\n",
        "        pass\n",
        "\n",
        "    # 2) Colab 환경인지 확인\n",
        "    try:\n",
        "        import google.colab.userdata as userdata\n",
        "        try:\n",
        "            return userdata.get(key_name)\n",
        "        except KeyError:\n",
        "            pass # Key not in Colab userdata\n",
        "    except ImportError:\n",
        "        pass\n",
        "\n",
        "    raise KeyError(f\"Secret '{key_name}' not found in Colab userdata, os.environ, or file.\")\n",
        "\n",
        "\n",
        "def download(id, filename):\n",
        "    if os.path.isfile(filename) and os.path.getsize(filename) > 0:\n",
        "        print(f\"[skip] {filename} 이미 존재합니다.\")\n",
        "    else:\n",
        "        gdown.download(id=id, output=filename, quiet=False)\n",
        "        print(f'[ok] {filename} 다운로드 완료.')\n",
        "\n",
        "        if filename.lower().endswith('.zip'):\n",
        "            try:\n",
        "                with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(os.path.dirname(filename) or '.') # Extract to directory of the file, or current if no directory\n",
        "                print(f'[ok] {filename} 압축풀기 완료.')\n",
        "            except zipfile.BadZipFile:\n",
        "                print(f\"[warning] {filename}은 유효한 zip 파일이 아닙니다.\")\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "def load_csv(filename):\n",
        "  \"\"\"Loads a CSV file into a pandas DataFrame.\"\"\"\n",
        "  try:\n",
        "    df = pd.read_csv(filename)\n",
        "    print(f\"[ok] {filename} 로드 완료.\")\n",
        "    return df\n",
        "  except FileNotFoundError:\n",
        "    print(f\"[error] {filename} 파일을 찾을 수 없습니다.\")\n",
        "    return None\n",
        "  except Exception as e:\n",
        "    print(f\"[error] {filename} 로드 중 오류 발생: {e}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def save_pages(pages, filename):\n",
        "    directory = os.path.dirname(filename)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        print(f\"디렉토리 '{directory}'를 생성했습니다.\")\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(pages, f)\n",
        "    print(f\"'{filename}' 파일에 pages를 저장했습니다.\")\n",
        "\n",
        "\n",
        "def load_pages(filename):\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"오류: '{filename}' 파일을 찾을 수 없습니다.\")\n",
        "        return None\n",
        "    with open(filename, 'rb') as f:\n",
        "        pages = pickle.load(f)\n",
        "    print(f\"'{filename}' 파일에서 pages를 로드했습니다.\")\n",
        "    return pages\n",
        "\n",
        "\n",
        "def timer(func):\n",
        "    start_time = time.time()\n",
        "    result = func()\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"실행 시간: {elapsed_time:.4f}초\")\n",
        "    return result\n",
        "\n",
        "def ext(original_filename, ext='pkl'):\n",
        "  base_filename, _ = os.path.splitext(original_filename)\n",
        "  return f\"{base_filename}.{ext}\"\n",
        "\n",
        "\n",
        "def firstname(original_filename):\n",
        "    filename_with_extension = os.path.basename(original_filename)\n",
        "    base_filename, _ = os.path.splitext(filename_with_extension)\n",
        "    return base_filename"
      ],
      "metadata": {
        "id": "3cK1EAzH5ndU",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T04:04:15.982030Z",
          "iopub.execute_input": "2025-09-16T04:04:15.982440Z",
          "iopub.status.idle": "2025-09-16T04:04:15.992554Z",
          "shell.execute_reply.started": "2025-09-16T04:04:15.982420Z",
          "shell.execute_reply": "2025-09-16T04:04:15.991832Z"
        }
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF/HWP 문서 Utils (document_utils.py)"
      ],
      "metadata": {
        "id": "uATmb0zEBrZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from bs4 import BeautifulSoup, NavigableString, Comment\n",
        "import easyocr\n",
        "import re\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from textwrap import dedent\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import logging\n",
        "\n",
        "\n",
        "def load_pymupdf(pdf_path, filename, langs=['ko','en'], zoom=3.0, gpu=True):\n",
        "    \"\"\"\n",
        "    PDF 페이지별 텍스트 레이어 + EasyOCR 결과 병합\n",
        "    - langs: EasyOCR 언어 리스트\n",
        "    - zoom: 해상도 배율 (3.0이면 약 216dpi)\n",
        "    - gpu: GPU 사용 여부\n",
        "    \"\"\"\n",
        "    # 캐시 로드\n",
        "    output_path = f'outputs/{filename}'\n",
        "    if os.path.exists(output_path):\n",
        "        return load_pages(output_path)\n",
        "\n",
        "    # EasyOCR Reader 초기화\n",
        "    reader = easyocr.Reader(langs, gpu=gpu)\n",
        "\n",
        "    doc = fitz.open(f'files/{pdf_path}')\n",
        "    pages = []\n",
        "\n",
        "    for page_num, page in enumerate(doc, start=1):\n",
        "        # 1. 텍스트 레이어 추출\n",
        "        text_layer = page.get_text()\n",
        "\n",
        "        # 2. 고해상도 렌더링\n",
        "        matrix = fitz.Matrix(zoom, zoom)\n",
        "        pix = page.get_pixmap(matrix=matrix, alpha=False)\n",
        "        img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
        "\n",
        "        # 3. EasyOCR 실행\n",
        "        cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "        results = reader.readtext(cv_img, detail=0)  # detail=0 → 텍스트만 리스트로 반환\n",
        "        ocr_text = \"\\n\".join(results)\n",
        "\n",
        "        # 4. 병합\n",
        "        merged_text = (text_layer or \"\").strip() + \"\\n\" + (ocr_text or \"\").strip()\n",
        "\n",
        "        print(f\"[페이지 {page_num}] 텍스트 길이: {len(text_layer)}, OCR 길이: {len(ocr_text)}\")\n",
        "        pages.append(Document(page_content=merged_text))\n",
        "        display(img)\n",
        "        print(ocr_text)\n",
        "    doc.close()\n",
        "\n",
        "    # 캐시 저장\n",
        "    save_pages(pages, output_path)\n",
        "    return pages\n",
        "\n",
        "\n",
        "def load_pymupdf4llm_easyocr(pdf_filename, metadata = {}):\n",
        "    IMAGE_PATH = 'images'\n",
        "    pdf_path = f'files/{pdf_filename}'\n",
        "    output_path = f'outputs/{ext(pdf_filename)}'\n",
        "    if os.path.exists(output_path):\n",
        "        return load_pages(output_path)\n",
        "\n",
        "    os.makedirs(IMAGE_PATH, exist_ok=True)\n",
        "\n",
        "    # EasyOCR 리더 객체 초기화 (GPU 사용 가능 시 활용)\n",
        "    reader = easyocr.Reader(['ko', 'en'], gpu=torch.cuda.is_available())\n",
        "\n",
        "    # 1. PyMuPDF4LLM을 사용해 마크다운 생성 및 이미지 추출\n",
        "    # write_images=True 옵션으로 이미지 추출\n",
        "    # image_path 옵션으로 이미지 저장 위치 지정\n",
        "    # page_chunks=True 옵션으로 페이지별로 분리된 결과 생성\n",
        "    extracted_chunks = pymupdf4llm.to_markdown(pdf_path, write_images=True, image_path=IMAGE_PATH, page_chunks=True)\n",
        "\n",
        "    # final_markdown = \"\"\n",
        "    pages = []\n",
        "    # 2. EasyOCR로 이미지 내 텍스트 인식 후 마크다운에 추가\n",
        "    for chunk in extracted_chunks:\n",
        "        page_text = chunk[\"text\"]\n",
        "\n",
        "        page_number = chunk[\"metadata\"][\"page\"] # Get the page index from metadata\n",
        "        # print('페이지: ', page_number)\n",
        "\n",
        "        # 마크다운 내 이미지 참조 찾기 (예: ![image_name](images/image_name.png))\n",
        "        # ([^\\]]+)는 이미지 이름 부분을 캡처\n",
        "        image_ref_pattern = re.compile(r\"!\\[(.*?)\\]\\((.*?)\\)\")\n",
        "        matches = image_ref_pattern.finditer(page_text)\n",
        "\n",
        "        # 이미지 참조를 순서대로 처리\n",
        "        for match in reversed(list(matches)):\n",
        "            image_path = match.group(2)\n",
        "\n",
        "            # EasyOCR로 이미지 내 텍스트 인식\n",
        "            try:\n",
        "                ocr_results = reader.readtext(image_path)\n",
        "                ocr_caption = \" \".join([text for _, text, _ in ocr_results])\n",
        "            except Exception as e:\n",
        "                print(f\"OCR 처리 중 오류 발생: {e}\")\n",
        "                ocr_caption = \"OCR 처리 실패\"\n",
        "\n",
        "            # 마크다운 텍스트 업데이트 (이미지 참조 다음에 OCR 결과 삽입)\n",
        "            original_match_string = match.group(0)\n",
        "            replacement_string = f\"{original_match_string}\\n\\n**OCR 텍스트:** {ocr_caption}\\n\"\n",
        "            page_text = page_text[:match.start()] + replacement_string + page_text[match.end():]\n",
        "        pages.append(Document(page_content=page_text, metadata=metadata))\n",
        "        # final_markdown += page_text + \"\\n\\n\"\n",
        "\n",
        "    save_pages(pages, output_path)\n",
        "    return pages #final_markdown\n",
        "\n",
        "\n",
        "def hwp_to_html(hwp_path, temp_html_dir):\n",
        "    \"\"\"\n",
        "    hwp5html을 사용해 HWP를 HTML로 변환합니다.\n",
        "    변환 실패 시 hwp5txt를, 그것도 실패하면 hwplib(Java)를 폴백으로 사용합니다.\n",
        "    \"\"\"\n",
        "    # hwp5 로그를 숨기기 위한 설정\n",
        "    logging.getLogger('hwp5html').setLevel(logging.WARNING)\n",
        "\n",
        "    # hwplib jar 파일을 저장할 디렉토리 및 버전\n",
        "    JAVA_MAIN_CLASS_NAME = \"HwpTextExtractor\"\n",
        "    JAR_DIR = Path(\"./temp_hwplib\")\n",
        "    HWPLIB_JAR_VERSION = \"1.1.10\"\n",
        "    HWPLIB_JAR_NAME = f\"hwplib-{HWPLIB_JAR_VERSION}.jar\"\n",
        "    HWPLIB_JAR_PATH = JAR_DIR / HWPLIB_JAR_NAME\n",
        "    HWPLIB_DOWNLOAD_URL = f\"https://repo1.maven.org/maven2/kr/dogfoot/hwplib/{HWPLIB_JAR_VERSION}/{HWPLIB_JAR_NAME}\"\n",
        "\n",
        "    path_hwp = Path(hwp_path)\n",
        "    path_html = Path(temp_html_dir) / f\"{path_hwp.stem}.html\"\n",
        "    os.makedirs(temp_html_dir, exist_ok=True)\n",
        "\n",
        "    def setup_hwplib_java():\n",
        "        \"\"\"hwplib JAR 파일 다운로드 및 자바 소스 컴파일\"\"\"\n",
        "        JAVA_MAIN_CLASS_FILE = JAR_DIR / f\"{JAVA_MAIN_CLASS_NAME}.java\"\n",
        "        # 수정된 자바 소스 코드 (args 배열의 첫 번째 요소 사용 및 OnlyMainParagraph 옵션 적용)\n",
        "        JAVA_MAIN_CLASS_CODE = dedent(\"\"\"\n",
        "            import kr.dogfoot.hwplib.object.HWPFile;\n",
        "            import kr.dogfoot.hwplib.reader.HWPReader;\n",
        "            import kr.dogfoot.hwplib.tool.textextractor.TextExtractor;\n",
        "            import kr.dogfoot.hwplib.tool.textextractor.TextExtractMethod;\n",
        "            import java.io.File;\n",
        "\n",
        "            public class HwpTextExtractor {\n",
        "                public static void main(String[] args) {\n",
        "                    if (args.length < 1) {\n",
        "                        System.err.println(\"Usage: java HwpTextExtractor <hwp_file_path>\");\n",
        "                        System.exit(1);\n",
        "                    }\n",
        "                    // 수정: args 배열의 첫 번째 요소 사용\n",
        "                    String hwpFilePath = args[0];\n",
        "                    try {\n",
        "                        HWPFile hwpFile = HWPReader.fromFile(hwpFilePath);\n",
        "                        if (hwpFile != null) {\n",
        "                            // 수정: OnlyMainParagraph 옵션을 사용하여 텍스트 추출\n",
        "                            String extractedText = TextExtractor.extract(hwpFile, TextExtractMethod.OnlyMainParagraph);\n",
        "                            System.out.print(extractedText);\n",
        "                        }\n",
        "                    } catch (Exception e) {\n",
        "                        e.printStackTrace();\n",
        "                        System.exit(1);\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        \"\"\").strip()\n",
        "        os.makedirs(JAR_DIR, exist_ok=True)\n",
        "        if not HWPLIB_JAR_PATH.exists():\n",
        "            print(f\"INFO: hwplib JAR 파일 (버전 {HWPLIB_JAR_VERSION}) 다운로드...\")\n",
        "            try:\n",
        "                urllib.request.urlretrieve(HWPLIB_DOWNLOAD_URL, HWPLIB_JAR_PATH)\n",
        "                print(\"INFO: hwplib JAR 파일 다운로드 완료.\")\n",
        "            except Exception as e:\n",
        "                raise RuntimeError(f\"hwplib JAR 파일 다운로드 실패: {e}\")\n",
        "        if not JAVA_MAIN_CLASS_FILE.exists():\n",
        "            with open(JAVA_MAIN_CLASS_FILE, 'w', encoding='utf-8') as f:\n",
        "                f.write(JAVA_MAIN_CLASS_CODE)\n",
        "        class_output_dir = JAR_DIR\n",
        "        if not (class_output_dir / f\"{JAVA_MAIN_CLASS_NAME}.class\").exists():\n",
        "            print(\"INFO: 자바 클래스 컴파일...\")\n",
        "            try:\n",
        "                subprocess.run(\n",
        "                    [\"javac\", \"-cp\", os.fspath(HWPLIB_JAR_PATH), \"-d\", os.fspath(class_output_dir), os.fspath(JAVA_MAIN_CLASS_FILE)],\n",
        "                    check=True,\n",
        "                    text=True,\n",
        "                    encoding=\"utf-8\",\n",
        "                    capture_output=True\n",
        "                )\n",
        "                print(\"INFO: 자바 클래스 컴파일 완료.\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"컴파일 실패: stderr: {e.stderr}\")\n",
        "                raise RuntimeError(\"자바 소스 컴파일 실패. 소스코드, JDK 설치, 그리고 PATH 설정을 확인하세요.\")\n",
        "\n",
        "    def extract_text_with_hwplib(hwp_path):\n",
        "        \"\"\"hwplib(Java)를 사용하여 텍스트 추출\"\"\"\n",
        "        try:\n",
        "            setup_hwplib_java()\n",
        "            cmd = [\n",
        "                \"java\",\n",
        "                \"-cp\",\n",
        "                f\"{os.fspath(HWPLIB_JAR_PATH)}{os.pathsep}{os.fspath(JAR_DIR)}\",\n",
        "                JAVA_MAIN_CLASS_NAME,\n",
        "                os.fspath(hwp_path)\n",
        "            ]\n",
        "            result = subprocess.run(cmd, check=True, text=True, encoding=\"utf-8\", capture_output=True)\n",
        "            return result.stdout\n",
        "        except FileNotFoundError:\n",
        "            raise RuntimeError(\"Java 실행 파일을 찾을 수 없습니다. Java가 설치되어 있고 PATH에 추가되었는지 확인하세요.\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            raise RuntimeError(f\"hwplib 실행 실패 (오류 코드: {e.returncode}). stderr: {e.stderr}\")\n",
        "\n",
        "    try:\n",
        "        # 1. hwp5html 시도\n",
        "        subprocess.run(\n",
        "            [\"hwp5html\", \"--output\", os.fspath(path_html), \"--html\", os.fspath(path_hwp)],\n",
        "            check=True,\n",
        "            text=True,\n",
        "            encoding=\"utf-8\",\n",
        "            capture_output=True\n",
        "        )\n",
        "        print(\"hwp5html 변환 성공.\")\n",
        "        with open(path_html, \"r\", encoding=\"utf-8\") as f:\n",
        "            soup = BeautifulSoup(f, \"html.parser\")\n",
        "        return soup.body or soup\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # 2. hwplib 폴백 시도\n",
        "        print(f\"hwp5html 변환 실패 (오류 코드: {e.returncode}). stderr: {e.stderr}\")\n",
        "        print(f\"hwplib(Java)로 최종 대체합니다.\")\n",
        "        try:\n",
        "            text = extract_text_with_hwplib(hwp_path)\n",
        "            return BeautifulSoup(f\"<body><p>{text}</p></body>\", 'html.parser').body\n",
        "        except Exception as e:\n",
        "            print(f\"hwplib 처리 중 예상치 못한 오류 발생: {e}\")\n",
        "            raise e\n",
        "\n",
        "\n",
        "def load_hwp5html_easyocr(hwp_filename, metadata = {}, max_chars_per_page=1500, min_items_per_page=2):\n",
        "    \"\"\"\n",
        "    하이브리드 페이지 분리 규칙:\n",
        "    - 글자 수 누적이 max_chars_per_page를 넘으면 페이지 분리\n",
        "    - 제목(h1/h2/h3) 등장 시 페이지 분리\n",
        "    - 이미지 앞뒤로 페이지 분리\n",
        "    - 표도 글자 수에 포함\n",
        "    \"\"\"\n",
        "    def extract_table_md(table):\n",
        "        rows = []\n",
        "        for tr in table.find_all(\"tr\"):\n",
        "            cells = [c.get_text(strip=True) for c in tr.find_all([\"td\", \"th\"])]\n",
        "            if cells:\n",
        "                rows.append(cells)\n",
        "        if not rows:\n",
        "            return []\n",
        "        md = []\n",
        "        md.append(\"| \" + \" | \".join(rows[0]) + \" |\")\n",
        "        md.append(\"| \" + \" | \".join([\"---\"] * len(rows[0])) + \" |\")\n",
        "        for row in rows[1:]:\n",
        "            md.append(\"| \" + \" | \".join(row) + \" |\")\n",
        "        return md\n",
        "\n",
        "    TEMP_HTML_DIR = \"temp_hwp_html\"\n",
        "    hwp_path = f'files/{hwp_filename}'\n",
        "    output_path = f'outputs/{ext(hwp_filename)}'\n",
        "    if os.path.exists(output_path):\n",
        "        return load_pages(output_path)\n",
        "\n",
        "    # 1) HWP -> HTML\n",
        "    body = hwp_to_html(hwp_path, TEMP_HTML_DIR)\n",
        "\n",
        "    # 2) HTML 파싱 + 하이브리드 페이지 분리 + EasyOCR\n",
        "    reader = easyocr.Reader(['ko', 'en'], gpu=False)\n",
        "    md_lines = []\n",
        "    page_num = 1\n",
        "    char_count = 0\n",
        "    items_in_page = 0\n",
        "\n",
        "    def new_page():\n",
        "        nonlocal page_num, char_count, items_in_page\n",
        "        if items_in_page >= min_items_per_page:\n",
        "            md_lines.append(\"\")  # 페이지 끝 공백 줄\n",
        "            page_num += 1\n",
        "            md_lines.append(f\"## Page {page_num}\")\n",
        "            char_count = 0\n",
        "            items_in_page = 0\n",
        "\n",
        "    md_lines.append(f\"## Page {page_num}\")\n",
        "\n",
        "    for elem in body.descendants:\n",
        "        if isinstance(elem, Comment) or (isinstance(elem, NavigableString) and not str(elem).strip()):\n",
        "            continue\n",
        "        if not getattr(elem, \"name\", None):\n",
        "            continue\n",
        "\n",
        "        tag = elem.name.lower()\n",
        "\n",
        "        # 제목 등장 시 페이지 분리\n",
        "        if tag in [\"h1\", \"h2\", \"h3\"]:\n",
        "            new_page()\n",
        "            text = elem.get_text(\" \", strip=True)\n",
        "            if text:\n",
        "                md_lines.append(text)\n",
        "                char_count += len(text)\n",
        "                items_in_page += 1\n",
        "            continue\n",
        "\n",
        "        # 문단\n",
        "        if tag in [\"p\", \"li\"]:\n",
        "            text = elem.get_text(\" \", strip=True)\n",
        "            if text and not elem.find([\"table\", \"img\"]):\n",
        "                if char_count > max_chars_per_page:\n",
        "                    new_page()\n",
        "                md_lines.append(text)\n",
        "                char_count += len(text)\n",
        "                items_in_page += 1\n",
        "\n",
        "        # 표\n",
        "        if tag == \"table\":\n",
        "            tbl_md = extract_table_md(elem)\n",
        "            if tbl_md:\n",
        "                if char_count > max_chars_per_page:\n",
        "                    new_page()\n",
        "                md_lines.extend(tbl_md)\n",
        "                char_count += sum(len(\"\".join(r)) for r in tbl_md)\n",
        "                items_in_page += 1\n",
        "\n",
        "        # 이미지\n",
        "        if tag == \"img\":\n",
        "            src = elem.get(\"src\")\n",
        "            if src:\n",
        "                img_path = os.path.join(TEMP_HTML_DIR, os.path.basename(src))\n",
        "                if os.path.exists(img_path):\n",
        "                    # 이미지 앞에서 페이지 분리\n",
        "                    if char_count > max_chars_per_page:\n",
        "                        new_page()\n",
        "                    ocr_text = reader.readtext(img_path, detail=0)\n",
        "                    md_lines.append(f\"![{os.path.basename(img_path)}]({img_path})\")\n",
        "                    md_lines.append(\"\\n\".join(ocr_text) if ocr_text else \"_(인식된 텍스트 없음)_\")\n",
        "                    char_count += 50  # 이미지도 글자 수로 환산\n",
        "                    items_in_page += 1\n",
        "                    # 이미지 뒤에서 페이지 분리\n",
        "                    new_page()\n",
        "\n",
        "    pages = []\n",
        "    pages_raw = re.split(r'## Page \\d+\\s*', \"\\n\".join(md_lines).strip())\n",
        "    for page_text in pages_raw:\n",
        "        if page_text.strip():\n",
        "            pages.append(Document(page_content=page_text.strip(), metadata=metadata))\n",
        "    save_pages(pages, output_path)\n",
        "    return pages # \"\\n\".join(md_lines).strip()\n",
        "\n",
        "\n",
        "def load_documents(filename, metadata = {}):\n",
        "    def recursive_documents(documents):\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=150, separators=['\\n\\n', '\\n', ' ', ''], length_function=len)\n",
        "        documents = text_splitter.split_documents(documents)\n",
        "        return documents\n",
        "\n",
        "    _, ext = os.path.splitext(filename)\n",
        "    if ext.lower() == '.pdf':\n",
        "        documents = load_pymupdf4llm_easyocr(filename, metadata)\n",
        "    elif ext.lower() == '.hwp':\n",
        "        documents = load_hwp5html_easyocr(filename, metadata)\n",
        "    else:\n",
        "        print(f\"'{filename}'는 지원하지 않는 파일 형식입니다.\")\n",
        "\n",
        "    return recursive_documents(documents)\n"
      ],
      "metadata": {
        "id": "ADVhhRhsBqrc",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T05:14:15.498117Z",
          "iopub.execute_input": "2025-09-16T05:14:15.498480Z",
          "iopub.status.idle": "2025-09-16T05:14:15.530776Z",
          "shell.execute_reply.started": "2025-09-16T05:14:15.498458Z",
          "shell.execute_reply": "2025-09-16T05:14:15.530204Z"
        }
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요자료 다운로드"
      ],
      "metadata": {
        "id": "-Tj8nng49kFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download('1t9TWN25lsshk_tIXyh3Gx-NzfNAWRdeb', 'output.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "JFU0YE5T9mVj",
        "outputId": "1d99d1ad-5d0c-406d-cdf9-45dfd7eae9c8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T05:08:01.684778Z",
          "iopub.execute_input": "2025-09-16T05:08:01.685078Z",
          "iopub.status.idle": "2025-09-16T05:08:06.420914Z",
          "shell.execute_reply.started": "2025-09-16T05:08:01.685052Z",
          "shell.execute_reply": "2025-09-16T05:08:06.420221Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1t9TWN25lsshk_tIXyh3Gx-NzfNAWRdeb\n",
            "From (redirected): https://drive.google.com/uc?id=1t9TWN25lsshk_tIXyh3Gx-NzfNAWRdeb&confirm=t&uuid=6caa381d-be80-4f7d-9be9-306f2bf1f38f\n",
            "To: /content/output.zip\n",
            "100%|██████████| 212M/212M [00:02<00:00, 71.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] output.zip 다운로드 완료.\n",
            "[ok] output.zip 압축풀기 완료.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSV 파일 확인하기"
      ],
      "metadata": {
        "id": "DDSd0509A9aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_csv('data_list.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "NWPc-wBB9yEv",
        "outputId": "e302cb6e-c653-441b-e645-06f999eb47f1",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T04:04:21.556430Z",
          "iopub.execute_input": "2025-09-16T04:04:21.556696Z",
          "iopub.status.idle": "2025-09-16T04:04:21.613685Z",
          "shell.execute_reply.started": "2025-09-16T04:04:21.556678Z",
          "shell.execute_reply": "2025-09-16T04:04:21.612973Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] data_list.csv 로드 완료.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         공고 번호  공고 차수                                       사업명        사업 금액  \\\n",
              "0  20241001798    0.0  한영대학교 특성화 맞춤형 교육환경 구축 - 트랙운영 학사정보시스템 고도화  130000000.0   \n",
              "1  20241002912    0.0        2024년 대학산학협력활동 실태조사 시스템(UICC) 기능개선  129300000.0   \n",
              "2  20240827859    0.0                EIP3.0 고압가스 안전관리 시스템 구축 용역   40000000.0   \n",
              "3  20240430918    0.0                      도시계획위원회 통합관리시스템 구축용역  150000000.0   \n",
              "4  20240430896    0.0              봉화군 재난통합관리시스템 고도화 사업(협상)(긴급)  900000000.0   \n",
              "\n",
              "       발주 기관                공개 일자            입찰 참여 시작일            입찰 참여 마감일  \\\n",
              "0       한영대학  2024-10-04 13:51:23                  NaN  2024-10-15 17:00:00   \n",
              "1     한국연구재단  2024-10-04 15:01:52  2024-10-14 10:00:00  2024-10-16 14:00:00   \n",
              "2  한국생산기술연구원  2024-08-28 11:31:02  2024-08-29 09:00:00  2024-09-09 10:00:00   \n",
              "3      인천광역시  2024-04-18 16:26:32  2024-05-02 10:00:00  2024-05-09 16:00:00   \n",
              "4   경상북도 봉화군  2024-04-18 16:33:28  2024-04-26 09:00:00  2024-04-30 17:00:00   \n",
              "\n",
              "                                               사업 요약 파일형식  \\\n",
              "0  - 한영대학교 특성화 맞춤형 교육환경 구축을 위해 트랙운영 학사정보시스템을 고도화한...  hwp   \n",
              "1  - 사업 개요: 2024년 대학 산학협력활동 실태조사 시스템(UICC) 기능개선\\n...  hwp   \n",
              "2  - 사업 개요: EIP3.0 고압가스 안전관리 시스템 구축 용역\\n- 추진배경: 안...  hwp   \n",
              "3  - 사업명: 도시계획위원회 통합관리시스템 구축 용역\\n- 용역개요: 도시계획위원회와...  hwp   \n",
              "4  - 사업명: 봉화군 재난통합관리시스템 고도화 사업\\n- 사업개요: 공동수급(공동이행...  hwp   \n",
              "\n",
              "                                             파일명  \\\n",
              "0     한영대학_한영대학교 특성화 맞춤형 교육환경 구축 - 트랙운영 학사정보.hwp   \n",
              "1  한국연구재단_2024년 대학산학협력활동 실태조사 시스템(UICC) 기능개선.hwp   \n",
              "2       한국생산기술연구원_EIP3.0 고압가스 안전관리 시스템 구축 용역.hwp   \n",
              "3                 인천광역시_도시계획위원회 통합관리시스템 구축용역.hwp   \n",
              "4      경상북도 봉화군_봉화군 재난통합관리시스템 고도화 사업(협상)(긴급).hwp   \n",
              "\n",
              "                                                 텍스트  \n",
              "0      \\n \\n2024년 특성화 맞춤형 교육환경 구축 – 트랙운영 학사정보시스템 ...  \n",
              "1    \\r\\n \\r\\n \\r\\n  \\r\\n제 안 요 청 서\\r\\n[ 2024년 대학 ...  \n",
              "2      \\r\\n    \\r\\nEIP3.0 고압가스 안전관리\\r\\n시스템 구축 용역\\...  \n",
              "3    \\r\\n  \\r\\n \\r\\n도시계획위원회 통합관리시스템 구축\\r\\n제 안 요 청...  \n",
              "4        \\r\\n  \\r\\n \\r\\n제안요청서\\r\\n \\r\\n사 업 명\\r\\n봉화...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37a1ad2f-dfd0-4807-8b7a-69a929d510f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>공고 번호</th>\n",
              "      <th>공고 차수</th>\n",
              "      <th>사업명</th>\n",
              "      <th>사업 금액</th>\n",
              "      <th>발주 기관</th>\n",
              "      <th>공개 일자</th>\n",
              "      <th>입찰 참여 시작일</th>\n",
              "      <th>입찰 참여 마감일</th>\n",
              "      <th>사업 요약</th>\n",
              "      <th>파일형식</th>\n",
              "      <th>파일명</th>\n",
              "      <th>텍스트</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20241001798</td>\n",
              "      <td>0.0</td>\n",
              "      <td>한영대학교 특성화 맞춤형 교육환경 구축 - 트랙운영 학사정보시스템 고도화</td>\n",
              "      <td>130000000.0</td>\n",
              "      <td>한영대학</td>\n",
              "      <td>2024-10-04 13:51:23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2024-10-15 17:00:00</td>\n",
              "      <td>- 한영대학교 특성화 맞춤형 교육환경 구축을 위해 트랙운영 학사정보시스템을 고도화한...</td>\n",
              "      <td>hwp</td>\n",
              "      <td>한영대학_한영대학교 특성화 맞춤형 교육환경 구축 - 트랙운영 학사정보.hwp</td>\n",
              "      <td>\\n \\n2024년 특성화 맞춤형 교육환경 구축 – 트랙운영 학사정보시스템 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20241002912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2024년 대학산학협력활동 실태조사 시스템(UICC) 기능개선</td>\n",
              "      <td>129300000.0</td>\n",
              "      <td>한국연구재단</td>\n",
              "      <td>2024-10-04 15:01:52</td>\n",
              "      <td>2024-10-14 10:00:00</td>\n",
              "      <td>2024-10-16 14:00:00</td>\n",
              "      <td>- 사업 개요: 2024년 대학 산학협력활동 실태조사 시스템(UICC) 기능개선\\n...</td>\n",
              "      <td>hwp</td>\n",
              "      <td>한국연구재단_2024년 대학산학협력활동 실태조사 시스템(UICC) 기능개선.hwp</td>\n",
              "      <td>\\r\\n \\r\\n \\r\\n  \\r\\n제 안 요 청 서\\r\\n[ 2024년 대학 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20240827859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>EIP3.0 고압가스 안전관리 시스템 구축 용역</td>\n",
              "      <td>40000000.0</td>\n",
              "      <td>한국생산기술연구원</td>\n",
              "      <td>2024-08-28 11:31:02</td>\n",
              "      <td>2024-08-29 09:00:00</td>\n",
              "      <td>2024-09-09 10:00:00</td>\n",
              "      <td>- 사업 개요: EIP3.0 고압가스 안전관리 시스템 구축 용역\\n- 추진배경: 안...</td>\n",
              "      <td>hwp</td>\n",
              "      <td>한국생산기술연구원_EIP3.0 고압가스 안전관리 시스템 구축 용역.hwp</td>\n",
              "      <td>\\r\\n    \\r\\nEIP3.0 고압가스 안전관리\\r\\n시스템 구축 용역\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20240430918</td>\n",
              "      <td>0.0</td>\n",
              "      <td>도시계획위원회 통합관리시스템 구축용역</td>\n",
              "      <td>150000000.0</td>\n",
              "      <td>인천광역시</td>\n",
              "      <td>2024-04-18 16:26:32</td>\n",
              "      <td>2024-05-02 10:00:00</td>\n",
              "      <td>2024-05-09 16:00:00</td>\n",
              "      <td>- 사업명: 도시계획위원회 통합관리시스템 구축 용역\\n- 용역개요: 도시계획위원회와...</td>\n",
              "      <td>hwp</td>\n",
              "      <td>인천광역시_도시계획위원회 통합관리시스템 구축용역.hwp</td>\n",
              "      <td>\\r\\n  \\r\\n \\r\\n도시계획위원회 통합관리시스템 구축\\r\\n제 안 요 청...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20240430896</td>\n",
              "      <td>0.0</td>\n",
              "      <td>봉화군 재난통합관리시스템 고도화 사업(협상)(긴급)</td>\n",
              "      <td>900000000.0</td>\n",
              "      <td>경상북도 봉화군</td>\n",
              "      <td>2024-04-18 16:33:28</td>\n",
              "      <td>2024-04-26 09:00:00</td>\n",
              "      <td>2024-04-30 17:00:00</td>\n",
              "      <td>- 사업명: 봉화군 재난통합관리시스템 고도화 사업\\n- 사업개요: 공동수급(공동이행...</td>\n",
              "      <td>hwp</td>\n",
              "      <td>경상북도 봉화군_봉화군 재난통합관리시스템 고도화 사업(협상)(긴급).hwp</td>\n",
              "      <td>\\r\\n  \\r\\n \\r\\n제안요청서\\r\\n \\r\\n사 업 명\\r\\n봉화...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37a1ad2f-dfd0-4807-8b7a-69a929d510f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37a1ad2f-dfd0-4807-8b7a-69a929d510f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37a1ad2f-dfd0-4807-8b7a-69a929d510f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5de38bb9-2f00-42d5-b0ec-4a8ed18b25db\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5de38bb9-2f00-42d5-b0ec-4a8ed18b25db')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5de38bb9-2f00-42d5-b0ec-4a8ed18b25db button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"\\uacf5\\uace0 \\ubc88\\ud638\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 82,\n        \"samples\": [\n          \"20241138864\",\n          \"20241001798\",\n          \"20240523741\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uacf5\\uace0 \\ucc28\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3721726699209299,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc0ac\\uc5c5\\uba85\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"2025\\ub144 \\uc544\\uc774\\ub3cc\\ubd04\\uc778\\ub825 \\uc778\\uc801\\uc131 \\uac80\\uc0ac \\uc815\\ubcf4\\uc2dc\\uc2a4\\ud15c \\uc6b4\\uc601\",\n          \"2025\\ub144 \\ud1b5\\ud569\\uc811\\uc218\\uc2dc\\uc2a4\\ud15c \\uc6b4\\uc601\",\n          \"\\uc218\\ubb38\\uc790\\ub8cc\\uc815\\ubcf4\\uad00\\ub9ac\\uc2dc\\uc2a4\\ud15c(HDIMS) \\uc7ac\\uad6c\\ucd95 \\uc6a9\\uc5ed(3\\ub2e8\\uacc4)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc0ac\\uc5c5 \\uae08\\uc561\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1966690585.9237525,\n        \"min\": 0.0,\n        \"max\": 14107009000.0,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          70000000.0,\n          130000000.0,\n          977240000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ubc1c\\uc8fc \\uae30\\uad00\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 87,\n        \"samples\": [\n          \"\\ud55c\\uad6d\\uc218\\ucd9c\\uc785\\uc740\\ud589\",\n          \"\\ud55c\\uc601\\ub300\\ud559\",\n          \"\\ub300\\ud55c\\uc7a5\\uc560\\uc778\\uccb4\\uc721\\ud68c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uacf5\\uac1c \\uc77c\\uc790\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"2024-12-10 17:43:31\",\n          \"2024-11-27 10:51:02\",\n          \"2024-04-04 18:31:59\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc785\\ucc30 \\ucc38\\uc5ec \\uc2dc\\uc791\\uc77c\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-02-21 10:00:00\",\n        \"max\": \"2025-02-11 14:00:00\",\n        \"num_unique_values\": 73,\n        \"samples\": [\n          \"2025-01-08 14:30:00\",\n          \"2024-03-20 09:00:00\",\n          \"2025-02-06 10:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc785\\ucc30 \\ucc38\\uc5ec \\ub9c8\\uac10\\uc77c\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 87,\n        \"samples\": [\n          \"2024-04-09 15:00:00\",\n          \"2024-10-15 17:00:00\",\n          \"2024-06-11 10:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc0ac\\uc5c5 \\uc694\\uc57d\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"- \\uc0ac\\uc5c5 \\uac1c\\uc694: \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc2dc\\uc2a4\\ud15c \\uad6c\\ucd95\\n- \\ucd94\\uc9c4\\ubc30\\uacbd: \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c \\uacfc\\uc815\\uc758 \\ubd88\\ud3b8\\uacfc \\ube44\\ud6a8\\uc728\\uc131 \\uac1c\\uc120 \\ud544\\uc694\\uc131\\n- \\uc0ac\\uc5c5\\ubc94\\uc704: \\uc804\\uad6d \\uc694\\uc591\\uae30\\uad00\\uacfc \\ubcf4\\ud5d8\\uc0ac \\uc5f0\\uacc4 \\uc2dc\\uc2a4\\ud15c \\uad6c\\ucd95\\n- \\uae30\\ub300\\ud6a8\\uacfc: \\ubcf4\\ud5d8\\uac00\\uc785\\uc790\\uc758 \\ud3b8\\uc758 \\uc99d\\ub300, \\uc885\\uc774\\uc11c\\ub958 \\uc0ac\\uc6a9 \\uc808\\uac10, \\uccad\\uad6c\\uc728 \\uc99d\\uac00\\n- \\ucd94\\uc9c4\\ubaa9\\ud45c: \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uacfc\\uc815\\uc758 \\uc804\\uc0b0\\ud654\\ub97c \\ud1b5\\ud55c \\ud6a8\\uc728\\uc801\\uc778 \\ubcf4\\ud5d8\\uae08 \\uc9c0\\uae09 \\ud504\\ub85c\\uc138\\uc2a4 \\uad6c\\ucd95\",\n          \"- \\uc0ac\\uc5c5 \\uac1c\\uc694: \\ud1b5\\ud569\\uc815\\ubcf4\\uc2dc\\uc2a4\\ud15c \\uace0\\ub3c4\\ud654 \\uc6a9\\uc5ed\\uc73c\\ub85c \\uae30\\uad00\\uc0dd\\uba85\\uc724\\ub9ac, \\ub3d9\\ubb3c\\uc2e4\\ud5d8\\uc724\\ub9ac, \\uad6d\\uac00\\uc5f0\\uad6c\\uac1c\\ubc1c\\uc0ac\\uc5c5 \\uc5f0\\uad6c\\ube44 \\uc0ac\\uc6a9\\uae30\\uc900 \\uc900\\uc218, \\uae30\\ub2a5\\uac1c\\uc120 \\ub4f1\\uc758 \\uc0ac\\uc5c5 \\ubc94\\uc704\\ub97c \\ud3ec\\ud568\\ud55c\\ub2e4.\\n- \\ucd94\\uc9c4\\ubc30\\uacbd: \\uae30\\uad00\\uc758 \\uc5c5\\ubb34 \\ud504\\ub85c\\uc138\\uc2a4 \\uad6c\\ucd95 \\ubc0f \\uac1c\\uc120, \\ud1b5\\ud569\\uc815\\ubcf4\\uc2dc\\uc2a4\\ud15c \\uace0\\ub3c4\\ud654\\uc758 \\ud544\\uc694\\uc131\\uc5d0 \\uae30\\uc778\\ud55c\\ub2e4.\\n- \\uc0ac\\uc5c5\\ubc94\\uc704: \\uae30\\uad00\\uc0dd\\uba85\\uc724\\ub9ac, \\ub3d9\\ubb3c\\uc2e4\\ud5d8\\uc724\\ub9ac, \\uad6d\\uac00\\uc5f0\\uad6c\\uac1c\\ubc1c\\uc0ac\\uc5c5 \\uc5f0\\uad6c\\ube44 \\uc0ac\\uc6a9\\uae30\\uc900 \\uc900\\uc218, \\uc5f0\\uad6c\\uacc4\\ud68d \\uad00\\ub9ac, \\uc804\\uc790\\uacb0\\uc7ac\\uc11c\\uc2dd \\uc5f0\\ub3d9, \\uae30\\ub2a5\\uac1c\\uc120 \\ub4f1\\uc758 \\uc5c5\\ubb34\\ub97c \\ud3ec\\ud568\\ud55c\\ub2e4.\\n- \\uae30\\ub300\\ud6a8\\uacfc: \\uc5c5\\ubb34 \\ud6a8\\uc728\\uc131 \\ud5a5\\uc0c1, \\uc790\\ub8cc \\uad00\\ub9ac \\ubc0f \\uacf5\\uc720\\uc758 \\ud3b8\\ub9ac\\uc131, \\uc0ac\\uc6a9\\uc790 \\ud3b8\\uc758\\uc131\\uc744 \\uace0\\ub824\\ud55c \\uc2dc\\uc2a4\\ud15c \\uad6c\\ud604 \\ub4f1\\uc774 \\uc608\\uc0c1\\ub41c\\ub2e4.\\n- \\ucd94\\uc9c4\\ubaa9\\ud45c: \\uae30\\uad00\\uc758 \\uc5c5\\ubb34 \\ud504\\ub85c\\uc138\\uc2a4 \\uad6c\\ucd95 \\ubc0f \\uac1c\\uc120, \\ud1b5\\ud569\\uc815\\ubcf4\\uc2dc\\uc2a4\\ud15c \\uace0\\ub3c4\\ud654\\ub97c \\ud1b5\\ud574 \\uc5c5\\ubb34 \\ud6a8\\uc728\\uc131\\uc744 \\ud5a5\\uc0c1\\uc2dc\\ud0a4\\ub294 \\uac83\\uc774 \\ubaa9\\ud45c\\uc774\\ub2e4.\",\n          \"- \\uc0ac\\uc5c5 \\uac1c\\uc694: \\ucca0\\ub3c4\\uc778\\ud504\\ub77c \\ub514\\uc9c0\\ud138\\ud2b8\\uc708 \\uc815\\ubcf4\\ud654\\uc804\\ub7b5\\uacc4\\ud68d(ISP) \\uc218\\ub9bd\\n- \\ucd94\\uc9c4\\ubc30\\uacbd: \\ub514\\uc9c0\\ud138\\ud2b8\\uc708 \\uae30\\uc220\\uc744 \\ud1b5\\ud574 \\ucca0\\ub3c4 \\uc0dd\\uc560\\uc8fc\\uae30\\uc758 \\ub370\\uc774\\ud130 \\uc911\\uc2ec \\uc758\\uc0ac\\uacb0\\uc815, \\ucca0\\ub3c4 \\uc0b0\\uc5c5 \\uc0dd\\ud0dc\\uacc4 \\ud65c\\uc131\\ud654 \\ud544\\uc694\\n- \\uc0ac\\uc5c5\\ubc94\\uc704: \\uad6d\\ub0b4\\uc678 \\ub514\\uc9c0\\ud138\\ud2b8\\uc708 \\ud604\\ud669 \\ubc0f \\ud658\\uacbd \\ubd84\\uc11d, \\ud45c\\uc900\\uc815\\ubcf4\\uccb4\\uacc4 \\uad6c\\ucd95 \\ubc29\\uc548, \\uacf5\\ub2e8 \\ub808\\uac70\\uc2dc \\uc2dc\\uc2a4\\ud15c \\uc5f0\\uacc4\\uc131 \\ub3c4\\ucd9c, \\ud50c\\ub7ab\\ud3fc \\uad6c\\ucd95 \\ubc29\\uc548, \\uacbd\\uc601\\uc804\\ub7b5 \\ubc0f \\uc911\\uc7a5\\uae30 \\ub85c\\ub4dc\\ub9f5 \\uc218\\ub9bd\\n- \\uae30\\ub300\\ud6a8\\uacfc: \\ucd08\\uc5f0\\uacb0 \\uc2a4\\ub9c8\\ud2b8 \\ucca0\\ub3c4 \\uad6c\\ucd95, \\ucca0\\ub3c4 \\uc778\\ud504\\ub77c \\uacbd\\uc601 \\ud601\\uc2e0, \\uc720\\uc9c0\\ubcf4\\uc218 \\ud6a8\\uc728\\uc131 \\uc81c\\uace0, \\uc138\\uacc4 \\ucca0\\ub3c4\\uc2dc\\uc7a5 \\uc9c4\\ucd9c\\n- \\ucd94\\uc9c4\\ubaa9\\ud45c: \\ucee8\\uc124\\ud305, \\ub370\\uc774\\ud130, \\ubcf4\\uc548, \\ud488\\uc9c8, \\uc81c\\uc57d\\uc0ac\\ud56d, \\ud504\\ub85c\\uc81d\\ud2b8 \\uad00\\ub9ac \\uc694\\uad6c\\uc0ac\\ud56d \\uc218\\ud589\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud30c\\uc77c\\ud615\\uc2dd\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"pdf\",\n          \"hwp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud30c\\uc77c\\uba85\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"\\uc0ac\\ub2e8\\ubc95\\uc778 \\ubcf4\\ud5d8\\uac1c\\ubc1c\\uc6d0_\\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc2dc\\uc2a4\\ud15c \\uad6c\\ucd95 \\uc0ac\\uc5c5.hwp\",\n          \"\\ud55c\\uad6d\\ud55c\\uc758\\ud559\\uc5f0\\uad6c\\uc6d0_\\ud1b5\\ud569\\uc815\\ubcf4\\uc2dc\\uc2a4\\ud15c \\uace0\\ub3c4\\ud654 \\uc6a9\\uc5ed.hwp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud14d\\uc2a4\\ud2b8\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"    \\r\\n \\r\\n\\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc2dc\\uc2a4\\ud15c \\uad6c\\ucd95\\r\\n\\uc81c\\uc548\\uc694\\uccad\\uc11c\\r\\n>\\r\\n2024. 3 \\r\\n \\r\\n     \\r\\n\\ubaa9   \\ucc28\\r\\n\\u2160. \\uc0ac\\uc5c5 \\uac1c\\uc694\\r\\n   1. \\uac1c\\uc694 \\t  -   \\t 2\\r\\n   2. \\ucd94\\uc9c4\\ubc30\\uacbd \\ubc0f \\ud544\\uc694\\uc131\\t  -   \\t 2\\r\\n   3. \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc2dc\\uc2a4\\ud15c \\uac1c\\uc694\\t  -   \\t 3\\r\\n   4. \\uc0ac\\uc5c5 \\uc218\\ud589 \\ub300\\uc0c1\\t  -   \\t 4\\r\\n   5. \\uae30\\ub300\\ud6a8\\uacfc\\t  -   \\t 5\\r\\n\\u2161. \\uc5c5\\ubb34 \\ud604\\ud669\\r\\n   1. \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\ud604\\ud669\\t  -   \\t 6\\r\\n   2. \\ubb38\\uc81c\\uc810\\t  -   \\t10\\r\\n\\u2162. \\uc0ac\\uc5c5\\ucd94\\uc9c4\\uccb4\\uacc4 \\ubc0f \\uc77c\\uc815\\r\\n   1. \\ucd94\\uc9c4 \\ubc29\\ud5a5\\t  -   \\t11\\r\\n   2. \\uc0ac\\uc5c5\\ucd94\\uc9c4\\uccb4\\uacc4\\t  -   \\t11\\r\\n   3. \\ucd94\\uc9c4 \\uc77c\\uc815\\t  -   \\t 12\\r\\n\\u2163. \\uc81c\\uc548 \\uc694\\uccad \\ub0b4\\uc6a9\\r\\n   1. \\ubaa9\\ud45c \\uc5c5\\ubb34\\ud504\\ub85c\\uc138\\uc2a4\\t  -   \\t 13\\r\\n   2. \\ubaa9\\ud45c\\uc2dc\\uc2a4\\ud15c \\uac1c\\ub150\\ub3c4\\t  -   \\t 17\\r\\n   3. \\uacfc\\uc5c5\\ub300\\uc0c1 \\ubc94\\uc704\\t  -   \\t 19\\r\\n   4. \\uc0c1\\uc138\\uc694\\uad6c \\uc0ac\\ud56d\\t  -   \\t 24\\r\\n\\u2164. \\uc81c\\uc548\\uc11c \\uc791\\uc131 \\uc548\\ub0b4\\r\\n   1. \\uc81c\\uc548\\uc11c \\ud6a8\\ub825\\t  -   \\t 90\\r\\n   2. \\uc81c\\uc548\\uc11c \\uc791\\uc131 \\uad8c\\uace0 \\uc0ac\\ud56d\\t  -   \\t 90\\r\\n   3. \\uc720\\uc758\\uc0ac\\ud56d\\t  -   \\t 91\\r\\n   3. \\uc81c\\uc548\\uc11c \\ubaa9\\ucc28 \\ubc0f \\uc138\\ubd80 \\uc791\\uc131 \\ubc29\\ubc95\\t  -   \\t 93\\r\\n\\u2165. \\uc81c\\uc548 \\uc548\\ub0b4 \\uc0ac\\ud56d\\r\\n   1. \\uc785\\ucc30 \\ucc38\\uac00 \\uc790\\uaca9\\t  -   \\t 95\\r\\n   2. \\uc81c\\ucd9c \\uc11c\\ub958\\t  -   \\t 95\\r\\n   3. \\uc81c\\uc548 \\uc124\\uba85\\ud68c\\t  -   \\t 96\\r\\n\\u2166. \\uc81c\\uc548\\uc11c \\ud3c9\\uac00\\ubc29\\ubc95\\r\\n   1. \\ud3c9\\uac00 \\ubc29\\ubc95\\t  -   \\t 97\\r\\n   2. \\ud3c9\\uac00 \\uae30\\uc900\\t  -   \\t 98\\r\\n   3. \\ub099\\ucc30\\uc790 \\uacb0\\uc815\\ubc29\\ubc95\\t  -   \\t 102\\r\\n   \\r\\n  [\\ubd99\\uc7841] \\uc678\\uc8fc\\uc6a9\\uc5ed\\uc0ac\\uc5c5 \\ubcf4\\uc548\\ud2b9\\uc57d\\t  -   \\t 103\\r\\n  [\\ubd99\\uc7842] \\uc81c\\ucd9c\\uc11c\\uc2dd   \\t  -   \\t 106\\r\\n \\r\\n \\r\\n\\u2160\\r\\n  \\uc0ac\\uc5c5 \\uac1c\\uc694\\r\\n1. \\uac1c\\uc694\\r\\n   \\uc0ac \\uc5c5 \\uba85 : \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc2dc\\uc2a4\\ud15c \\uad6c\\ucd95\\r\\n   \\uc0ac\\uc5c5\\uae30\\uac04 : \\uacc4\\uc57d\\uc77c\\ub85c\\ubd80\\ud130 19\\uac1c\\uc6d4\\r\\n    \\u203b 1\\ucc28: \\u201924\\ub144 4\\uc6d4~10\\uc6d4 25\\uc77c, 2\\ucc28: \\u201924\\ub144 10\\uc6d4~\\u201925\\ub144 10\\uc6d4 25\\uc77c\\r\\n   \\uacc4\\uc57d\\ubc29\\uc2dd : \\uc77c\\ubc18\\uacbd\\uc7c1\\uc785\\ucc30, \\ud611\\uc0c1\\uc5d0 \\uc758\\ud55c \\uacc4\\uc57d\\r\\n  \\u203b \\ubcf8 \\uc81c\\uc548\\uc694\\uccad\\uc11c\\uc5d0\\uc11c\\ub294 \\uc0ac\\uc5c5\\uc608\\uc0b0\\uc774 \\ud3ec\\ud568\\ub418\\uc9c0 \\uc54a\\uc74c\\r\\n2. \\ucd94\\uc9c4\\ubc30\\uacbd \\ubc0f \\ud544\\uc694\\uc131\\r\\n   \\uc2e4\\uc190\\ubcf4\\ud5d8\\uc740 \\uad6d\\ubbfc\\uac74\\uac15\\ubcf4\\ud5d8\\uc758 \\ubcf4\\uc644\\ud615\\uc73c\\ub85c \\ub3c4\\uc785\\ub418\\uc5b4 \\u201923\\ub144\\ub9d0 \\uad6d\\ubbfc \\uc57d 4\\ucc9c\\ub9cc\\uba85\\uc774 \\uac00\\uc785\\ud55c \\uc77c\\uc0c1\\uc0dd\\ud65c\\uc5d0 \\ud544\\uc218\\uc801\\uc778 \\ubcf4\\ud5d8\\uc0c1\\ud488\\uc73c\\ub85c \\uc131\\uc7a5\\ud568\\r\\n  o \\uc5f0\\uac04 \\uc57d 1\\uc5b5\\uac74\\uc744 \\ucd08\\uacfc\\ud558\\ub294 \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc640 \\uc9c0\\uae09\\uc774 \\uc774\\ub8e8\\uc5b4\\uc9c0\\uace0 \\uc788\\uc73c\\ub098 \\ubcf5\\uc7a1\\ud55c \\uc808\\ucc28*\\ub85c \\uc778\\ud55c \\uc18c\\ube44\\uc790 \\ubd88\\ud3b8\\uc774 \\uacc4\\uc18d \\ubb38\\uc81c\\uc810\\uc73c\\ub85c \\uc9c0\\uc801\\ub428\\r\\n \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc11c\\ub958 \\ud655\\uc778 \\u2192  \\uc694\\uc591\\uae30\\uad00\\uc5d0 \\uc11c\\ub958\\ubc1c\\uae09 \\uc2e0\\uccad \\u2192  \\uc11c\\ub958\\uc218\\ub839 \\u2192  \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc11c \\uc791\\uc131 \\u2192  \\uc11c\\ub958\\uc81c\\ucd9c \\u2192  \\ubcf4\\ud5d8\\uae08 \\uc9c0\\uae09 \\uc2ec\\uc0ac \\u2192  \\ubcf4\\ud5d8\\uae08 \\uc218\\ub839\\r\\n  o \\ub610\\ud55c, \\uc9c4\\ub8cc\\ube44 \\uc601\\uc218\\uc99d \\ub4f1 \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc5d0 \\ud544\\uc694\\ud55c \\uc218\\uc5b5\\uc7a5\\uc758 \\uc885\\uc774\\uc11c\\ub958\\ub97c \\ubc1c\\uae09\\ud558\\uace0 \\ucc98\\ub9ac\\ud558\\ub294\\ub370 \\uc0ac\\ud68c\\uc801 \\ube44\\uc6a9\\uc774 \\ub0ad\\ube44\\ub428\\r\\n   \\uc774\\uc5d0 \\uc815\\ubd80\\ub294 \\uc18c\\ube44\\uc790\\uac00 \\uc804\\uc1a1\\ub300\\ud589\\uae30\\uad00\\uc744 \\ud1b5\\ud574 One-Stop\\uc73c\\ub85c \\uc2e4\\uc190\\ubcf4\\ud5d8\\uc804\\uc0b0\\uccad\\uad6c(\\uc774\\ud558 \\u2018\\uccad\\uad6c \\uc804\\uc0b0\\ud654\\u2019)\\uac00 \\uac00\\ub2a5\\ud558\\ub3c4\\ub85d \\ubcf4\\ud5d8\\uc5c5\\ubc95\\uc744 \\uac1c\\uc815* \\r\\n\\u201923.10.24 \\uacf5\\ud3ec \\u2192 \\u201924.10.25 \\ubcd1\\uc6d0\\uae09 \\uc2dc\\ud589(1\\ub2e8\\uacc4) \\u2192 \\u201925.10.25 \\uc758\\uc6d0 \\ubc0f \\uc57d\\uad6d \\uc2dc\\ud589(2\\ub2e8\\uacc4)\\r\\n  o \\uc774\\ubc88 \\uac1c\\uc815 \\ubc95\\ub960\\uc740 \\uc694\\uc591\\uae30\\uad00\\uacfc \\ubcf4\\ud5d8\\uc0ac \\uac04 \\uc804\\uc1a1\\ub300\\ud589\\uae30\\uad00\\uc744 \\ub450\\uace0 \\uccad\\uad6c \\uc804\\uc0b0\\ud654\\ub97c \\uad6c\\ud604\\ud558\\ub294 \\uac83\\uc73c\\ub85c \\ubcc4\\ub3c4 \\uc2dc\\uc2a4\\ud15c \\uad6c\\ucd95\\uc744 \\ud544\\uc694\\ub85c \\ud558\\uace0 \\uc788\\uc74c\\r\\n3. \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc2dc\\uc2a4\\ud15c \\uac1c\\uc694\\r\\n   \\ucc38\\uc5ec\\uae30\\uad00 : \\uc804\\uad6d \\uc694\\uc591\\uae30\\uad00(\\ubcd1\\uc758\\uc6d0 \\ubc0f \\uc57d\\uad6d), \\uc2e4\\uc190\\ubcf4\\ud5d8\\uacc4\\uc57d\\uc744 \\ubcf4\\uc720 \\ub610\\ub294 \\ubcf4\\uc720\\uc608\\uc815\\uc778 \\ubcf4\\ud5d8\\uc0ac\\r\\n \\r\\n \\r\\n\\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc2dc\\uc2a4\\ud15c \\uac1c\\ub150\\ub3c4\\r\\n   \\uc8fc\\uc694\\uae30\\ub2a5\\r\\n   o \\uc9c4\\ub8cc\\ub97c \\ubc1b\\uc740 \\ubcf4\\ud5d8\\uac00\\uc785\\uc790\\uc758 \\uc694\\uccad\\uc5d0 \\ub530\\ub77c \\uc694\\uc591\\uae30\\uad00\\uc5d0\\uc11c \\ubcf4\\ud5d8\\uc0ac\\ub85c \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c \\ud544\\uc694\\uc11c\\ub958\\ub97c \\uc804\\uc790\\uc801 \\ubc29\\ubc95\\uc73c\\ub85c \\uc804\\uc1a1\\r\\n   o \\uc804\\uc1a1\\ub300\\ud589\\uae30\\uad00\\uc740 \\uc694\\uc591\\uae30\\uad00\\uc73c\\ub85c\\ubd80\\ud130 \\uc804\\uc790\\ubb38\\uc11c\\ub97c \\uc218\\uc2e0\\ubc1b\\uc544 \\uac00\\uc785\\ubcf4\\ud5d8\\uc0ac\\ub85c \\uc804\\ub2ec\\r\\n   o \\uc694\\uc591\\uae30\\uad00\\uc758 \\uc11c\\ub958\\ub97c \\ubcf4\\ud5d8\\uc0ac\\uc5d0\\uc11c \\ud655\\uc778\\uc774 \\uac00\\ub2a5\\ud1a0\\ub85d \\ud45c\\uc900\\ud654\\ub41c \\ub808\\uc774\\uc544\\uc6c3\\uc73c\\ub85c \\ubcc0\\ud658 \\uc0ac\\uc6a9, \\uc804\\uc1a1\\ub418\\ub294 \\uc804\\uc790\\ubb38\\uc11c\\ub294 \\uc554\\ud638\\ud654\\ub418\\uc5b4\\uc57c \\ud568\\r\\n   \\uc774\\uc288\\uc0ac\\ud56d\\r\\n   o \\uc694\\uc591\\uae30\\uad00 \\uc815\\ubcf4\\uc2dc\\uc2a4\\ud15c\\uc5d0 \\ub300\\ud55c \\uc218\\uc815\\uc774 \\ud544\\uc694\\ud568, \\uc790\\uccb4 \\uc2dc\\uc2a4\\ud15c\\uc744 \\ubcf4\\uc720\\ud55c \\uc77c\\ubd80 \\ub300\\ud615\\ubcd1\\uc6d0\\uc744 \\uc81c\\uc678\\ud558\\uace0\\ub294 EMR\\uc5c5\\uccb4\\uc758 \\uc0c1\\uc6a9 \\uc18c\\ud504\\ud2b8\\uc6e8\\uc5b4\\ub97c \\uc0ac\\uc6a9\\ud568\\r\\n4. \\uc0ac\\uc5c5 \\uc218\\ud589 \\ub300\\uc0c1\\r\\n   \\uc694\\uc591\\uae30\\uad00 \\ud655\\uc0b0 \\uacc4\\ud68d\\r\\n      o \\uc694\\uc591\\uae30\\uad00\\uacfc\\uc758 \\uc5f0\\uacc4\\ub294 \\uc0ac\\uc6a9 \\uc911\\uc778 EMR \\uc2dc\\uc2a4\\ud15c\\uc744 \\ud1b5\\ud558\\uba70, \\u201924\\ub144 10.25\\uc77c \\uc2dc\\ud589\\ub418\\ub294 1\\ub2e8\\uacc4 \\uc5f0\\uacc4 \\ub300\\uc0c1\\uc740 \\ubcd1\\uc6d0 7,725\\uac1c, \\u201925\\ub144 10.25\\uc77c \\uc2dc\\ud589\\ub418\\ub294 2\\ub2e8\\uacc4 \\uc5f0\\uacc4 \\ub300\\uc0c1\\uc740 \\uc758\\uc6d0\\uacfc \\uc57d\\uad6d\\uc73c\\ub85c 93,472\\uac1c \\uc694\\uc591\\uae30\\uad00\\uc73c\\ub85c \\ud655\\uc0b0 \\uc6b4\\uc601\\ud560 \\uacc4\\ud68d\\r\\n2\\ub2e8\\uacc4 (\\u201925.10.25)\\r\\n\\uad6c\\ubd84\\r\\n\\uc694\\uc591\\uae30\\uad00 \\uc218\\r\\n\\uc758\\uc6d0\\r\\n35,766\\r\\n\\ud55c\\uc758\\uc6d0\\r\\n14,606\\r\\n\\uce58\\uacfc\\uc758\\uc6d0\\r\\n19,039\\r\\n\\uc57d\\uad6d\\r\\n24,061\\r\\n\\ud569\\uacc4\\r\\n93,472\\r\\n1\\ub2e8\\uacc4 (\\u201924.10.25)\\r\\n\\uad6c\\ubd84\\r\\n\\uc694\\uc591\\uae30\\uad00 \\uc218\\r\\n\\uc0c1\\uae09\\uc885\\ud569\\ubcd1\\uc6d0\\r\\n47\\r\\n\\uc885\\ud569\\ubcd1\\uc6d0\\r\\n331\\r\\n\\ubcd1\\uc6d0\\r\\n1,402\\r\\n\\uc694\\uc591\\ubcd1\\uc6d0\\r\\n1,396\\r\\n\\uc815\\uc2e0\\ubcd1\\uc6d0\\r\\n257\\r\\n\\uce58\\uacfc\\ubcd1\\uc6d0\\r\\n240\\r\\n\\ud55c\\ubc29\\ubcd1\\uc6d0\\r\\n562\\r\\n\\ubcf4\\uac74\\uc18c \\ub4f1\\r\\n3,490\\r\\n\\ud569\\uacc4\\r\\n7,725\\r\\n \\r\\n \\u203b \\uc694\\uc591\\uae30\\uad00 \\ud1b5\\uacc4 \\ucd9c\\ucc98: HIRA\\ube45\\ub370\\uc774\\ud130\\uac1c\\ubc29\\ud3ec\\ud138 > \\uacf5\\uacf5\\ub370\\uc774\\ud130 > \\uacf5\\uacf5\\ub370\\uc774\\ud130 \\ubaa9\\ub85d > \\u201c\\uc804\\uad6d \\ubcd1\\uc758\\uc6d0 \\ubc0f \\uc57d\\uad6d \\ud604\\ud669\\u201d\\r\\n   1\\ub2e8\\uacc4 \\uad6c\\ucd95 \\ub300\\uc0c1: \\ubcd1\\uc0c1 30\\uac1c \\uc774\\uc0c1 7\\ucc9c\\uc5ec \\uac1c \\uc694\\uc591\\uae30\\uad00\\r\\n   o \\uae30\\uac04: \\u201924.04\\u223c\\u201924.10.25\\r\\n   2\\ub2e8\\uacc4 \\uad6c\\ucd95 \\ub300\\uc0c1: \\uc758\\uc6d0 \\ubc0f \\uc57d\\uad6d 9.3\\ub9cc \\uac1c\\r\\n   o \\uae30\\uac04: \\u201924.11\\u223c\\u201925.10.25\\r\\n\\u203b 2\\ub2e8\\uacc4 \\uad6c\\ucd95 \\uc0ac\\uc5c5\\uc758 \\uacbd\\uc6b0, 1\\ucc28 \\uc0ac\\uc5c5 \\uc9c4\\ud589 \\uacbd\\uacfc\\ub97c \\uace0\\ub824\\ud558\\uc5ec \\uc77c\\uc815\\uc774 \\uc870\\uc815\\ub420 \\uc218 \\uc788\\uc74c\\r\\n   (\\ucc38\\uace0\\uc790\\ub8cc) \\r\\n  o (\\ubcf4\\ud5d8\\uc0ac) \\uc2e4\\uc190\\ubcf4\\ud5d8\\uacc4\\uc57d\\uc744 \\ubcf4\\uc720 \\ub610\\ub294 \\ubcf4\\uc720\\uc608\\uc815\\uc778 \\ubcf4\\ud5d8\\uc0ac\\ub294 \\uc190\\ud574\\ubcf4\\ud5d8\\uc0ac 17\\uac1c, \\uc0dd\\uba85\\ubcf4\\ud5d8\\uc0ac 16\\uac1c\\r\\n \\r\\n\\uc2e4\\uc190\\ubcf4\\ud5d8\\uacc4\\uc57d \\ubcf4\\uc720 \\ub610\\ub294 \\ubcf4\\uc720\\uc608\\uc815 \\ubcf4\\ud5d8\\uc0ac\\r\\n\\uc190\\ud574\\ubcf4\\ud5d8\\uc0ac\\r\\n\\uc0dd\\uba85\\ubcf4\\ud5d8\\uc0ac\\r\\n1\\r\\n\\uba54\\ub9ac\\uce20\\ud654\\uc7ac\\ud574\\uc0c1\\ubcf4\\ud5d8\\r\\n1\\r\\n\\ud55c\\ud654\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n2\\r\\n\\ud55c\\ud654\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n2\\r\\nABL\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n3\\r\\n\\ub86f\\ub370\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n3\\r\\n\\uc0bc\\uc131\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n4\\r\\nMG\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n4\\r\\n\\ud765\\uad6d\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n5\\r\\n\\ud765\\uad6d\\ud654\\uc7ac\\ud574\\uc0c1\\ubcf4\\ud5d8\\r\\n5\\r\\n\\uad50\\ubcf4\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n6\\r\\n\\uc0bc\\uc131\\ud654\\uc7ac\\ud574\\uc0c1\\ubcf4\\ud5d8\\r\\n6\\r\\n\\uc2e0\\ud55c\\ub77c\\uc774\\ud504\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n7\\r\\n\\ud604\\ub300\\ud574\\uc0c1\\ud654\\uc7ac\\ubcf4\\ud5d8\\r\\n7\\r\\n\\ud478\\ubcf8\\ud604\\ub300\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n8\\r\\nKB\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n8\\r\\nKB\\ub77c\\uc774\\ud504\\uc0dd\\uba85\\r\\n9\\r\\nDB\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n9\\r\\nDGB\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n10\\r\\nAXA\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n10\\r\\nKDB\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n11\\r\\n\\ud558\\ub098\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n11\\r\\n\\ubbf8\\ub798\\uc5d0\\uc14b\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n12\\r\\nAIG\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n12\\r\\nNH\\ub18d\\ud611\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n13\\r\\n\\uc5d0\\uc774\\uc2a4\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n13\\r\\n\\ub77c\\uc774\\ub098\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n14\\r\\n\\uce90\\ub86f\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n14\\r\\nAIA\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n15\\r\\nNH\\ub18d\\ud611\\uc190\\ud574\\ubcf4\\ud5d8\\r\\n15\\r\\nDB\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n16\\r\\n\\uc2e0\\ud55cEZ\\uc190\\ud574\\ubcf4\\ud5d8 (\\ubcf4\\uc720\\uc608\\uc815)\\r\\n16\\r\\n\\ub3d9\\uc591\\uc0dd\\uba85\\ubcf4\\ud5d8\\r\\n17\\r\\n\\uce74\\uce74\\uc624\\ud398\\uc774\\uc190\\ud574\\ubcf4\\ud5d8 (\\ubcf4\\uc720\\uc608\\uc815)\\r\\n\\ucd1d 33\\uac1c \\ubcf4\\ud5d8\\uc0ac \\r\\n5. \\uae30\\ub300\\ud6a8\\uacfc\\r\\n   \\uc2e4\\uc190\\ubcf4\\ud5d8 \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c \\uc804\\uc0b0\\ud654\\uc5d0 \\ub530\\ub978 \\ubcf4\\ud5d8\\uac00\\uc785\\uc790\\uc758 \\ud3b8\\uc775 \\uc99d\\ub300 \\ubc0f \\uc885\\uc774\\uc11c\\ub958 \\uc0ac\\uc6a9\\uc808\\uac10\\uc5d0 \\ub530\\ub978 \\uc694\\uc591\\uae30\\uad00 \\ube44\\uc6a9 \\uc808\\uac10\\r\\n   \\uae30\\uc874 \\uc885\\uc774\\uc11c\\ub958 \\ubc0f \\uc2a4\\uce94\\ubb38\\uc11c \\ub370\\uc774\\ud130\\uc758 \\uc218\\uae30 \\uc785\\ub825 \\uac10\\uc18c\\uc5d0 \\ub530\\ub978 \\uc5c5\\ubb34 \\ud504\\ub85c\\uc138\\uc2a4 \\uac1c\\uc120 \\ubc0f \\uc778\\uac74\\ube44 \\uc808\\uac10\\r\\n    \\uc2e4\\uc190\\ubcf4\\ud5d8 \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c \\uc804\\uc0b0\\ud654\\uc5d0 \\ub530\\ub978 \\uccad\\uad6c\\uc728 \\uc99d\\uac00\\r\\n \\r\\n\\u2161\\r\\n  \\uc5c5\\ubb34\\ud604\\ud669\\r\\n1. \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\ud604\\ud669   \\r\\n   \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\ud604\\ud589 \\uc5c5\\ubb34 \\ud750\\ub984\\r\\n \\r\\n\\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\ud604\\ud589 \\uc5c5\\ubb34 \\ud750\\ub984\\ub3c4\\r\\n  o (\\uc758\\ub8cc\\uc11c\\ube44\\uc2a4 \\uc774\\uc6a9) \\ubcf4\\ud5d8\\uac00\\uc785\\uc790\\uac00 \\uc694\\uc591\\uae30\\uad00\\uc5d0\\uc11c \\uc758\\ub8cc\\uc11c\\ube44\\uc2a4\\ub97c \\uc774\\uc6a9 \\ud6c4 \\uc9c4\\ub8cc\\ube44, \\uc57d\\uc81c\\ube44 \\ub4f1\\uc758 \\ube44\\uc6a9 \\uc218\\ub0a9\\r\\n  o (\\uccad\\uad6c \\ud544\\uc694\\uc11c\\ub958 \\uc900\\ube44) \\ubcf4\\ud5d8\\uac00\\uc785\\uc790\\ub294 \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c \\ud544\\uc694\\uc11c\\ub958\\ub97c \\ud655\\uc778\\ud558\\uace0 \\uc9c4\\ub8cc\\ub97c \\ubc1b\\uc740 \\uc694\\uc591\\uae30\\uad00\\uc5d0 \\uc11c\\ub958\\ubc1c\\uae09 \\uc2e0\\uccad \\ubc0f \\uc218\\ub839\\r\\n   -\\uc11c\\ub958\\ub294 \\ub300\\uba74\\ucc3d\\uad6c, \\ubb34\\uc778\\ubc1c\\uae09\\uae30, \\uc99d\\uba85\\uc11c\\ubc1c\\uae09\\ud648\\ud398\\uc774\\uc9c0 \\ub4f1\\uc758 \\ubc29\\ubc95\\uc73c\\ub85c \\ubc1c\\uae09\\r\\n   -\\uc2e4\\uc190\\uc758\\ub8cc\\ube44 \\uccad\\uad6c \\ud544\\uc218\\uc11c\\ub958\\ub294   \\uc9c4\\ub8cc\\ube44 \\uc601\\uc218\\uc99d,   \\uc57d\\uc81c\\ube44 \\uc601\\uc218\\uc99d,   \\uc9c4\\ub8cc\\ube44 \\uc138\\ubd80\\ub0b4\\uc5ed\\uc11c \\ubc0f   \\ucc98\\ubc29\\uc804\\uc774\\uba70, \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\ub530\\ub77c \\ucd94\\uac00\\uc11c\\ub958 \\ud544\\uc694\\r\\n\\u203b \\ud658\\uc790 \\ubcf8\\uc778\\uc774 \\uc544\\ub2cc \\uc81c 3\\uc790\\uac00 \\uc11c\\ub958\\ubc1c\\uae09\\uc744 \\uc694\\uccad\\ud558\\ub294 \\uacbd\\uc6b0 \\uac00\\uc871\\uad00\\uacc4\\uc99d\\uba85\\uc11c \\ubc0f \\ub300\\ub9ac\\uc778 \\uc704\\uc784\\uc7a5 \\ud544\\uc694\\r\\n  o (\\uccad\\uad6c\\uc11c \\uc791\\uc131 \\ubc0f \\uc11c\\ub958\\uc81c\\ucd9c) \\ubcf4\\ud5d8\\uac00\\uc785\\uc790 \\ub610\\ub294 \\uccad\\uad6c \\ub300\\ub9ac\\uc778\\uc740 \\uccad\\uad6c\\uc11c\\ub97c \\uc791\\uc131\\ud558\\uace0 \\ubc1c\\uae09\\ubc1b\\uc740 \\uc11c\\ub958\\uc640 \\ud568\\uaed8 \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\uc81c\\ucd9c\\r\\n \\u3000-\\uccad\\uad6c \\uc2dc \\ubcf4\\ud5d8\\uc0ac\\uc758 \\uac1c\\uc778\\uc815\\ubcf4\\ucc98\\ub9ac \\ub3d9\\uc758\\uc11c\\ub97c \\uc791\\uc131\\ud558\\uba70, \\ub300\\ub9ac\\uc778\\uc774 \\uccad\\uad6c\\ud558\\ub294 \\uacbd\\uc6b0 \\uad8c\\ud55c\\uc744 \\uc704\\uc784\\ubc1b\\uc544\\uc57c \\ud568\\r\\n  o (\\ubcf4\\ud5d8\\uae08 \\uc9c0\\uae09 \\uc2ec\\uc0ac) \\ubcf4\\ud5d8\\uc0ac\\ub294 \\uc81c\\ucd9c\\ub41c \\uc11c\\ub958\\ub97c \\uae30\\ubc18\\uc73c\\ub85c \\ubcf4\\ud5d8\\uae08 \\uc9c0\\uae09 \\uc5ec\\ubd80\\uc640 \\uc9c0\\uae09\\uc561\\uc744 \\uacb0\\uc815\\r\\n  o (\\ubcf4\\ud5d8\\uae08 \\uc9c0\\uae09) \\ubcf4\\ud5d8\\uc0ac\\ub294 \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc790\\uc640 \\ubcf4\\ud5d8\\uac00\\uc785\\uc790\\uc5d0\\uac8c \\ubcf4\\uc0c1 \\uae08\\uc561\\uc744 \\uc548\\ub0b4\\ud558\\uace0 \\ubcf4\\ud5d8\\uae08\\uc744 \\ubcf4\\ud5d8\\uac00\\uc785\\uc790\\uc5d0\\uac8c \\uc9c0\\uae09\\r\\n   \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\ud604\\ud589 \\ubc29\\uc2dd\\r\\n  o \\ud604\\ud589 \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c\\ub294 \\ubcf4\\ud5d8\\uac00\\uc785\\uc790\\uac00 \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\ubcf4\\ud5d8\\uae08\\uc744 \\uccad\\uad6c\\ud558\\ub294 \\u2018\\uc9c1\\uc811\\uccad\\uad6c\\u2019 \\ubc29\\uc2dd\\uacfc \\uc694\\uc591\\uae30\\uad00 \\ub2e8\\ub9d0\\uae30\\ub97c \\ud1b5\\ud574 \\ubcf4\\ud5d8\\uae08\\uc744 \\uccad\\uad6c\\ud558\\ub294 \\ubc29\\uc2dd \\uc874\\uc7ac\\r\\n  o \\u2018\\uc9c1\\uc811\\uccad\\uad6c\\u2019 \\ubc29\\uc2dd\\uc740 \\ubcf4\\ud5d8\\uac00\\uc785\\uc790\\uac00 \\uc694\\uc591\\uae30\\uad00\\uc5d0\\uc11c \\uccad\\uad6c \\ud544\\uc694\\uc11c\\ub958\\ub97c \\ubc1c\\uae09\\ubc1b\\uc544 \\ubcf4\\ud5d8\\uc0ac \\uc571/\\uc6f9 \\ub610\\ub294 \\uc624\\ud504\\ub77c\\uc778\\uc73c\\ub85c \\uc81c\\ucd9c\\ud568\\r\\n \\r\\n\\uc81c\\ucd9c\\ubc29\\ubc95\\r\\n\\uc124\\uba85\\r\\n\\ubcf4\\ud5d8\\uc0ac \\uc571(\\ud648\\ud398\\uc774\\uc9c0)\\r\\n\\uc11c\\ub958 \\uc2a4\\uce94 \\ub610\\ub294 \\uc0ac\\uc9c4\\ucd2c\\uc601 \\ud6c4 \\uc774\\ubbf8\\uc9c0(pdf\\ub4f1) \\ud30c\\uc77c\\ub85c \\uc81c\\ucd9c\\r\\n\\uc624\\ud504\\ub77c\\uc778(\\uc0ac\\ubcf8\\uc81c\\ucd9c \\ubc0f Fax)\\r\\n\\uc2e4\\ubb3c \\ubb38\\uc11c \\uc0ac\\ubcf8\\uc744 \\ubcf4\\ud5d8\\uc0ac \\ucc3d\\uad6c\\uc5d0\\uc11c \\uc81c\\ucd9c,\\r\\n\\uc2e4\\ubb3c \\ubb38\\uc11c \\uc0ac\\ubcf8\\uc744 \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\uc6b0\\ud3b8\\uc73c\\ub85c \\uc81c\\ucd9c, \\r\\n\\uc2e4\\ubb3c \\ubb38\\uc11c \\uc0ac\\ubcf8\\uc744 Fax\\ub85c \\ubcf4\\ud5d8\\uc0ac\\ub85c \\uc81c\\ucd9c\\r\\n   - \\ubcf4\\ud5d8\\uc0ac\\ub4e4\\uc740 \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc11c\\ub958 \\uc791\\uc131\\uc5d0\\uc11c\\ubd80\\ud130 \\uc11c\\ub958\\uc758 \\ucd2c\\uc601-\\uc81c\\ucd9c\\uae4c\\uc9c0 \\uc77c\\uad04 \\uc2e0\\uccad\\uc774 \\uac00\\ub2a5\\ud55c \\ubaa8\\ubc14\\uc77c \\uc571 \\uc11c\\ube44\\uc2a4\\ub97c \\uc81c\\uacf5 \\uc911\\r\\n   - \\ubcf4\\ud5d8\\uc0ac \\ubaa8\\ubc14\\uc77c \\uc571\\uc5d0 \\uc811\\uc18d\\ud558\\uc5ec \\uc2e4\\uc190\\uc758\\ub8cc\\ubcf4\\ud5d8 \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc11c\\ub97c \\uc791\\uc131\\ud558\\uace0, \\uc758\\ub8cc\\ube44 \\uc99d\\uba85\\uc11c\\ub958 \\uc774\\ubbf8\\uc9c0 \\ud30c\\uc77c\\uc744 \\ucca8\\ubd80\\ud558\\uc5ec \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\uc77c\\uad04 \\uc1a1\\ubd80\\ud560 \\uc218 \\uc788\\uc74c\\r\\n  \\r\\n \\r\\n\\ubaa8\\ubc14\\uc77c \\uc571\\uc744 \\uc774\\uc6a9\\ud55c \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c \\uac1c\\uc694\\r\\n    \\u203b \\ud658\\uc790\\ub294 \\uc694\\uc591\\uae30\\uad00\\uc73c\\ub85c\\ubd80\\ud130 \\uc758\\ub8cc\\ube44 \\uc99d\\uba85\\uc11c\\ub97c \\ubc1c\\uae09\\ubc1b\\uc740 \\ud6c4 \\ud574\\ub2f9 \\uc11c\\ub958\\ub97c \\uc2a4\\ub9c8\\ud2b8\\ud3f0 \\uce74\\uba54\\ub77c\\ub85c \\ucd2c\\uc601\\ud558\\uc5ec \\uc774\\ubbf8\\uc9c0 \\ud30c\\uc77c\\ub85c \\uc800\\uc7a5 \\r\\n  o \\uc694\\uc591\\uae30\\uad00 \\ub2e8\\ub9d0\\uae30\\ub97c \\uc774\\uc6a9\\ud558\\ub294 \\ubc29\\uc2dd\\uc740 \\ubcf4\\ud5d8\\uac00\\uc785\\uc790\\uac00 \\uc694\\uc591\\uae30\\uad00 \\ub2e8\\ub9d0\\uc5d0\\uc11c\\uccad\\uad6c \\ud544\\uc694\\uc11c\\ub958\\ub97c \\uc120\\ud0dd\\ud558\\uc5ec \\uccad\\uad6c\\ud560 \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\ubc14\\ub85c \\uc11c\\ub958\\ub97c \\uc804\\uc1a1\\ud568\\r\\n   - \\uc694\\uc591\\uae30\\uad00\\uacfc \\ubcf4\\ud5d8\\uc0ac \\uc815\\ubcf4\\uc2dc\\uc2a4\\ud15c\\uc744 \\uc11c\\ub85c \\uc5f0\\uacb0\\ud558\\ub294 \\ubb34\\uc778\\ub2e8\\ub9d0\\uae30\\ub97c \\uc124\\uce58\\ud558\\uace0, \\ud658\\uc790\\uac00 \\ud574\\ub2f9 \\ub2e8\\ub9d0\\uae30\\ub97c \\uc774\\uc6a9\\ud574 \\uc790\\uc2e0\\uc758 \\uc758\\ub8cc\\ube44 \\uc99d\\uba85\\uc11c\\ub958 \\ub4f1\\uc744 \\ubc1c\\uae09\\ubc1b\\uac70\\ub098, \\uc804\\uc790\\ubb38\\uc11c\\ub85c \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\uc1a1\\ubd80\\ud560 \\uc218 \\uc788\\uc74c\\r\\n   - \\ub300\\ud615\\ubcd1\\uc6d0 \\ubc0f \\ubb34\\uc778\\ub2e8\\ub9d0\\uae30 \\uc0ac\\uc5c5\\uc790\\uc640 \\uc81c\\ud734\\ud558\\uc5ec \\uccad\\uad6c \\uc11c\\ube44\\uc2a4\\ub97c \\uc81c\\uacf5 \\uc911\\r\\n \\r\\n \\r\\n\\ubb34\\uc778\\ub2e8\\ub9d0\\uae30\\ub97c \\uc774\\uc6a9\\ud55c \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c \\uac1c\\uc694\\r\\n   (\\uad00\\ub828\\uc2dc\\uc2a4\\ud15c) \\uc804\\uc790\\uc758\\ubb34\\uae30\\ub85d \\r\\n o \\uc804\\uc790\\uc758\\ubb34\\uae30\\ub85d(EMR*)\\uc2dc\\uc2a4\\ud15c\\uc740 \\ud658\\uc790\\uac00 \\ub0b4\\uc6d0\\ud558\\uc600\\uc744 \\ub54c \\ubc1c\\uc0dd\\ud558\\ub294 \\ud658\\uc790\\uc758 \\uc9c4\\ub8cc\\uae30\\ub85d(\\uc9c4\\ub2e8, \\uc57d\\ubb3c\\ucc98\\ubc29, \\uac80\\uc0ac\\uacb0\\uacfc \\ub4f1)\\uc744 \\uc804\\uc790\\uc801\\uc778 \\ud615\\ud0dc\\ub85c \\ub0b4\\uc6d0\\uc9c4\\ub8cc\\uae30\\ub85d \\ub2e8\\uc704\\ub85c \\uae30\\ub85d\\ud560 \\uc218 \\uc788\\ub294 \\uc2dc\\uc2a4\\ud15c\\r\\n* EMR : Electronic Medical Records\\r\\n o \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc640 \\uad00\\ub828\\ub41c \\ud544\\uc218\\uc11c\\ub958\\ub97c EMR\\uc2dc\\uc2a4\\ud15c\\uc758 \\uc815\\ubcf4\\ub97c \\uae30\\ubc18\\ud558\\uc5ec \\ubc1c\\uae09\\ubc1b\\uc744 \\uc218 \\uc788\\uc74c\\r\\n   - \\ud658\\uc790\\ub294 \\uc694\\uc591\\uae30\\uad00\\uc758 \\ud0a4\\uc624\\uc2a4\\ud06c \\ub2e8\\ub9d0 \\ub4f1\\uc744 \\ud1b5\\ud574 \\ubcf8\\uc778\\uc758 \\uc9c4\\ub8cc\\uae30\\ub85d\\uc744 \\uc5f4\\ub78c\\ud558\\uac70\\ub098 \\uadf8 \\uc0ac\\ubcf8\\uc744 \\ubc1c\\uae09\\r\\n o \\ubcd1\\uc6d0 \\uaddc\\ubaa8\\uc5d0 \\ub530\\ub77c EMR\\uc2dc\\uc2a4\\ud15c\\uc744 \\uc790\\uccb4 \\uac1c\\ubc1c\\ud558\\uac70\\ub098 \\uc0c1\\uc6a9 \\uc194\\ub8e8\\uc158\\uc744 \\uc0ac\\uc6a9\\ud558\\uace0 \\uc788\\uc74c*\\r\\n    * \\uc0ac\\uc6a9 \\ud604\\ud669\\uc740 2023.11 \\uae30\\uc900\\r\\n   - \\ubcd1\\uc6d0\\uae09 \\uc911 350\\uac1c \\ubcd1\\uc6d0\\uc740 \\uc790\\uccb4 \\uac1c\\ubc1c\\ud558\\uc5ec \\uc0ac\\uc6a9\\ud558\\uace0 \\uc788\\uc73c\\uba70, \\ubcd1\\uc6d0\\uae09 \\uc774\\uc0c1\\uc5d0 \\uc11c\\ube44\\uc2a4\\ud558\\ub294 EMR\\uc5c5\\uccb4\\ub294 55\\uac1c \\r\\n\\u203b \\uc0c1\\uae09\\uc885\\ud569\\ubcd1\\uc6d0\\uc740 \\ubaa8\\ub450 \\uc790\\uccb4 \\uac1c\\ubc1c EMR \\uc2dc\\uc2a4\\ud15c \\uc0ac\\uc6a9 \\r\\n   - \\uc758\\uc6d0\\uae09 \\uc911 27\\uac1c \\uc758\\uc6d0\\uc774 \\uc790\\uccb4 \\uac1c\\ubc1c\\uc774\\uba70, \\uc758\\uc6d0\\uae09\\uc5d0 \\uc11c\\ube44\\uc2a4\\ud558\\ub294 EMR\\uc5c5\\uccb4\\ub294 43\\uac1c\\r\\n   - \\uc774 \\uc678 \\ubcf4\\uac74\\uae30\\uad00 \\ubc0f \\uc57d\\uad6d EMR\\uc2dc\\uc2a4\\ud15c\\uc740 16\\uac1c\\r\\n2. \\ubb38\\uc81c\\uc810\\r\\n  \\ubcf4\\ud5d8\\uac00\\uc785\\uc790 \\uce21\\uba74\\r\\n o (\\uccad\\uad6c \\ud544\\uc694\\uc11c\\ub958 \\uc774\\ud574 \\ubd80\\uc871) \\ubcf4\\ud5d8\\uc0ac\\ubcc4\\ub85c \\uccad\\uad6c \\ud544\\uc694\\uc11c\\ub958\\uac00 \\uc0c1\\uc774\\ud558\\uba70, \\uc11c\\ub958\\uc5d0 \\ub300\\ud55c \\uc774\\ud574 \\ubd80\\uc871\\uc73c\\ub85c \\uc694\\uc591\\uae30\\uad00\\uacfc \\uc758\\uc0ac\\uc18c\\ud1b5\\uc774 \\uc5b4\\ub824\\uc6c0\\r\\n o (\\ubc88\\uac70\\ub85c\\uc6b4 \\uc11c\\ub958\\ubc1c\\uae09) \\uc11c\\ub958\\ubc1c\\uae09\\uc744 \\uc704\\ud574 \\uc694\\uc591\\uae30\\uad00\\uc5d0 \\ucd94\\uac00 \\ubc29\\ubb38\\ud574\\uc57c \\ud558\\uba70, \\uc81c\\uc99d\\uba85\\uc11c\\ub958 \\ubc1c\\uae09 \\uc218\\uc218\\ub8cc \\ube44\\uc6a9 \\uc9c0\\ubd88\\ud558\\ub294 \\uacbd\\uc6b0 \\ubc1c\\uc0dd\\r\\n o (\\ubd88\\ud3b8\\ud55c \\uc11c\\ub958\\uc81c\\ucd9c) \\ubc1c\\uae09\\ubc1b\\uc740 \\uc11c\\ub958\\ub97c \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\uc9c1\\uc811 \\ubc29\\ubb38, Fax \\uc1a1\\uc2e0 \\ub610\\ub294 \\uc2a4\\uce94\\ud558\\uc5ec \\uc774\\ubbf8\\uc9c0 \\ud30c\\uc77c \\uc5c5\\ub85c\\ub4dc\\ub97c \\ud1b5\\ud574 \\uc81c\\ucd9c\\ud558\\uc5ec\\uc57c \\ud568\\uc5d0 \\ub530\\ub978 \\ubd88\\ud3b8\\ud568\\uc774 \\uc0c1\\ub2f9\\ud568\\r\\n o (\\ub300\\uae30 \\uc2dc\\uac04 \\ubc1c\\uc0dd) \\uc218\\uc791\\uc5c5\\uc73c\\ub85c \\uc778\\ud55c \\ubcd1\\uc6d0\\ube44 \\uc218\\ub0a9 \\ud6c4 \\ucd5c\\uc885 \\ubcf4\\ud5d8\\uae08 \\uc218\\ub839\\uae4c\\uc9c0 \\uc2dc\\uac04 \\uc18c\\uc694\\r\\n o (\\uc18c\\uc561 \\uccad\\uad6c \\ud3ec\\uae30) \\uc11c\\ub958\\ubc1c\\uae09 \\ubc0f \\uccad\\uad6c \\uc808\\ucc28\\uc758 \\ubcf5\\uc7a1\\uc131\\uc73c\\ub85c \\uc778\\ud574 \\uc18c\\uc561 \\uccad\\uad6c \\ud3ec\\uae30 \\uc0ac\\ub840 \\uc874\\uc7ac\\r\\n  \\uc694\\uc591\\uae30\\uad00 \\ubc0f \\ubcf4\\ud5d8\\uc0ac \\uce21\\uba74\\r\\n o (\\uc694\\uc591\\uae30\\uad00 \\uc5c5\\ubb34 \\uacfc\\uc911) \\uc11c\\ub958\\ubc1c\\uae09 \\uc694\\uccad \\uc811\\uc218\\uc640 \\ubc1c\\uae09 \\uc791\\uc5c5 \\ubc18\\ubcf5\\uc73c\\ub85c \\uc778\\ud55c \\uc6d0\\ubb34\\uacfc \\uc778\\ub825 \\ubd80\\ub2f4 \\ubc0f \\uc5c5\\ubb34 \\ube44\\ud6a8\\uc728\\uc131 \\uacfc\\uc911\\r\\n o (\\ubcf4\\ud5d8\\uc0ac \\uc5c5\\ubb34 \\ube44\\ud6a8\\uc728\\uc131) \\uc785\\uc218\\ud55c \\uc11c\\ub958 \\uc2dc\\uc2a4\\ud15c \\uc785\\ub825 \\ubc0f \\uac80\\uc99d\\uc5d0 \\ub2e4\\uc218 \\uc778\\ub825 \\uc18c\\uc694 \\ubc0f \\uc2ec\\uc0ac \\ud6c4 \\uc885\\uc774\\ubb38\\uc11c \\ubcf4\\uad00\\ud558\\ub294 \\ud615\\ud0dc\\uc758 \\ube44\\ud6a8\\uc728\\uc131 \\uc874\\uc7ac\\r\\n o (\\ubcf4\\ud5d8\\uc0ac \\uc5c5\\ubb34 \\uc9c0\\uc5f0) \\uc11c\\ub958\\uac00 \\ubd88\\uc77c\\uce58\\ud558\\uac70\\ub098 \\ubd80\\uc815\\ud655\\ud55c \\uacbd\\uc6b0\\uac00 \\ub9ce\\uc544 \\uc7ac\\uc694\\uccad\\ud574\\uc57c \\ud558\\uc5ec \\uc5c5\\ubb34 \\uc9c0\\uc5f0\\r\\n \\r\\n\\u2162\\r\\n  \\uc0ac\\uc5c5\\ucd94\\uc9c4\\uccb4\\uacc4 \\ubc0f \\uc77c\\uc815\\r\\n1. \\ucd94\\uc9c4 \\ubc29\\ud5a5\\r\\n   \\uc774\\uc6a9\\uc790 \\uc911\\uc2ec\\uc758 \\ud3b8\\ub9ac\\ud55c \\uc2e4\\uc190\\ubcf4\\ud5d8 \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c \\uc11c\\ube44\\uc2a4 \\uc218\\ub9bd\\r\\n   \\uc548\\uc2ec\\ud558\\uace0 \\uc774\\uc6a9\\ud560 \\uc218 \\uc788\\ub294 \\uac1c\\uc778\\uc815\\ubcf4 \\ubc0f \\uc758\\ub8cc\\ub370\\uc774\\ud130 \\uc720\\ud1b5\\uccb4\\uacc4 \\uad6c\\ucd95\\r\\n   365\\uc77c 24\\uc2dc\\uac04 \\uc774\\uc6a9\\ud560 \\uc218 \\uc788\\ub294 \\ub300\\uad6d\\ubbfc\\ud3ec\\ud138 \\uad6c\\ucd95\\r\\n2. \\uc0ac\\uc5c5\\ucd94\\uc9c4\\uccb4\\uacc4\\r\\n \\r\\n(\\uc8fc\\uad00\\uae30\\uad00)\\r\\n\\ubcf4\\ud5d8\\uac1c\\ubc1c\\uc6d0\\r\\n\\uc815\\ubcf4\\uc2dc\\uc2a4\\ud15c \\uac10\\ub9ac\\r\\n\\uc0ac\\uc5c5\\uc218\\ud589\\uc5c5\\uccb4\\r\\n \\r\\n\\uad6c \\ubd84\\r\\n\\uc8fc\\uc694 \\uc5ed\\ud560\\r\\n\\uc8fc\\uad00\\uae30\\uad00\\r\\no \\uc0ac\\uc5c5 \\uc218\\ud589 \\uacc4\\ud68d \\uac80\\ud1a0 \\ubc0f \\uc2b9\\uc778\\r\\no \\uc0ac\\uc5c5 \\uacc4\\ud68d \\uc870\\uc815 \\ubc0f \\uad00\\ub9ac\\r\\no \\uc5c5\\ubb34\\ubcc4 \\uc694\\uad6c\\uc0ac\\ud56d \\ud655\\uc778 \\ub4f1 \\uc6b4\\uc601 \\uad00\\ub9ac \\ubc0f \\uad00\\ub9ac \\uac10\\ub3c5\\r\\no \\uc0ac\\uc5c5\\uc218\\ud589\\uc5c5\\uccb4 \\uc9c4\\ub3c4\\uad00\\ub9ac \\ubc0f \\uac80\\uc218\\r\\no \\ud488\\uc9c8 \\uad00\\ub9ac \\ubc0f \\uc758\\uc0ac \\uacb0\\uc815\\r\\no \\uc0ac\\uc5c5\\uad00\\ub9ac\\uc790\\uc758 \\uad8c\\ud55c\\uc744 \\uc704\\uc784\\ubc1b\\uc544 \\uc0ac\\uc5c5\\ud1b5\\uc81c \\ubc0f \\uc8fc\\uc694 \\uc774\\uc288 \\ud574\\uacb0\\r\\no \\uc0ac\\uc5c5\\uc9c4\\ud589\\uad00\\ub9ac, \\ud504\\ub85c\\uc81d\\ud2b8 \\ub9e4\\ub2c8\\uc800 \\uc9c0\\uc6d0, \\uad50\\uc721, \\uc778\\ub825\\uad00\\ub9ac, \\ubcc0\\uacbd\\ud1b5\\uc81c\\r\\no \\ub2e8\\uacc4\\ubcc4 \\ud488\\uc9c8\\uac80\\ud1a0 \\ubc0f \\uacb0\\uacfc\\ubcf4\\uace0, \\uae30\\uc220\\uc790\\ubb38 \\uc218\\ud589\\r\\no \\uc774\\ud574 \\ub2f9\\uc0ac\\uc790 \\uac04 \\uc758\\uacac \\uad50\\ud658 \\ubc0f \\uc870\\uc815\\r\\no \\uac1c\\uc778\\uc815\\ubcf4 \\uc601\\ud5a5\\ud3c9\\uac00\\r\\n\\uc815\\ubcf4\\uc2dc\\uc2a4\\ud15c \\uac10\\ub9ac\\r\\no \\ud504\\ub85c\\uc81d\\ud2b8 \\uc9c4\\ud589\\uacfc\\uc815 \\ubc0f \\uc0b0\\ucd9c\\ubb3c \\ud488\\uc9c8\\uc5d0 \\ub300\\ud55c \\uac10\\ub9ac\\r\\n\\uc0ac\\uc5c5\\uc218\\ud589\\uc5c5\\uccb4\\r\\no \\uc0ac\\uc5c5 \\uc218\\ud589 \\uacc4\\ud68d \\uc218\\ub9bd, \\ucd94\\uc9c4 \\ubc0f \\uacb0\\uacfc \\ubcf4\\uace0\\r\\no \\uc7a5\\ube44 \\ud6a8\\uc728\\uc131\\uacfc \\uc11c\\ube44\\uc2a4 \\ud655\\uc7a5\\uc131\\uc744 \\uace0\\ub824\\ud55c \\uc2dc\\uc2a4\\ud15c \\uad6c\\ucd95\\r\\no \\uac1c\\ubc1c\\uc778\\ub825 \\uad00\\ub9ac, \\uad50\\uc721\\uc9c0\\uc6d0 \\ub4f1\\r\\no \\uc5c5\\ubb34 \\ub2f4\\ub2f9\\uc790\\uc640 \\ucee4\\ubba4\\ub2c8\\ucf00\\uc774\\uc158 \\ubc0f \\uac1c\\ubc1c\\r\\n3. \\ucd94\\uc9c4 \\uc77c\\uc815 \\r\\n   \\uc0ac\\uc5c5 \\uae30\\uac04: \\uacc4\\uc57d\\uc77c\\ub85c\\ubd80\\ud130 19\\uac1c\\uc6d4\\r\\n   \\uc138\\ubd80 \\uc77c\\uc815\\r\\n  o 1\\ub2e8\\uacc4 \\uad6c\\ucd95 \\uae30\\uac04: 2024.04. ~ 2024.10. (\\uc57d 7\\uac1c\\uc6d4) \\r\\n \\u203b 2024.10.25(\\uae08) \\uc11c\\ube44\\uc2a4 \\uc624\\ud508 \\uc77c\\uc815 \\r\\n  \\u203b \\uc0ac\\uc5c5\\uc790 \\uc120\\uc815 \\uc774\\ud6c4, \\uc6b0\\uc120\\ud611\\uc0c1\\uacfc \\ubcd1\\ud589\\ud558\\uc5ec \\uc2e0\\uc18d\\ud55c \\ubd84\\uc11d/\\uc124\\uacc4 \\uc778\\ub825 \\ud22c\\uc785 \\ud544\\uc694\\r\\n  o 2\\ub2e8\\uacc4 \\uad6c\\ucd95 \\uae30\\uac04: 2024.11. ~ 2025.10. (\\uc57d 12\\uac1c\\uc6d4) \\r\\n \\u203b 2025.10.25(\\uae08) \\uc11c\\ube44\\uc2a4 \\uc624\\ud508 \\uc77c\\uc815\\r\\n  \\u203b\\u203b \\uc694\\uc591\\uae30\\uad00 \\ub300\\uc0c1\\ubcc4 \\uc810\\uc9c4\\uc801 \\uc624\\ud508 \\uace0\\ub824\\r\\n \\r\\n\\ucd94\\uc9c4\\ub0b4\\uc6a9\\r\\n\\uad6c\\ucd95 \\uc77c\\uc815\\r\\n1\\ub2e8\\uacc4 \\uad6c\\ucd95\\r\\n2\\ub2e8\\uacc4 \\uad6c\\ucd95\\r\\nM\\r\\nM1\\r\\nM2\\r\\nM3\\r\\nM4\\r\\nM5\\r\\nM6\\r\\nM7\\r\\nM8\\r\\nM9\\r\\nM10\\r\\nM11\\r\\nM12\\r\\nM13\\r\\nM14\\r\\nM15\\r\\nM16\\r\\nM17\\r\\nM18\\r\\n  \\uc751\\uc6a9\\uc2dc\\uc2a4\\ud15c\\r\\n   - \\ubaa9\\ud45c\\uc2dc\\uc2a4\\ud15c \\ubd84\\uc11d\\u2024\\uc124\\uacc4\\r\\n   - \\uac1c\\ubc1c \\ubc0f \\ub2e8\\uc704 \\ud14c\\uc2a4\\ud2b8\\r\\n   - \\ud1b5\\ud569\\ud14c\\uc2a4\\ud2b8\\r\\n  \\uae30\\ubc18\\ud658\\uacbd \\ubc0f \\uc2dc\\uc2a4\\ud15c\\uad6c\\ucd95\\r\\n   - \\uacc4\\ud68d \\uc218\\ub9bd \\ubc0f \\ubd84\\uc11d\\r\\n   - \\uac1c\\ubc1c \\ud658\\uacbd \\uad6c\\ucd95\\r\\n   - \\uc6b4\\uc601 \\uc2dc\\uc2a4\\ud15c \\uad6c\\ucd95\\r\\n   - DR \\uad6c\\ucd95\\r\\n   - \\uc2dc\\uc2a4\\ud15c \\uc2dc\\ud5d8\\r\\n  \\uc11c\\ube44\\uc2a4 \\uc624\\ud508 \\ubc0f \\uc548\\uc815\\ud654\\r\\n   - \\uc11c\\ube44\\uc2a4 \\uc624\\ud508\\r\\n   - \\uc2dc\\uc2a4\\ud15c \\uc548\\uc815\\ud654\\r\\n  \\uc2dc\\uc2a4\\ud15c \\ud655\\uc0b0\\r\\n  - \\ucd08\\uae30 \\ud655\\uc0b0\\ub300\\uc0c1 \\uc120\\uc815\\r\\n   - \\uc5f0\\uacc4 API \\uac1c\\ubc1c \\ubc0f \\uc124\\uce58\\r\\n   - \\ud1b5\\ud569\\ud14c\\uc2a4\\ud2b8\\r\\n  \\uc2dc\\uc2a4\\ud15c \\uc6b4\\uc601 \\r\\n   - \\uc6b4\\uc601\\uad50\\uc721 \\ubc0f \\uae30\\uc220\\uc774\\uc804\\r\\n   - \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc2dc\\uc2a4\\ud15c \\uc6b4\\uc601\\r\\n   - \\uc2dc\\uc2a4\\ud15c \\uc720\\uc9c0\\ubcf4\\uc218\\r\\n\\u203b \\uc0c1\\uae30 \\ucd94\\uc9c4 \\uc77c\\uc815\\uc740 \\uc0ac\\uc5c5\\ucd94\\uc9c4 \\uacfc\\uc815\\uc5d0\\uc11c \\ud611\\uc758-\\uc870\\uc815\\ub420 \\uc218 \\uc788\\uc74c\\r\\n \\r\\n\\u2163\\r\\n  \\uc81c\\uc548 \\uc694\\uccad \\ub0b4\\uc6a9\\r\\n1. \\ubaa9\\ud45c \\uc5c5\\ubb34 \\ud504\\ub85c\\uc138\\uc2a4\\r\\n   \\u2018\\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654\\u2019\\ub780?\\r\\n  o \\uc2e4\\uc190\\ubcf4\\ud5d8\\uc5d0 \\uac00\\uc785\\ud55c \\ud658\\uc790\\uac00 \\uc694\\uccad\\ud558\\uba74 \\uc694\\uc591\\uae30\\uad00\\uc774 \\uc9c4\\ub8cc\\ub0b4\\uc5ed \\ub4f1\\uc744 \\uc804\\uc790\\ubb38\\uc11c \\ud615\\ud0dc\\ub85c \\uc81c3\\uc758 \\uc804\\uc1a1\\ub300\\ud589\\uae30\\uad00\\uc744 \\uac70\\uccd0 \\ubcf4\\ud5d8\\uacc4\\uc57d\\uc744 \\uccb4\\uacb0\\ud55c \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\ubcf4\\ub0b4\\ub294 \\ubc29\\uc2dd\\r\\n   \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc5c5\\ubb34 \\uad6c\\uc131 \\ubc0f \\uc808\\ucc28\\r\\n \\r\\n\\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc5c5\\ubb34 \\uad6c\\uc131 \\ubc0f \\uc808\\ucc28\\r\\n    (\\uc9c4\\ub8cc\\ub0b4\\uc5ed \\uc870\\ud68c \\uc694\\uad6c) \\u2018\\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c\\uad8c\\uc790\\u2019\\ub294 \\u2018\\uc885\\ud569\\ud3ec\\ud138\\u2019\\uc5d0\\uc11c 3\\ub144 \\uc774\\ub0b4 \\ubcd1\\uc6d0\\uc5d0 \\ubc29\\ubb38\\ud55c \\uc9c4\\ub8cc\\ub0b4\\uc5ed \\uc870\\ud68c \\uc694\\uad6c\\r\\n    - \\uccad\\uad6c\\uad8c\\uc790\\ub294 \\ubcf8\\uc778\\uc778\\uc99d \\ud6c4 \\uc9c4\\ub8cc\\ub0b4\\uc5ed \\uc870\\ud68c\\ub97c \\uc694\\uad6c\\ud560 \\uc218 \\uc788\\uc74c\\r\\n    (\\uc9c4\\ub8cc\\ub0b4\\uc5ed \\uc804\\uc1a1) \\uc804\\uc1a1\\ub300\\ud589\\uae30\\uad00\\uc740 \\uc694\\uc591\\uae30\\uad00\\uc5d0 \\uc9c4\\ub8cc\\ub0b4\\uc5ed\\uc744 \\uc804\\uc1a1\\ubc1b\\uc544 \\uccad\\uad6c\\uc790\\uac00 \\uc885\\ud569\\ud3ec\\ud138\\uc5d0\\uc11c \\uc870\\ud68c\\ud560 \\uc218 \\uc788\\ub3c4\\ub85d \\ud568\\r\\n   (\\uc9c4\\ub8cc\\uc815\\ubcf4 \\uc804\\uc1a1 \\uc694\\uad6c) \\uc9c4\\ub8cc\\ubaa9\\ub85d\\uc744 \\ud655\\uc778\\ud55c \\u2018\\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c\\uad8c\\uc790\\u2019\\ub294 \\ubcf4\\ud5d8\\uae08\\uc744 \\uccad\\uad6c\\ud560 \\uc9c4\\ub8cc\\ub0b4\\uc5ed\\uc744 \\uc120\\ud0dd\\ud558\\uace0, \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc11c \\ubc0f \\uac1c\\uc778\\uc815\\ubcf4 \\ub3d9\\uc758\\uc11c\\ub97c \\uc791\\uc131\\ud558\\uc5ec \\uc9c4\\ub8cc\\uc815\\ubcf4\\ub97c \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\uc804\\uc1a1\\ud558\\ub3c4\\ub85d \\uc694\\uccad\\r\\n- \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc11c\\uc640 \\uac1c\\uc778\\uc815\\ubcf4\\ub3d9\\uc758\\uc11c\\ub97c \\uc791\\uc131\\ud574\\uc57c \\ud558\\uba70, \\uc2e4\\uc190\\ubcf4\\ud5d8\\uc744 \\uccb4\\uacb0\\ud55c \\ubcf4\\ud5d8\\uc0ac\\uc5d0\\ub9cc \\uc9c4\\ub8cc\\uc815\\ubcf4 \\uc804\\uc1a1 \\uc694\\uccad\\uc774 \\uac00\\ub2a5\\ud568\\r\\n- (\\ud544\\uc218\\uccad\\uad6c\\uc11c\\ub958)   \\uc9c4\\ub8cc\\ube44 \\uc601\\uc218\\uc99d,   \\uc57d\\uc81c\\ube44 \\uc601\\uc218\\uc99d,   \\uc9c4\\ub8cc\\ube44 \\uc138\\ubd80\\ub0b4\\uc5ed\\uc11c,   \\ucc98\\ubc29\\uc804 \\r\\n    (\\uc9c4\\ub8cc\\uc815\\ubcf4 \\uc804\\uc1a1 : \\uc694\\uc591\\uae30\\uad00 \\u2192 \\uc804\\uc1a1\\ub300\\ud589\\uae30\\uad00) \\uc804\\uc1a1 \\uc694\\uccad\\uc744 \\ubc1b\\uc740 \\uc804\\uc1a1\\ub300\\ud589\\uae30\\uad00\\uc740 \\ud574\\ub2f9 \\uc9c4\\ub8cc\\uc815\\ubcf4\\ub97c \\ubcf4\\uc720\\ud558\\uace0 \\uc788\\ub294 \\uc694\\uc591\\uae30\\uad00\\uc73c\\ub85c\\ubd80\\ud130 \\uc9c4\\ub8cc\\uc815\\ubcf4\\ub97c \\uc804\\uc1a1\\ubc1b\\uc74c\\r\\n    (\\uc9c4\\ub8cc\\uc815\\ubcf4 \\uc804\\uc1a1 : \\uc804\\uc1a1\\ub300\\ud589\\uae30\\uad00 \\u2192 \\ubcf4\\ud5d8\\uc0ac) \\uc804\\uc1a1\\ubc1b\\uc740 \\uc9c4\\ub8cc\\uc815\\ubcf4\\ub97c \\ubcf4\\ud5d8\\uae08\\uc744 \\uccad\\uad6c\\ud558\\ub294 \\ubcf4\\ud5d8\\uc0ac\\ub85c \\uc804\\uc1a1\\r\\n    (\\uccad\\uad6c\\uacb0\\uacfc \\uc548\\ub0b4) \\ubcf4\\ud5d8\\uc0ac\\ub294 \\ubcf4\\ud5d8\\uae08 \\uc2ec\\uc0ac \\uacb0\\uacfc\\ub97c \\uccad\\uad6c\\uc790\\uc5d0\\uac8c \\uc548\\ub0b4\\ud558\\uace0 \\ubcf4\\ud5d8\\uae08\\uc744 \\uc9c0\\uae09\\r\\n   \\ubaa9\\ud45c \\uc5c5\\ubb34 \\ud504\\ub85c\\uc138\\uc2a4(\\uc548)\\r\\n \\r\\n \\r\\n\\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\ubaa9\\ud45c \\uc5c5\\ubb34 \\ud504\\ub85c\\uc138\\uc2a4(\\uc548)\\r\\n o(\\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uad8c\\uc790 \\uc5ed\\ud560) \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c \\ud544\\uc694 \\uc11c\\ub958 \\uc804\\uc1a1 \\uc694\\uccad, \\uac1c\\uc778 \\uc758\\ub8cc\\ub370\\uc774\\ud130 \\uc218\\uc9d1 \\ud65c\\uc6a9\\uc758 \\uc2b9\\uc778\\uc744 \\uc704\\ud55c \\ub3d9\\uc758\\uad8c \\ud589\\uc0ac\\r\\n  - \\ubcf4\\uc720\\uacc4\\uc57d \\uc870\\ud68c : \\ubcf4\\uc720\\ud558\\uace0 \\uc788\\ub294 \\uc2e4\\uc190\\ubcf4\\ud5d8\\uc744 \\uc870\\ud68c\\ud558\\uc5ec \\uccad\\uad6c\\ud560 \\ubcf4\\ud5d8\\uc0ac \\uc120\\ud0dd\\r\\n  - \\uc9c4\\ub8cc\\ub0b4\\uc5ed \\uc870\\ud68c : \\uc911\\uacc4 \\ud3ec\\ud138\\uc5d0 \\uc811\\uc18d\\ud558\\uc5ec \\ubcf8\\uc778\\uc778\\uc99d \\ud6c4 \\ubcf8\\uc778\\uc758 \\uc9c4\\ub8cc\\ub0b4\\uc5ed\\ubaa9\\ub85d\\uc744 \\uc870\\ud68c\\ud558\\uace0 \\uccad\\uad6c\\ud560 \\uc9c4\\ub8cc\\ub0b4\\uc5ed\\uc744 \\uc120\\ud0dd \\r\\n  - \\uc0ac\\uace0\\uc811\\uc218 : \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc11c, \\ubcf4\\ud5d8\\uc0ac \\uc57d\\uad00 \\ub3d9\\uc758\\uc11c, \\uac1c\\uc778\\uc815\\ubcf4/\\uc758\\ub8cc\\uc815\\ubcf4 \\uc81c\\uacf5 \\ub3d9\\uc758\\uc11c, \\uc9c0\\uae09\\uacc4\\uc88c\\ubc88\\ud638 \\ub4f1 \\uae30\\ubcf8\\uc815\\ubcf4\\ub97c \\uc791\\uc131\\ud558\\uc5ec \\uccad\\uad6c \\uc811\\uc218 \\uc694\\uccad \\ud6c4 \\uc811\\uc218\\uc644\\ub8cc \\uc5ec\\ubd80 \\ud655\\uc778\\r\\n o (\\uc804\\uc1a1\\ub300\\ud589\\uae30\\uad00 \\uc5ed\\ud560) \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c \\uc804\\uc0b0\\ud654 \\uc2dc\\uc2a4\\ud15c \\uc6b4\\uc601 \\ubc0f \\uad00\\ub9ac, \\ud658\\uc790\\uc758 \\ub3d9\\uc758 \\ubc0f \\uc9c4\\ub8cc\\uc815\\ubcf4 \\uc804\\uc1a1 \\uc694\\uccad\\uc5d0 \\uadfc\\uac70\\ud558\\uc5ec \\uc694\\uc591\\uae30\\uad00\\uc5d0\\uc11c \\ubcf4\\uc720\\ud558\\uace0 \\uc788\\ub294 \\uc815\\ubcf4\\uc8fc\\uccb4\\uc758 \\uc758\\ub8cc\\ub370\\uc774\\ud130\\ub97c \\uc81c\\uacf5\\ubc1b\\uc544 \\uc804\\uc790\\uc801 \\ud615\\ud0dc\\ub85c \\uc720\\ud1b5\\ud558\\ub294 \\ud5c8\\ube0c \\uc5ed\\ud560\\uc744 \\uc218\\ud589\\r\\n  - \\uc9c4\\ub8cc\\ub0b4\\uc5ed \\uc870\\ud68c : \\uc694\\uc591\\uae30\\uad00\\uc5d0 \\uc2e4\\uc190\\ubcf4\\ud5d8 \\uccad\\uad6c\\uad8c\\uc790\\uc758 \\uc9c4\\ub8cc\\ub0b4\\uc5ed\\uc744 \\uc694\\uccad\\ud558\\uace0 \\uc870\\ud68c\\ub41c \\ubaa9\\ub85d\\uc744 \\uc885\\ud569\\ud3ec\\ud138\\uc5d0 \\ubcf4\\uc5ec\\uc90c\\r\\n  - \\uc0ac\\uace0\\uc811\\uc218 : \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uad8c\\uc790\\uc758 \\ubcf4\\uc720\\uacc4\\uc57d\\uc774 \\uc870\\ud68c\\ub418\\uc9c0 \\uc54a\\uc744 \\uacbd\\uc6b0 \\ubcf4\\ud5d8\\uc0ac \\uc2dc\\uc2a4\\ud15c\\uc5d0\\uc11c \\uacc4\\uc57d\\uc870\\ud68c\\r\\n  - \\uccad\\uad6c\\uc815\\ubcf4 \\uc804\\uc1a1 : \\uc804\\uc1a1\\ubc1b\\uc740 \\uc9c4\\ub8cc\\ub370\\uc774\\ud130\\ub97c \\ud45c\\uc900\\uc591\\uc2dd\\uc5d0 \\ub9de\\uac8c \\ucc98\\ub9ac\\ud558\\uace0 EDI \\uc804\\ubb38\\uc0dd\\uc131\\ud558\\uc5ec \\uc774\\ubbf8\\uc9c0 \\ud30c\\uc77c\\uacfc \\ud568\\uaed8 \\ubcf4\\ud5d8\\uc0ac\\uc5d0 \\uccad\\uad6c\\uc11c \\uc804\\uc1a1\\r\\n\\u203b \\uc0ac\\uace0\\uc811\\uc218 \\uc694\\uccad \\uc2dc \\uc694\\uc591\\uae30\\uad00\\uc73c\\ub85c\\ubd80\\ud130 \\uc804\\uc1a1\\ubc1b\\uc740 \\uc9c4\\ub8cc\\ub370\\uc774\\ud130\\ub85c \\uc774\\ubbf8\\uc9c0 \\ud615\\ud0dc(PDF) \\ud30c\\uc77c \\uc0dd\\uc131\\r\\n\\u203b \\uc785\\ub825\\ub41c \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c \\ub0b4\\uc6a9\\uc73c\\ub85c \\uc774\\ubbf8\\uc9c0 \\ud615\\uc2dd(PDF)\\uc758 \\uccad\\uad6c\\uc11c \\uc0dd\\uc131\\r\\n  - \\uccad\\uad6c\\uc644\\ub8cc : \\ubcf4\\ud5d8\\uc0ac\\ub85c\\ubd80\\ud130 \\uccad\\uad6c \\uc811\\uc218 \\uc131\\uacf5 \\uc5ec\\ubd80\\ub97c \\uc804\\uc1a1\\ubc1b\\uc544 \\uc885\\ud569\\ud3ec\\ud138\\uc5d0 \\ubcf4\\uc5ec\\uc90c\\r\\n o (\\uc694\\uc591\\uae30\\uad00 \\uc5ed\\ud560) \\ubcf4\\uc720\\ud558\\uace0 \\uc788\\ub294 \\uc758\\ub8cc\\uc815\\ubcf4\\ub97c \\ubcf4\\ud5d8\\uae08 \\uccad\\uad6c\\uc790\\uc758 \\uc694\\uccad\\uc5d0 \\ub530\\ub77c \\uc804\\uc1a1\\r\\n\\u203b \\uc758\\ub8cc\\uc815\\ubcf4\\ub294 \\uc694\\uc591\\uae30\\uad00 EMR \\uc2dc\\uc2a4\\ud15c\\uc744 \\ud1b5\\ud574 \\uc804\\uc1a1\\ub428\\r\\n - \\uc9c4\\ub8cc\\ub0b4\\uc5ed \\uc870\\ud68c : \\uc694\\uccad\\uc790\\uc758\",\n          \"   \\r\\n \\r\\n\\uc81c\\uc548\\uc694\\uccad\\uc11c\\r\\n \\r\\n \\ud1b5\\ud569\\uc815\\ubcf4\\uc2dc\\uc2a4\\ud15c \\uace0\\ub3c4\\ud654 \\uc6a9\\uc5ed\\r\\n\\uc81c\\uc548\\uc694\\uccad\\uc11c\\r\\n2024. 05.\\r\\n   \\r\\n \\r\\n    \\r\\n\\ubcf8 \\uc790\\ub8cc\\ub294 \\ud55c\\uad6d\\ud55c\\uc758\\ud559\\uc5f0\\uad6c\\uc6d0 \\uc81c\\uc548\\uc11c \\uc791\\uc131 \\uc774\\uc678\\uc758 \\ubaa9\\uc801\\uc73c\\ub85c \\ubcf5\\uc81c, \\uc804\\ub2ec \\ubc0f \\uc0ac\\uc6a9\\uc744 \\uae08\\ud568\\r\\n    \\r\\n\\ubaa9   \\ucc28\\r\\n \\u2160. \\uc0ac\\uc5c5 \\uac1c\\uc694\\t  -   \\t 1\\r\\n \\u2161. \\uc0ac\\uc5c5\\ucd94\\uc9c4 \\ubc29\\uc548\\t  -   \\t 3\\r\\n \\u2162. \\uc81c\\uc548 \\uc694\\uccad\\ub0b4\\uc6a9\\t  -   \\t 7\\r\\n\\uc694\\uad6c\\uc0ac\\ud56d \\uad6c\\uc131\\t  -   \\t 7   \\r\\n\\uc694\\uad6c\\uc0ac\\ud56d \\ubaa9\\ub85d\\t  -   \\t 8   \\r\\n\\uc694\\uad6c\\uc0ac\\ud56d \\uc0c1\\uc138\\t  -   \\t10   \\r\\n- \\uae30\\ub2a5    \\uc694\\uad6c\\uc0ac\\ud56d \\t  -   \\t 10   \\r\\n- \\uc131\\ub2a5    \\uc694\\uad6c\\uc0ac\\ud56d \\t  -   \\t 18  \\r\\n- \\uc778\\ud130\\ud398\\uc774\\uc2a4    \\uc694\\uad6c\\uc0ac\\ud56d \\t  -   \\t 20   \\r\\n- \\ub370\\uc774\\ud130    \\uc694\\uad6c\\uc0ac\\ud56d \\t  -   \\t 22   \\r\\n- \\ud14c\\uc2a4\\ud2b8 \\uc694\\uad6c\\uc0ac\\ud56d \\t  -   \\t 27   \\r\\n- \\ubcf4\\uc548 \\uc694\\uad6c\\uc0ac\\ud56d \\t  -   \\t  30   \\r\\n- \\ud488\\uc9c8 \\uc694\\uad6c\\uc0ac\\ud56d \\t  -   \\t 33   \\r\\n- \\uc81c\\uc57d\\uc0ac\\ud56d \\t  -   \\t 34   \\r\\n- \\ud504\\ub85c\\uc81d\\ud2b8\\uad00\\ub9ac \\uc694\\uad6c\\uc0ac\\ud56d \\t  -   \\t 37   \\r\\n- \\ud504\\ub85c\\uc81d\\ud2b8\\uc9c0\\uc6d0 \\uc694\\uad6c\\uc0ac\\ud56d \\t  -   \\t 39   \\r\\n  \\r\\n \\u2163. \\uc81c\\uc548\\uc11c \\ud3c9\\uac00 \\ubc0f \\uc0ac\\uc5c5\\uc790 \\uc120\\uc815\\t  -   \\t 41\\r\\n\\uc120\\uc815 \\ubc29\\uc2dd\\t  -   \\t 41    \\r\\n\\uc785\\ucc30 \\ucc38\\uac00 \\uc790\\uaca9 \\t  -   \\t 41    \\r\\n\\uc81c\\uc548\\uc11c \\ud3c9\\uac00\\uae30\\uc900\\t  -   \\t 42    \\r\\n\\uc81c\\uc548\\uc0ac \\uc720\\uc758\\uc0ac\\ud56d \\t  -   \\t 42    \\r\\n\\uc81c\\uc548\\uc11c \\uc791\\uc131\\uae30\\uc900 \\t  -   \\t 46    \\r\\n\\uc81c\\uc548\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF 샘플 로딩"
      ],
      "metadata": {
        "id": "Qf2gR73jD99S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_df = df[df['파일형식'] == 'pdf']\n",
        "pdf_filename = pdf_df.iloc[0]['파일명'] # 고려대학교_차세대 포털·학사 정보시스템 구축사업.pdf\n",
        "pages = load_pymupdf4llm_easyocr(pdf_filename) # 추후 pages를 반환하도록 변경해야 함.\n",
        "markdown_output = '\\n\\n---\\n\\n'.join([p.page_content for p in pages])\n",
        "with open(ext(pdf_filename, 'md'), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(markdown_output)\n",
        "print(f\"PDF 처리 완료. {ext(pdf_filename, 'md')} 파일 생성.\")"
      ],
      "metadata": {
        "id": "oyWPNEwNIi-2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T04:04:21.614554Z",
          "iopub.execute_input": "2025-09-16T04:04:21.615317Z",
          "iopub.status.idle": "2025-09-16T04:04:21.633257Z",
          "shell.execute_reply.started": "2025-09-16T04:04:21.615298Z",
          "shell.execute_reply": "2025-09-16T04:04:21.632509Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b750f1d0-71be-48f6-fc0e-b5d8ec68c81c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'outputs/고려대학교_차세대 포털·학사 정보시스템 구축사업.pkl' 파일에서 pages를 로드했습니다.\n",
            "PDF 처리 완료. 고려대학교_차세대 포털·학사 정보시스템 구축사업.md 파일 생성.\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HWP 샘플 로딩"
      ],
      "metadata": {
        "id": "cFnZJ4WrWv3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시 사용\n",
        "hwp_filename = df.iloc[0]['파일명'] # 한영대학_한영대학교 특성화 맞춤형 교육환경 구축 - 트랙운영 학사정보.hwp\n",
        "print(f\"원본 파일명: {hwp_filename}\")\n",
        "print(f\".pkl 파일명: {ext(hwp_filename)}\")\n",
        "\n",
        "filename_to_find = '전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축.hwp'\n",
        "found_row = df[df['파일명'] == filename_to_find]\n",
        "\n",
        "if not found_row.empty:\n",
        "    print(f\"'{filename_to_find}' 파일을 찾았습니다.\")\n",
        "    display(found_row)\n",
        "else:\n",
        "    print(f\"'{filename_to_find}' 파일을 찾을 수 없습니다.\")\n"
      ],
      "metadata": {
        "id": "459041ba",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T04:04:21.635465Z",
          "iopub.execute_input": "2025-09-16T04:04:21.635668Z",
          "iopub.status.idle": "2025-09-16T04:04:21.648884Z",
          "shell.execute_reply.started": "2025-09-16T04:04:21.635653Z",
          "shell.execute_reply": "2025-09-16T04:04:21.648356Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "85bd35bc-f83e-4e4c-8b27-d362e98d3f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 파일명: 한영대학_한영대학교 특성화 맞춤형 교육환경 구축 - 트랙운영 학사정보.hwp\n",
            ".pkl 파일명: 한영대학_한영대학교 특성화 맞춤형 교육환경 구축 - 트랙운영 학사정보.pkl\n",
            "'전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축.hwp' 파일을 찾았습니다.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          공고 번호  공고 차수                           사업명        사업 금액  발주 기관  \\\n",
              "20  20240903688    0.0  JST 공유대학(원) xAPI기반 LRS시스템 구축  116000000.0  전북대학교   \n",
              "\n",
              "                  공개 일자            입찰 참여 시작일            입찰 참여 마감일  \\\n",
              "20  2024-09-04 15:01:14  2024-09-05 09:00:00  2024-09-19 12:00:00   \n",
              "\n",
              "                                                사업 요약 파일형식  \\\n",
              "20  - 사업개요: JST 공유대학(원)에서 xAPI 기반 LRS시스템을 구축하는 사업\\...  hwp   \n",
              "\n",
              "                                       파일명  \\\n",
              "20  전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축.hwp   \n",
              "\n",
              "                                                  텍스트  \n",
              "20     \\r\\n   \\r\\n \\r\\n \\r\\n JST 공유대학(원) xAPI기반 LR...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71ce2f26-24a3-4cab-8dc4-b6023431637b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>공고 번호</th>\n",
              "      <th>공고 차수</th>\n",
              "      <th>사업명</th>\n",
              "      <th>사업 금액</th>\n",
              "      <th>발주 기관</th>\n",
              "      <th>공개 일자</th>\n",
              "      <th>입찰 참여 시작일</th>\n",
              "      <th>입찰 참여 마감일</th>\n",
              "      <th>사업 요약</th>\n",
              "      <th>파일형식</th>\n",
              "      <th>파일명</th>\n",
              "      <th>텍스트</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20240903688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>JST 공유대학(원) xAPI기반 LRS시스템 구축</td>\n",
              "      <td>116000000.0</td>\n",
              "      <td>전북대학교</td>\n",
              "      <td>2024-09-04 15:01:14</td>\n",
              "      <td>2024-09-05 09:00:00</td>\n",
              "      <td>2024-09-19 12:00:00</td>\n",
              "      <td>- 사업개요: JST 공유대학(원)에서 xAPI 기반 LRS시스템을 구축하는 사업\\...</td>\n",
              "      <td>hwp</td>\n",
              "      <td>전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축.hwp</td>\n",
              "      <td>\\r\\n   \\r\\n \\r\\n \\r\\n JST 공유대학(원) xAPI기반 LR...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71ce2f26-24a3-4cab-8dc4-b6023431637b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71ce2f26-24a3-4cab-8dc4-b6023431637b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71ce2f26-24a3-4cab-8dc4-b6023431637b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_3260dc16-8c11-40e3-8f6b-7a1a7f6f3272\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('found_row')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3260dc16-8c11-40e3-8f6b-7a1a7f6f3272 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('found_row');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "found_row",
              "repr_error": "0"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 실행 예시 =====\n",
        "hwp_filename = \"전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축.hwp\"\n",
        "documents = load_hwp5html_easyocr(hwp_filename)\n",
        "markdown_output = '\\n\\n---\\n\\n'.join([p.page_content for p in documents])\n",
        "with open(ext(hwp_filename, 'md'), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(markdown_output)\n",
        "print(f\"PDF 처리 완료. {ext(hwp_filename, 'md')} 파일 생성.\")\n",
        "print(markdown_output[:1200])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T04:04:21.649627Z",
          "iopub.execute_input": "2025-09-16T04:04:21.649799Z",
          "iopub.status.idle": "2025-09-16T04:04:21.665776Z",
          "shell.execute_reply.started": "2025-09-16T04:04:21.649786Z",
          "shell.execute_reply": "2025-09-16T04:04:21.665208Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEP5_ChVWv3X",
        "outputId": "a46323d3-90b2-4dde-f516-aebb96cd43ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'outputs/전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축.pkl' 파일에서 pages를 로드했습니다.\n",
            "PDF 처리 완료. 전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축.md 파일 생성.\n",
            "|  |  |\n",
            "| --- | --- |\n",
            "| 「JST공유대학(원)xAPI기반LRS시스템 구축」제 안 요 청 서 |\n",
            "|  |  |\n",
            "「 JST 공유대학(원) xAPI 기반 LRS 시스템 구축 」\n",
            "제 안 요 청 서\n",
            "2024. 9.\n",
            "| 사 업 명 | JST공유대학(원)xAPI기반LRS시스템 구축 |\n",
            "| --- | --- |\n",
            "| 주관기관 | 전북지역혁신플랫폼 대학교육혁신본부 |\n",
            "사 업 명\n",
            "JST 공유대학(원) xAPI 기반 LRS 시스템 구축\n",
            "주관기관\n",
            "전북지역혁신플랫폼 대학교육혁신본부\n",
            "| Ⅰ |  | 사업안내 |\n",
            "| --- | --- | --- |\n",
            "Ⅰ\n",
            "사업안내\n",
            "1. 사업개요\n",
            "□ 사 업 명: JST 공유대학(원) xAPI 기반 LRS 시스템 구축\n",
            "□ 주관기관: 전북지역혁신플랫폼 대학교육혁신본부\n",
            "□ 사업기간: 계약체결일로부터 75일까지\n",
            "□ 사업예산: 금116,000,000원(금일억일천육백만원, 부가세 포함)\n",
            "□ 계약방법: 제한(총액)경쟁입찰(협상에 의한 계약)\n",
            "2. 추진배경 및 사업목적\n",
            "□ 추진배경\n",
            "❍ (학습 데이터의 통합 관리) 기존의 LMS 나 다양한 학습 플랫폼에서 발생하는 데이터를 통합적으로 관리하고 분석할 필요성 증가\n",
            "❍ (개인 맞춤형 학습 환경 구축) 학습자의 다양한 학습 데이터를 수집 및 분석하여 학습자의 패턴을 파악하여 학습자에게 맞춤형 학습 경로 제공\n",
            "❍ (데이터 기반의 의사결정) JST 공유대학(원) 학습 데이터를 분석하여 교육 정책 수립에 필요한 정보를 제공하고, 교육 효과를 객관적으로 평가 할 수 있는 교육 데이터 기반의 정책 의사결정 지원 체계 요구\n",
            "❍ 초개인화 LRS(Learning Record Store) 구축: 빅데이터에 기반한 학습자의 학습분석을 바탕으로, 개인 맞춤별 학습경로를 제공하여 학습 효과 극 대화 필요\n",
            "□ 사업목적\n",
            "❍ xAPI 기반으로 학습자의 다양한 학습활동 데이터 수집 체계 구축\n",
            "❍ 분석된 학습 활동 데이터를 바탕으로 학습자 맞춤형 학습 경로 제공\n",
            "❍ 학습자의 학습효과 향상 및 교수 방법 개선 인사이트 도출\n",
            "3. 사업내용 및 기대효과\n",
            "□ 사업내용\n",
            " JST 공유대학(원) LRS 시스템 구축안 구성도\n",
            "❍ 현재 운영 중인 JST 공유대학( ) 내 통합 및 개편하고, 학 사 및 비교과 시스템과 연계하여 xAPI 기반의 LRS 시스템 구축\n",
            "❍ 데이터 중심 JST 공유대학(원) 생태계 조성에 필요한 학습 데이터 저장 및 운영 체계 구축\n",
            "- ADL(Advanced Distributed Lea\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 싱글턴 백터스토어 생성"
      ],
      "metadata": {
        "id": "aS0kROZLWv3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "def create_context(df):\n",
        "    VERSION = 'v1'\n",
        "    EMB_NAME = 'intfloat/multilingual-e5-large-instruct'\n",
        "    STORED_FOLDER = f'faiss-{VERSION}'\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = load_secret(\"GOOGLE_API_KEY\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = load_secret(\"OPENAI_API_KEY\")\n",
        "    embedding = HuggingFaceEmbeddings(model_name=EMB_NAME, multi_process=True) # GPU가 2개이기 때문임\n",
        "\n",
        "    def save_vectorstore(documents):\n",
        "        # 새로운 문서가 있을 경우, 기존 인덱스에 추가\n",
        "        print(f\"{len(documents)}개의 새로운 문서를 vectorstore에 추가합니다.\")\n",
        "        vectorstore.add_documents(documents=documents)\n",
        "        vectorstore.save_local(STORED_FOLDER) # 변경된 인덱스 저장\n",
        "        print(f\"업데이트된 vectorstore를 '{STORED_FOLDER}' 폴더에 저장했습니다.\")\n",
        "        return vectorstore\n",
        "\n",
        "    def create_documents(df):\n",
        "        \"\"\"\n",
        "        DataFrame의 각 행을 순회하며 LangChain Document 객체를 생성합니다.\n",
        "        '텍스트' 컬럼을 page_content로 사용하고, 나머지 컬럼을 메타데이터로 추가합니다.\n",
        "        \"\"\"\n",
        "        documents = []\n",
        "\n",
        "        # NaN 값을 빈 문자열로 대체하여 메타데이터에 문제가 없도록 처리\n",
        "        df = df.fillna('')\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "            # page_content는 '텍스트' 컬럼의 내용으로 설정\n",
        "            print(f\"이건 {index + 1}번째 문서: {row['사업명']}\")\n",
        "            page_content = str(row['텍스트'])\n",
        "\n",
        "            # 메타데이터 딕셔너리 생성\n",
        "            metadata = {\n",
        "                '공고 번호': row['공고 번호'],\n",
        "                '사업명': row['사업명'],\n",
        "                '사업 금액': row['사업 금액'],\n",
        "                '발주 기관': row['발주 기관'],\n",
        "                '공개 일자': row['공개 일자'],\n",
        "                '입찰 참여 시작일': row['입찰 참여 시작일'],\n",
        "                '입찰 참여 마감일': row['입찰 참여 마감일'],\n",
        "                '사업 요약': row['사업 요약'],\n",
        "                '파일명': row['파일명']\n",
        "            }\n",
        "\n",
        "            # Document 객체 생성\n",
        "            docs = load_documents(row['파일명'], metadata=metadata)\n",
        "            documents.extend(docs)\n",
        "\n",
        "        return documents\n",
        "\n",
        "    def print_pipe(x):\n",
        "        print(\"--- 랭체인 중간 결과 ---\")\n",
        "        print(x)\n",
        "        print(\"-------------------------\")\n",
        "        return x\n",
        "\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    def load_llm_gemini():\n",
        "        llm = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-2.5-flash\", temperature=0.2, thinking_budget=0,  # reasoning 비활성화\n",
        "            max_output_tokens=1000,  # HuggingFacePipeline의 max_new_tokens에 해당\n",
        "        )\n",
        "        return llm\n",
        "\n",
        "    # OpenAI LLM 로드 함수 (새로 추가)\n",
        "    def load_llm_openai():\n",
        "        llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0.2, max_tokens=1000)\n",
        "        return llm\n",
        "\n",
        "    def create_chain(retriever, llm):\n",
        "        prompt = PromptTemplate(\n",
        "            template=(\n",
        "                \"다음 문맥만을 근거로 질문에 답변하세요.\\n\"\n",
        "                \"- 반드시 한국어로 답변하세요.\\n\"\n",
        "                \"- 문맥에 없는 내용은 '모르겠습니다'라고 답하세요.\\n\"\n",
        "                \"- 금액/기한/요건은 원문과 일치하게 유지하세요.\\n\\n\"\n",
        "                \"문맥:\\n{context}\\n\\n\"\n",
        "                \"질문:\\n{question}\\n\\n\"\n",
        "                \"답변:\"\n",
        "            ),\n",
        "            input_variables=[\"context\", \"question\"]\n",
        "        )\n",
        "        chain = (\n",
        "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "            | prompt | llm | StrOutputParser()\n",
        "        )\n",
        "        return chain\n",
        "\n",
        "    def create_default_chain(retriever, llm):\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\",\n",
        "             \"다음 문맥만을 근거로 질문에 답변하세요.\\n\"\n",
        "             \"- 반드시 한국어로 답변하세요.\\n\"\n",
        "             \"- 문맥에 없는 내용은 '모르겠습니다'라고 답하세요.\\n\"\n",
        "             \"- 금액/기한/요건은 원문과 일치하게 유지하세요.\"\n",
        "            ),\n",
        "            (\"human\", \"문맥:\\n{context}\\n\\n질문:\\n{question}\")\n",
        "        ])\n",
        "\n",
        "        chain = (\n",
        "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "            | prompt | RunnableLambda(print_pipe) | llm | RunnableLambda(print_pipe) | StrOutputParser()\n",
        "        )\n",
        "        return chain\n",
        "\n",
        "    # 1. 기존 FAISS 인덱스 로드 또는 새로 생성\n",
        "    if os.path.exists(STORED_FOLDER):\n",
        "        vectorstore = FAISS.load_local(STORED_FOLDER, embedding, allow_dangerous_deserialization=True)\n",
        "        print(f\"'{STORED_FOLDER}' 폴더에서 vectorstore를 로드했습니다.\")\n",
        "    else:\n",
        "        # 인덱스가 없을 경우, 더미 문서를 사용해 인덱스 초기 생성\n",
        "        dummy_docs = [Document(page_content=\"초기 생성을 위한 더미 문서입니다.\")]\n",
        "        vectorstore = FAISS.from_documents(documents=dummy_docs, embedding=embedding)\n",
        "        print(f\"새로운 vectorstore를 더미 문서로 생성했습니다.\")\n",
        "        documents = create_documents(df)\n",
        "        save_vectorstore(documents)\n",
        "\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    llm = load_llm_openai() # load_llm_gemini()\n",
        "    chain = create_default_chain(retriever, llm)\n",
        "    return save_vectorstore, chain\n",
        "\n",
        "df = load_csv('data_list.csv')\n",
        "# hwp_filename = \"전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축.hwp\"\n",
        "# documents = load_documents(hwp_filename)\n",
        "save_vectorstore, chain = create_context(df)\n",
        "# vectorstore = save_vectorstore(documents)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T07:04:50.422322Z",
          "iopub.execute_input": "2025-09-16T07:04:50.422647Z",
          "iopub.status.idle": "2025-09-16T07:04:50.465615Z",
          "shell.execute_reply.started": "2025-09-16T07:04:50.422624Z",
          "shell.execute_reply": "2025-09-16T07:04:50.464665Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_nLjU3JRWv3X",
        "outputId": "7ff044a1-fc51-4e93-c05b-5a895057447e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] data_list.csv 로드 완료.\n",
            "'faiss-v1' 폴더에서 vectorstore를 로드했습니다.\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf 'outputs/한국농어촌공사_아세안+3 식량안보정보시스템(AFSIS) 3단계 협력(캄보디아.pkl'\n",
        "# !rm -rf 'temp_hwp_html/한국농어촌공사_아세안+3 식량안보정보시스템(AFSIS) 3단계 협력(캄보디아.html'\n",
        "# !rm -rf temp_hwp_html\n",
        "# !rm -rf 'outputs/한국농어촌공사_아세안+3 식량안보정보시스템(AFSIS) 3단계 협력(캄보디아.pkl'\n",
        "# !rm -rf 'outputs/[긴급] [지문] [국제] 우즈베키스탄 열린 의정활동 상하원 국회 방송시스템 구축 및 지역의회 연계 개선 PMC 용역.pkl'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T05:03:20.396566Z",
          "iopub.execute_input": "2025-09-16T05:03:20.397705Z",
          "iopub.status.idle": "2025-09-16T05:03:21.003064Z",
          "shell.execute_reply.started": "2025-09-16T05:03:20.397667Z",
          "shell.execute_reply": "2025-09-16T05:03:21.001930Z"
        },
        "id": "hB4YSqsCWv3Y"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 싱글턴 실행하기"
      ],
      "metadata": {
        "id": "rXXnfnshWv3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(timer(lambda: chain.invoke(\"컨설팅 요구사항에 대해서 설명해 주세요.\")))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T07:02:06.294905Z",
          "iopub.execute_input": "2025-09-16T07:02:06.295504Z",
          "iopub.status.idle": "2025-09-16T07:02:25.996008Z",
          "shell.execute_reply.started": "2025-09-16T07:02:06.295483Z",
          "shell.execute_reply": "2025-09-16T07:02:25.995403Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqyGNg0ZWv3Z",
        "outputId": "2599791b-e34e-4040-eff2-f67f414eeab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 랭체인 중간 결과 ---\n",
            "messages=[SystemMessage(content=\"다음 문맥만을 근거로 질문에 답변하세요.\\n- 반드시 한국어로 답변하세요.\\n- 문맥에 없는 내용은 '모르겠습니다'라고 답하세요.\\n- 금액/기한/요건은 원문과 일치하게 유지하세요.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='문맥:\\n| 산출정보 |  |\\n| 관련 요구사항 |  |\\n\\n| 산출정보 |  |\\n| 관련요구사항 |  |\\n\\n| 산출정보 |  |\\n| 관련요구사항 |  |\\n\\n연 번\\n구분\\n설명\\n개수\\n1\\n컨설팅 요구사항\\n(CSR, Consulting Requirement)\\n- 정보 자산의 기밀성과 무결성을 확보하기 위 해 목표 시스템의 데이터 및 기능, 운영 접근 을 통제하기 위한 요구사항을 기술\\n8\\n2\\n데이터 요구사항\\n(DAR, Data Requirement)\\n- 정보시스템 구축을 위한 DB 구축 및 데이터 구조 설계 요구사항을 기술\\n7\\n3\\n보안 요구사항\\n(SER, Security Requirement)\\n- 정보 자산의 기밀성과 무결성을 확보하기 위 해 목표 시스템의 데이터 및 기능, 운영 접근 을 통제하기 위한 요구사항을 기술\\n5\\n4\\n품질 요구사항\\n(QUR, Quality Requirement)\\n- 목표 사업의 원활한 수행 및 운영을 위해 관리가 필요한 품질 항목, 품질 평가 대상 및 목표에 대 한 요구사항을 기술\\n1\\n5\\n제약 요구사항\\n(COR, Constraint Requirement)\\n- 목표시스템 설계, 구축, 운영과 관련하여 사전 에 파악된 기술 · 표준 · 업무 · 법제도 등 제약조건 등을 파악하여 기술\\n3\\n6\\n프로젝트 관리 요구사항\\n(PMR, Project Management Requirement)\\n- 프로젝트의 원활한 수행을 위한 관리 방법 및 추진 단계별 수행방안에 대한 요구사항을 기술\\n5\\n7\\n프로젝트 지원 요구사항\\n(PSR, Project Support Requirement)\\n- 프로젝트의 원활한 수행을 위해 필요한 지원 사항 및 방안에 대한 요구사항을 기술\\n2\\n※ 제안사는 에 기술된 요구사항을 기반으로 제안하되, 업무분석단계에서 보다 창의적 인 방법으로 요구사항을 해석하고 정제하여 사업에 반영해야 함\\n\\U000f02b2 요 구사항 상세\\n1. 컨설팅 요구사항( CSR)\\n| 요구사항번호 | CSR-001 | 요구사항 분류 | 컨설팅 요구사항 |\\n| --- | --- | --- | --- |\\n| 요구사항 명 | 대내·외 환경분석 |\\n| 상세설명 | 정의 | 대내·외 환경 분석(벤치마킹, 이해관계자 인터뷰, 현 정보서비스 분석 등) |\\n| 세부내용 | ㅇ 인천광역시 취업환경, 노동정책 등 관련 정책현황 및 동향 분석ㅇ 일자리 지원 기관, 부서 간 연계 협업을 위한 내·외부 환경분석ㅇ기관(부서) 담당자 인터뷰를 통한 업무 추진 실태 및 요구사항 도출, 분석ㅇ 일자리, 기업지원, 자원봉사, 사회복지 지원정보 제공을 위한 환경분석ㅇ 최신 정보통신기술(ICT)동향 및 기술 적용 타당성 분석ㅇ 공공기관 및 민간기업 일자리플랫폼 트렌드 파악-타 기관 일자리포털 선진사례 분석 및 벤치마킹(중앙정부, 지자체16개시‧도이상)-고용서비스 플랫폼(취업포털 포함) 등 최신 정보통신기술을 노동시장에 적용한 사례 분석 및 벤치마킹ㅇ 관내 일자리 정보시스템별 서비스, 인프라, 업무 프로세스 분석 등을통한 문제점 진단 및 개선사항 도출(일자리포털 기능 진단 포함)ㅇ 환경, 현황, 문제점, 개선사항, 정보화 요구사항 등을 종합하여 인천일자리플랫폼 정보시스템 구축에 필요한 추진과제 및 방향성 수립- 선진사례, 개선과제 간 갭 분석 및 요구사항 분석 결과, 시사점- 주요 서비스별 분석 및 동향 예측을 통한 방향성 도출 |\\n| 산출정보 | ㅇ 환경분석서, 현황분석서 |\\n\\n질문:\\n컨설팅 요구사항에 대해서 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
            "-------------------------\n",
            "--- 랭체인 중간 결과 ---\n",
            "content='컨설팅 요구사항(CSR)은 정보 자산의 기밀성과 무결성을 확보하기 위해 목표 시스템의 데이터 및 기능, 운영 접근을 통제하는 요구사항을 기술하는 것입니다. 구체적으로는 대내·외 환경 분석(벤치마킹, 이해관계자 인터뷰, 현 정보서비스 분석 등)을 통해 인천광역시의 취업환경, 노동정책, 일자리 지원 기관 및 부서 간 연계 협업 환경, 최신 ICT 동향, 공공기관 및 민간기업의 일자리 플랫폼 사례 등을 분석하고, 이를 바탕으로 문제점 진단과 개선사항 도출, 추진과제 및 방향성 수립을 목적으로 합니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 147, 'prompt_tokens': 939, 'total_tokens': 1086, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CGKyyatkpbIPmAbHRofthi5r5HyWh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--0757c896-2085-46d1-b9d5-937ec3ee5f22-0' usage_metadata={'input_tokens': 939, 'output_tokens': 147, 'total_tokens': 1086, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "-------------------------\n",
            "실행 시간: 27.3187초\n",
            "컨설팅 요구사항(CSR)은 정보 자산의 기밀성과 무결성을 확보하기 위해 목표 시스템의 데이터 및 기능, 운영 접근을 통제하는 요구사항을 기술하는 것입니다. 구체적으로는 대내·외 환경 분석(벤치마킹, 이해관계자 인터뷰, 현 정보서비스 분석 등)을 통해 인천광역시의 취업환경, 노동정책, 일자리 지원 기관 및 부서 간 연계 협업 환경, 최신 ICT 동향, 공공기관 및 민간기업의 일자리 플랫폼 사례 등을 분석하고, 이를 바탕으로 문제점 진단과 개선사항 도출, 추진과제 및 방향성 수립을 목적으로 합니다.\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "print(timer(lambda: chain.invoke('전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축에 관련하여 설명해 주세요.')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF2_GNM1eda4",
        "outputId": "00fd0218-5b6d-493c-8737-cf000a5869e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 랭체인 중간 결과 ---\n",
            "messages=[SystemMessage(content=\"다음 문맥만을 근거로 질문에 답변하세요.\\n- 반드시 한국어로 답변하세요.\\n- 문맥에 없는 내용은 '모르겠습니다'라고 답하세요.\\n- 금액/기한/요건은 원문과 일치하게 유지하세요.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='문맥:\\n|  |  |\\n| --- | --- |\\n| 「JST공유대학(원)xAPI기반LRS시스템 구축」제 안 요 청 서 |\\n|  |  |\\n「 JST 공유대학(원) xAPI 기반 LRS 시스템 구축 」\\n제 안 요 청 서\\n2024. 9.\\n| 사 업 명 | JST공유대학(원)xAPI기반LRS시스템 구축 |\\n| --- | --- |\\n| 주관기관 | 전북지역혁신플랫폼 대학교육혁신본부 |\\n사 업 명\\nJST 공유대학(원) xAPI 기반 LRS 시스템 구축\\n주관기관\\n전북지역혁신플랫폼 대학교육혁신본부\\n| Ⅰ |  | 사업안내 |\\n| --- | --- | --- |\\nⅠ\\n사업안내\\n1. 사업개요\\n□ 사 업 명: JST 공유대학(원) xAPI 기반 LRS 시스템 구축\\n□ 주관기관: 전북지역혁신플랫폼 대학교육혁신본부\\n□ 사업기간: 계약체결일로부터 75일까지\\n□ 사업예산: 금116,000,000원(금일억일천육백만원, 부가세 포함)\\n□ 계약방법: 제한(총액)경쟁입찰(협상에 의한 계약)\\n2. 추진배경 및 사업목적\\n□ 추진배경\\n❍ (학습 데이터의 통합 관리) 기존의 LMS 나 다양한 학습 플랫폼에서 발생하는 데이터를 통합적으로 관리하고 분석할 필요성 증가\\n❍ (개인 맞춤형 학습 환경 구축) 학습자의 다양한 학습 데이터를 수집 및 분석하여 학습자의 패턴을 파악하여 학습자에게 맞춤형 학습 경로 제공\\n❍ (데이터 기반의 의사결정) JST 공유대학(원) 학습 데이터를 분석하여 교육 정책 수립에 필요한 정보를 제공하고, 교육 효과를 객관적으로 평가 할 수 있는 교육 데이터 기반의 정책 의사결정 지원 체계 요구\\n❍ 초개인화 LRS(Learning Record Store) 구축: 빅데이터에 기반한 학습자의 학습분석을 바탕으로, 개인 맞춤별 학습경로를 제공하여 학습 효과 극 대화 필요\\n□ 사업목적\\n❍ xAPI 기반으로 학습자의 다양한 학습활동 데이터 수집 체계 구축\\n❍ 분석된 학습 활동 데이터를 바탕으로 학습자 맞춤형 학습 경로 제공\\n❍ 학습자의 학습효과 향상 및 교수 방법 개선 인사이트 도출\\n3. 사업내용 및 기대효과\\n□ 사업내용\\n\\uf06d JST 공유대학(원) LRS 시스템 구축안 구성도\\n❍ 현재 운영 중인 JST 공유대학( ) 내 통합 및 개편하고, 학 사 및 비교과 시스템과 연계하여 xAPI 기반의 LRS 시스템 구축\\n❍ 데이터 중심 JST 공유대학(원) 생태계 조성에 필요한 학습 데이터 저장 및 운영 체계 구축\\n- ADL(Advanced Distributed Learning) 의 xAPI 표준 체계를 지원\\n- LRP(Learning Record Provider), LRS, LRC(Learning Record Consumer) 체계에 따른 xAPI 데이터를 실시간 저장 및 관리 할 수 있는 시스템 구성\\n- 공유대학(원) 내에서 발생하는 학생들의 모든 학습 경험 기록을 실시간 수집 관리할 수 있는 에듀테크 데이터 표준체계 구축\\n- 온라인 및 오프라인 학습 활동 및 성과 데이터의 저장 관리를 지원하고 블렌디드 러닝 중심의 평생학습 체계를 지원할 수 있는 글로벌 표준 LRS 규격을 준수\\n- GS 인증 및 조달청 등록 제품에 대한 우선적 도입 진행\\n❍ 수집할 학습분석 요소를 정의하고, 사용자별 필요한 학습 지표 설계 및 대시보드에 대한 시각화\\n\\n본인 은 JST 공유대학(원) xAPI 기반 LRS 시스템 구축 진행을 위하여 위와 같이 개인 정보 처리에 관한 사항을 확인하였으며 이를 이해하고 동의합니다.\\n2024년    월     일\\n대표자:                 (인) / 입찰등록자 :                 (서명)\\n전북지역혁신플랫폼 대학교육혁신본부장 귀하\\n[ 서식 9 ]\\n확    약    서\\n입찰 건명 : JST 공유대학(원) xAPI 기반 LRS 시스템 구축\\n본인은 기술제안서의 제반사항을 사실에 근거하여 작성하였고, 이에 따른 법 률적, 재정적, 행정적 책임을 감수하겠습니다.\\n또한, JST 공유대학(원) xAPI 기반 LRS 시스템 구축 용역 사업자 선정방식 및 제 안요청서 내용과 본 입찰에 관련된 전북지역혁신플랫폼 대학교육혁신본부의 방 침에 이의가 없음을 확약하며 어떠한 법적 이의를 제기하지 않겠습니다.\\n그리고 전북지역혁신플랫폼 대학교육혁신본부가 기술평가를 위해 구성한 내 · 외부 평가위원과 평가방법 및 평가기준에 따른 결과를 수용하고, 본 제안서의 허위기재 또는 자료 부실로 인한 평가 상의 불이익은 물론 부정당업자 제재 또 는 낙찰대상에서 제외 등 전북지역혁신플랫폼 대학교육혁신본부의 어떠한 결정 사항도 존중하며 이에 대해 이의 제기하지 않을 것을 확약합니다.\\n2024년   월     일\\n주  소 :\\n회사명 :\\n사업자등록번호 :\\n대    표    자 :                  (인)\\n전북지역혁신플랫폼 대학교육혁신본부장 귀하\\n\\n2024.    .      .\\n서 약 자 : ○○○ 회사   대 표 ○ ○ ○ \\U000f0099\\n전북지역혁신플랫폼 대학교육혁신본부장 귀하\\n[ 서식 8 ]\\n개인정보 수집 및 활용 동의서\\nJST 공유대학(원) xAPI 기반 LRS 시스템 구축 참여자는 본 개인정보 수집 및 활용 동의서 를 각각 1부씩 제출하여야 함.\\n| 입찰등록자 | 업  체  명 |  | 부  서  명 |  |\\n| --- | --- | --- | --- | --- |\\n| 전화번호 |  | 성       명 |  |\\n| ▢개인정보 수집 및 활용 동의서 제출 대상◦JST공유대학(원)xAPI기반LRS시스템 구축참여자- 참여업체 대표자, 입찰참가 신청자 및 권한 수임자, 상주인력, 긴급전담반▢개인정보의 수집 및 활용◦개인정보 수집 및 활용 목적- 사업 추진을 위한 입찰 서류 및 입찰 관련 권한 수임 확인- 사업 참여자 신원 및 자격 확인◦수집하는 개인정보 항목- 참여업체 대표자, 입찰참가신청자 : 성명, 소속(업체명, 부서), 휴대폰번호- 입찰권한 수임자 : 성명, 소속(업체명, 부서), 주소, 휴대폰번호-사업 상주인력 및 긴급전담반 : 성명, 소속, 연령, 전화번호, 주소 및 자격증, 경력증명서,재직증명서 등 제출 서류 일체◦개인정보의 보유 및 활용기간- 개인정보 보유기간 : 본 동의서 접수일로부터 최대 3년- 개인정보 활용기간 : 본 동의서 접수일로부터 최대 2개월- 동의거부 권리 안내 : 동의인은 본 개인정보 수집에 대한 동의를 거부할 수 있음.(단, 이 경우 본부에서 진행하는 사업에 참여할 수 없거나, 입찰에 관한 권한을 수임 받을 수 없음)본인은JST공유대학(원)xAPI기반LRS시스템 구축진행을위하여 위와 같이 개인정보 처리에 관한 사항을 확인하였으며 이를 이해하고 동의합니다.2024년    월     일대표자:                 (인) / 입찰등록자 :                 (서명)전북지역혁신플랫폼 대학교육혁신본부장 귀하 |\\n입찰등록자\\n업  체  명\\n부  서  명\\n전화번호\\n성       명\\n▢ 개인정보 수집 및 활용 동의서 제출 대상\\n◦ JST 공유대학(원) xAPI 기반 LRS 시스템 구축 참여자\\n- 참여업체 대표자, 입찰참가 신청자 및 권한 수임자, 상주인력, 긴급전담반\\n▢ 개인정보의 수집 및 활용\\n◦ 개인정보 수집 및 활용 목적\\n- 사업 추진을 위한 입찰 서류 및 입찰 관련 권한 수임 확인\\n- 사업 참여자 신원 및 자격 확인\\n◦ 수집하는 개인정보 항목\\n- 참여업체 대표자, 입찰참가신청자 : 성명, 소속(업체명, 부서), 휴대폰번호\\n- 입찰권한 수임자 : 성명, 소속(업체명, 부서), 주소, 휴대폰번호\\n- 사업 상주인력 및 긴급전담반 : 성명, 소속, 연령, 전화번호, 주소 및 자격증, 경력증명서, 재 직증명서 등 제출 서류 일체\\n◦ 개인정보의 보유 및 활용기간\\n- 개인정보 보유기간 : 본 동의서 접수일로부터 최대 3년\\n- 개인정보 활용기간 : 본 동의서 접수일로부터 최대 2개월\\n- 동의거부 권리 안내 : 동의인은 본 개인정보 수집에 대한 동의를 거부할 수 있음.\\n(단, 이 경우 본부에서 진행하는 사업에 참여할 수 없거나, 입찰에 관한 권한을 수임 받을 수 없음)\\n\\n❍ xAPI Data 질의조회 API(GraphQL) 지원\\n❍ xAPI 실시간으로 추출하여 시각화하는 대쉬보드 기능 지원\\n❍ CMI5, Video Profile 및 다양한 ADL 학습분석 프로파일 모델 지원\\n❍ GS 인증 1/2 등급 및 조달청 디지털 서비스몰 등록 제품 우선 도입\\n❍ 개인정보보호, 정보보안 등 공공기관 표준지침 준수를 통해 보안 관련 법률에 어긋나지 않는 안정적 사이트 구현\\n3. 클라우드 서비스 적용\\n❍ Cloud 환경 또는 서버 환경\\n- 클라우드 및 서버 환경에서 xAPI 모델 설계를 위한 파일롯 테스트용 LRS 시스템 설치 및 모델 개발 지원\\n- xAPI v1.0, v1.0.3 표준 Statement 지원\\n- 실시간 xAPI Validation 기능\\n- 실시간 데이터 정렬 ‧ 집계 ‧ 조회 기능을 쿼리( SQL, Graphql, Restful API 등)으로 지원\\n- 최소 6종의 차트 시각화를 통한 데이터 검색 기능 지원\\n- 가상화 기술을 이용한 Auto Scale In/Out 기능 지원\\n- 저장된 xAPI Data 를 실시간으로 분산할 수 있는 샤딩기술 지원\\n❍ JST 공유대학(원) LRS 시스템 서비스 운영을 위한 안정화 및 보안 강 화 지원\\n- (인프라관제) 24 시간 × 365 일 무중단 인프라 관제를 통해 안정적인 서비스 운영 기반 마련\\n- (S/W 업데이트) 안정적 운영을 위한 주기적 S/W 업데이트 적용\\n- (보안 강화) 웹 방화벽 설치 및 모니터링 등 대응 및 관리 시행\\n- (장애 대응) 서비스 및 인프라 장애 발생 시 신속한 조치 및 데이터 백업 수행\\n※ 주기적인 데이터 백업 및 비상연락망 구축을 통한 신속한 장애 대응 체계 마련 및 구축된 JST 공유대학(원) LRS 시스템 운영 안정화 지원\\n- (서비스 이관) JST 공유대학(원) LRS 시스템의 성공적 이관을 위한 제 반기술 지원\\n- (서비스 안정화) JST 공유대학(원) LRS 시스템의 안정적 운영 기반 마 련을 위한 테스트 및 안정화 운영\\n※ 24 시간 × 365 일 안정적 서비스 운영을 위한 제반 기술 지원 및 협력 체제 운영\\n- (협력체계) 장애 발생 등 JST 공유대학(원) LRS 시스템 운영 관련 비상상황 발생 시 비상관리 체제 운영 등\\n※ 서비스 운영 안정화 등을 위한 비상 상주, 장애 대응, 비상 연락망 등\\n3. 상세 요구사항\\n□ 요구사항 총괄표\\n| 구   분 | 설        명 | 개수 |\\n| --- | --- | --- |\\n| 컨설팅-CNR(Consulting Requirement) | 업무 효율성과 생산성을 높이기 위한 정보시스템 구축, 업무프로세스 개선 방안 등의 도출을 위한 요구사항 | 2 |\\n| 시스템 장비구성-ECR(Equipment CompositionRequirement) | 목표사업수행을 위해 필요한 하드웨어, 소프트웨어, 네트워크 등의도입 장비 내역 등 시스템 장비 구성에 대한 요구사항을 기술 | 4 |\\n| 기능-SFR(System FunctionRequirement) | 목표시스템이 반드시 수행하여야 하거나 목표시스템을 이용하여 사용자가 반드시 할 수 있어야 하는 기능에 대한 기술단, 개별 기능요구사항은 전체 시스템의 계층적 구조분석을 통해 단위업무별 기능구조를 도출한 후, 이에 대한 세부 기능별 상세 요구사항을 작성하는 것을 원칙으로 하며, 기능 수행을 위한 데이터 요구사항과 연계를 고려하여 기술함 | 6 |\\n| 성능-PER(PerformanceRequirement) | 목표시스템의 처리속도 및 시간, 처리량, 동적․정적용량, 가용성 등 성능에 대한 요구사항을 기술 | 2 |\\n| 인터페이스-SIR(System InterfaceRequirement) | 목표시스템과 외부를 연결하는 시스템인터페이스와 사용자인터페이스에 대한 요구사항을 기술 | 1 |\\n| 데이터-DAR(Data Requirement) | 목표 시스템의 서비스에 필요한 초기자료 구축 및 데이터 변환을 위한 대상,방법, 보안이 필요한 데이터 등 데이터를 구축하기 위해 필요한 요구사항기술 | 7 |\\n\\n질문:\\n전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축에 관련하여 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
            "-------------------------\n",
            "--- 랭체인 중간 결과 ---\n",
            "content='전북대학교 JST 공유대학(원) xAPI기반 LRS시스템 구축 사업은 2024년 9월에 시작되어 계약체결일로부터 75일간 진행됩니다. 이 사업의 주관기관은 전북지역혁신플랫폼 대학교육혁신본부이며, 총 예산은 116,000,000원(부가세 포함)입니다. 제한(총액)경쟁입찰 방식으로 계약이 이루어집니다.\\n\\n이 사업은 기존의 LMS 및 다양한 학습 플랫폼에서 발생하는 데이터를 통합적으로 관리하고 분석하는 시스템을 구축하는 것을 목표로 합니다. 이를 통해 학습자의 학습 패턴을 파악하고 맞춤형 학습 경로를 제공하며, 데이터 기반의 교육 정책 수립과 효과 평가를 지원합니다. 특히, 빅데이터에 기반한 초개인화 학습 기록 저장소(LRS)를 구축하여 온라인과 오프라인 학습 활동 데이터를 실시간으로 수집, 저장, 분석할 수 있는 체계를 마련하는 것이 핵심 내용입니다.\\n\\n구체적으로, xAPI 표준을 지원하는 데이터 저장 및 운영 체계, 실시간 데이터 수집과 시각화 대시보드, 다양한 학습 분석 프로파일 지원, 그리고 클라우드 환경에서의 안정적 시스템 운영과 보안 강화를 포함한 요구사항이 반영되어 있습니다. 또한, GS 인증 및 조달청 등록 제품 도입 우선권을 확보하며, 개인정보 보호와 정보보안 기준도 준수합니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 324, 'prompt_tokens': 3245, 'total_tokens': 3569, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_04d3664870', 'id': 'chatcmpl-CGKzBcHTXWqVJjXU37MI5FcrURHFJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--790aa695-49ce-4c3a-8282-73cacff70d73-0' usage_metadata={'input_tokens': 3245, 'output_tokens': 324, 'total_tokens': 3569, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "-------------------------\n",
            "실행 시간: 16.4855초\n",
            "전북대학교 JST 공유대학(원) xAPI기반 LRS시스템 구축 사업은 2024년 9월에 시작되어 계약체결일로부터 75일간 진행됩니다. 이 사업의 주관기관은 전북지역혁신플랫폼 대학교육혁신본부이며, 총 예산은 116,000,000원(부가세 포함)입니다. 제한(총액)경쟁입찰 방식으로 계약이 이루어집니다.\n",
            "\n",
            "이 사업은 기존의 LMS 및 다양한 학습 플랫폼에서 발생하는 데이터를 통합적으로 관리하고 분석하는 시스템을 구축하는 것을 목표로 합니다. 이를 통해 학습자의 학습 패턴을 파악하고 맞춤형 학습 경로를 제공하며, 데이터 기반의 교육 정책 수립과 효과 평가를 지원합니다. 특히, 빅데이터에 기반한 초개인화 학습 기록 저장소(LRS)를 구축하여 온라인과 오프라인 학습 활동 데이터를 실시간으로 수집, 저장, 분석할 수 있는 체계를 마련하는 것이 핵심 내용입니다.\n",
            "\n",
            "구체적으로, xAPI 표준을 지원하는 데이터 저장 및 운영 체계, 실시간 데이터 수집과 시각화 대시보드, 다양한 학습 분석 프로파일 지원, 그리고 클라우드 환경에서의 안정적 시스템 운영과 보안 강화를 포함한 요구사항이 반영되어 있습니다. 또한, GS 인증 및 조달청 등록 제품 도입 우선권을 확보하며, 개인정보 보호와 정보보안 기준도 준수합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(timer(lambda: chain.invoke('전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축에 연관하여, 요구사항 목록표 내용을 알려주세요.')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1_OeksgfGMH",
        "outputId": "d5e78042-5807-4942-9676-e7b6b011d682"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 랭체인 중간 결과 ---\n",
            "messages=[SystemMessage(content=\"다음 문맥만을 근거로 질문에 답변하세요.\\n- 반드시 한국어로 답변하세요.\\n- 문맥에 없는 내용은 '모르겠습니다'라고 답하세요.\\n- 금액/기한/요건은 원문과 일치하게 유지하세요.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='문맥:\\n|  |  |\\n| --- | --- |\\n| 「JST공유대학(원)xAPI기반LRS시스템 구축」제 안 요 청 서 |\\n|  |  |\\n「 JST 공유대학(원) xAPI 기반 LRS 시스템 구축 」\\n제 안 요 청 서\\n2024. 9.\\n| 사 업 명 | JST공유대학(원)xAPI기반LRS시스템 구축 |\\n| --- | --- |\\n| 주관기관 | 전북지역혁신플랫폼 대학교육혁신본부 |\\n사 업 명\\nJST 공유대학(원) xAPI 기반 LRS 시스템 구축\\n주관기관\\n전북지역혁신플랫폼 대학교육혁신본부\\n| Ⅰ |  | 사업안내 |\\n| --- | --- | --- |\\nⅠ\\n사업안내\\n1. 사업개요\\n□ 사 업 명: JST 공유대학(원) xAPI 기반 LRS 시스템 구축\\n□ 주관기관: 전북지역혁신플랫폼 대학교육혁신본부\\n□ 사업기간: 계약체결일로부터 75일까지\\n□ 사업예산: 금116,000,000원(금일억일천육백만원, 부가세 포함)\\n□ 계약방법: 제한(총액)경쟁입찰(협상에 의한 계약)\\n2. 추진배경 및 사업목적\\n□ 추진배경\\n❍ (학습 데이터의 통합 관리) 기존의 LMS 나 다양한 학습 플랫폼에서 발생하는 데이터를 통합적으로 관리하고 분석할 필요성 증가\\n❍ (개인 맞춤형 학습 환경 구축) 학습자의 다양한 학습 데이터를 수집 및 분석하여 학습자의 패턴을 파악하여 학습자에게 맞춤형 학습 경로 제공\\n❍ (데이터 기반의 의사결정) JST 공유대학(원) 학습 데이터를 분석하여 교육 정책 수립에 필요한 정보를 제공하고, 교육 효과를 객관적으로 평가 할 수 있는 교육 데이터 기반의 정책 의사결정 지원 체계 요구\\n❍ 초개인화 LRS(Learning Record Store) 구축: 빅데이터에 기반한 학습자의 학습분석을 바탕으로, 개인 맞춤별 학습경로를 제공하여 학습 효과 극 대화 필요\\n□ 사업목적\\n❍ xAPI 기반으로 학습자의 다양한 학습활동 데이터 수집 체계 구축\\n❍ 분석된 학습 활동 데이터를 바탕으로 학습자 맞춤형 학습 경로 제공\\n❍ 학습자의 학습효과 향상 및 교수 방법 개선 인사이트 도출\\n3. 사업내용 및 기대효과\\n□ 사업내용\\n\\uf06d JST 공유대학(원) LRS 시스템 구축안 구성도\\n❍ 현재 운영 중인 JST 공유대학( ) 내 통합 및 개편하고, 학 사 및 비교과 시스템과 연계하여 xAPI 기반의 LRS 시스템 구축\\n❍ 데이터 중심 JST 공유대학(원) 생태계 조성에 필요한 학습 데이터 저장 및 운영 체계 구축\\n- ADL(Advanced Distributed Learning) 의 xAPI 표준 체계를 지원\\n- LRP(Learning Record Provider), LRS, LRC(Learning Record Consumer) 체계에 따른 xAPI 데이터를 실시간 저장 및 관리 할 수 있는 시스템 구성\\n- 공유대학(원) 내에서 발생하는 학생들의 모든 학습 경험 기록을 실시간 수집 관리할 수 있는 에듀테크 데이터 표준체계 구축\\n- 온라인 및 오프라인 학습 활동 및 성과 데이터의 저장 관리를 지원하고 블렌디드 러닝 중심의 평생학습 체계를 지원할 수 있는 글로벌 표준 LRS 규격을 준수\\n- GS 인증 및 조달청 등록 제품에 대한 우선적 도입 진행\\n❍ 수집할 학습분석 요소를 정의하고, 사용자별 필요한 학습 지표 설계 및 대시보드에 대한 시각화\\n\\n본인 은 JST 공유대학(원) xAPI 기반 LRS 시스템 구축 진행을 위하여 위와 같이 개인 정보 처리에 관한 사항을 확인하였으며 이를 이해하고 동의합니다.\\n2024년    월     일\\n대표자:                 (인) / 입찰등록자 :                 (서명)\\n전북지역혁신플랫폼 대학교육혁신본부장 귀하\\n[ 서식 9 ]\\n확    약    서\\n입찰 건명 : JST 공유대학(원) xAPI 기반 LRS 시스템 구축\\n본인은 기술제안서의 제반사항을 사실에 근거하여 작성하였고, 이에 따른 법 률적, 재정적, 행정적 책임을 감수하겠습니다.\\n또한, JST 공유대학(원) xAPI 기반 LRS 시스템 구축 용역 사업자 선정방식 및 제 안요청서 내용과 본 입찰에 관련된 전북지역혁신플랫폼 대학교육혁신본부의 방 침에 이의가 없음을 확약하며 어떠한 법적 이의를 제기하지 않겠습니다.\\n그리고 전북지역혁신플랫폼 대학교육혁신본부가 기술평가를 위해 구성한 내 · 외부 평가위원과 평가방법 및 평가기준에 따른 결과를 수용하고, 본 제안서의 허위기재 또는 자료 부실로 인한 평가 상의 불이익은 물론 부정당업자 제재 또 는 낙찰대상에서 제외 등 전북지역혁신플랫폼 대학교육혁신본부의 어떠한 결정 사항도 존중하며 이에 대해 이의 제기하지 않을 것을 확약합니다.\\n2024년   월     일\\n주  소 :\\n회사명 :\\n사업자등록번호 :\\n대    표    자 :                  (인)\\n전북지역혁신플랫폼 대학교육혁신본부장 귀하\\n\\n❍ xAPI Data 질의조회 API(GraphQL) 지원\\n❍ xAPI 실시간으로 추출하여 시각화하는 대쉬보드 기능 지원\\n❍ CMI5, Video Profile 및 다양한 ADL 학습분석 프로파일 모델 지원\\n❍ GS 인증 1/2 등급 및 조달청 디지털 서비스몰 등록 제품 우선 도입\\n❍ 개인정보보호, 정보보안 등 공공기관 표준지침 준수를 통해 보안 관련 법률에 어긋나지 않는 안정적 사이트 구현\\n3. 클라우드 서비스 적용\\n❍ Cloud 환경 또는 서버 환경\\n- 클라우드 및 서버 환경에서 xAPI 모델 설계를 위한 파일롯 테스트용 LRS 시스템 설치 및 모델 개발 지원\\n- xAPI v1.0, v1.0.3 표준 Statement 지원\\n- 실시간 xAPI Validation 기능\\n- 실시간 데이터 정렬 ‧ 집계 ‧ 조회 기능을 쿼리( SQL, Graphql, Restful API 등)으로 지원\\n- 최소 6종의 차트 시각화를 통한 데이터 검색 기능 지원\\n- 가상화 기술을 이용한 Auto Scale In/Out 기능 지원\\n- 저장된 xAPI Data 를 실시간으로 분산할 수 있는 샤딩기술 지원\\n❍ JST 공유대학(원) LRS 시스템 서비스 운영을 위한 안정화 및 보안 강 화 지원\\n- (인프라관제) 24 시간 × 365 일 무중단 인프라 관제를 통해 안정적인 서비스 운영 기반 마련\\n- (S/W 업데이트) 안정적 운영을 위한 주기적 S/W 업데이트 적용\\n- (보안 강화) 웹 방화벽 설치 및 모니터링 등 대응 및 관리 시행\\n- (장애 대응) 서비스 및 인프라 장애 발생 시 신속한 조치 및 데이터 백업 수행\\n※ 주기적인 데이터 백업 및 비상연락망 구축을 통한 신속한 장애 대응 체계 마련 및 구축된 JST 공유대학(원) LRS 시스템 운영 안정화 지원\\n- (서비스 이관) JST 공유대학(원) LRS 시스템의 성공적 이관을 위한 제 반기술 지원\\n- (서비스 안정화) JST 공유대학(원) LRS 시스템의 안정적 운영 기반 마 련을 위한 테스트 및 안정화 운영\\n※ 24 시간 × 365 일 안정적 서비스 운영을 위한 제반 기술 지원 및 협력 체제 운영\\n- (협력체계) 장애 발생 등 JST 공유대학(원) LRS 시스템 운영 관련 비상상황 발생 시 비상관리 체제 운영 등\\n※ 서비스 운영 안정화 등을 위한 비상 상주, 장애 대응, 비상 연락망 등\\n3. 상세 요구사항\\n□ 요구사항 총괄표\\n| 구   분 | 설        명 | 개수 |\\n| --- | --- | --- |\\n| 컨설팅-CNR(Consulting Requirement) | 업무 효율성과 생산성을 높이기 위한 정보시스템 구축, 업무프로세스 개선 방안 등의 도출을 위한 요구사항 | 2 |\\n| 시스템 장비구성-ECR(Equipment CompositionRequirement) | 목표사업수행을 위해 필요한 하드웨어, 소프트웨어, 네트워크 등의도입 장비 내역 등 시스템 장비 구성에 대한 요구사항을 기술 | 4 |\\n| 기능-SFR(System FunctionRequirement) | 목표시스템이 반드시 수행하여야 하거나 목표시스템을 이용하여 사용자가 반드시 할 수 있어야 하는 기능에 대한 기술단, 개별 기능요구사항은 전체 시스템의 계층적 구조분석을 통해 단위업무별 기능구조를 도출한 후, 이에 대한 세부 기능별 상세 요구사항을 작성하는 것을 원칙으로 하며, 기능 수행을 위한 데이터 요구사항과 연계를 고려하여 기술함 | 6 |\\n| 성능-PER(PerformanceRequirement) | 목표시스템의 처리속도 및 시간, 처리량, 동적․정적용량, 가용성 등 성능에 대한 요구사항을 기술 | 2 |\\n| 인터페이스-SIR(System InterfaceRequirement) | 목표시스템과 외부를 연결하는 시스템인터페이스와 사용자인터페이스에 대한 요구사항을 기술 | 1 |\\n| 데이터-DAR(Data Requirement) | 목표 시스템의 서비스에 필요한 초기자료 구축 및 데이터 변환을 위한 대상,방법, 보안이 필요한 데이터 등 데이터를 구축하기 위해 필요한 요구사항기술 | 7 |\\n\\n요구사항 분류\\n기능 요구사항\\n요구사항 명칭\\nLRS 시스템 구성\\n응락수준\\n필수\\n요구사항 내용\\n❍ ADL 표준 체계에 따른 LRS 시스템 구축\\n- xAPI 데이터를 기반으로 학습의 모든 행위가 실시간으로 LRS 에 수집되고 ADL 표준이 제시하는 xAPI Validation 을 통한 실시간 xAPI 데이터 유효성이 검증되는 시스템을 도입 또는 구축함\\n- 통합학습 및 학습플랫폼을 통한 학습 활동에 대한 xAPI 프로파일을 CMI5 Profile Model 에 근거하여 저장하며, 저장된 데이터를 실시간 검증 조회 할 수 있는 기능 제시 및 검증을 위한 LRS 시스템을 파일롯 테스트용으로 제공\\n- LRS 시스템으로 전송된 모든 xAPI Statement 정보는 DB 부하시에도 데이터 유실이 발생하지 않는 안정적 Transaction 을 보장해야 함\\n❍ xAPI v1.0 및 v1.0.3 표준 지원 LRS 시스템 도입\\n- xAPI 표준을 지원하는 LRS 시스템을 구축하거나 검증된 상용 솔루션을 도입함\\n- 도입/구축되는 LRS 시스템은 ADL 의 검증된 Test Suite 를 100% 통과해야 함\\n※ ADL xAPI Test Suite(https://lrstest.adlnet.gov) 에서 Test Suite 결과서를 제출해야 함\\n- LRS 솔루션 도입 시 GS 인증 1등급 획득 및 조달청 등록 제품으로 기능 적합성, 성능효율성, 사용성 등에 대한 인증을 취득한 제품으로 제시할 것\\n- 학습 분석 데이터 표준화 진단 및 분석(단어/용어, 데이터 도메인, 코드)\\n- 대내 · 외 학습활동 데이터와 연계한 데이터, 테이블 등 데이터 연계 영역 분석\\n❍ 관리자 기능\\n- 수집되는 모든 xAPI 데이터를 실시간 확인할 수 있는 대시보드 기능 제공\\n- 동영상 Activity 의 경우, 학습자별, 영상별 영상 시청 구간에 대한 실시간 조회 히트맵 기능을 제공\\n- xAPI 의 Full Statement, Agent, Verb, Object, Context 별 목록 및 검색 기능\\n- xAPI State 정보 목록 및 검색 기능\\n❍ 데이터 시각화도구 연계 기능\\n- 최소 1종 이상의 BI 도구를 통한 데이터 시각화를 지원\\n- 다양한 데이터 시각화 차트를 학습자, 교강사, 운영자 분류에 따라 차트 유형을 선정하고, 이를 실시간 연동할 수 있도록 데이터 질의 조회 및 데이터 시각화 예시를 제공\\n- Profile Model 에 따른 데이터 시각화 기능 제공\\n산출정보\\n개발산출물\\n| 고유번호 | SFR-03 | 요구사항 분류 | 기능 요구사항 |\\n| --- | --- | --- | --- |\\n| 요구사항 명칭 | LRS조회 및 정렬 기능 구성 | 응락수준 | 필수 |\\n| 요구사항 내용 | ❍실시간 데이터 조회를 위한 실시간 인덱싱 및 분산처리 지원- 실시간 누적 데이터의 중복, 누락 없이 데이터를 수집 및 실시간 인덱싱 처리- 데이터의 유실 방지 및 자동복구를 위한 데이터 샤딩처리❍교수학습 맥락정보 기반 실시간 데이터 조회- xAPI표준 체계에 따른IRI Context를 기반으로 데이터 그룹핑 및 정렬 집계 기능- ETL및 대규모 배치작업을 사용하지 않고, 실시간xAPI데이터를 집계할 수 있는 기능을 제공- Range검색을 통한 데이터 조회 필터 기능- Integer, Float, Time Stamp기반 데이터 조회 필터 기능- Boolean Query기능을 통한 조건절 필터 기능- 데이터 정렬 기능- 100개 이상의 집계데이터가 실시간으로 집계되어 출력될 수 있도록 데이터 고속 집계 및 조회기능을 제공- 데이터 차트를 통한 데이터 시각화 방안 제시❍DSL쿼리를 실시간 조회 및 정렬할 수 있는 웹인터페이스 및 질의 결과 출력 기능- jupyter notebook과 같은 데이터 질의조회 웹 인터페이스를 제공- python, R기반 데이터 조회 코드를 실시간 실행 할 수 있는 기능- 조회된 데이터를 실시간으로 시각화 할 수 있는 기능을 제공- 데이터 집계 쿼리를 저장 및 시각화 대시보드로export할 수 있는 기능을 제공❍AI시스템과 연계하는 기능을 제공 |\\n\\n질문:\\n전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축에 연관하여, 요구사항 목록표 내용을 알려주세요.', additional_kwargs={}, response_metadata={})]\n",
            "-------------------------\n",
            "--- 랭체인 중간 결과 ---\n",
            "content='요구사항 총괄표에 따른 내용은 다음과 같습니다.\\n\\n| 구 분 | 설 명 | 개수 |\\n| --- | --- | --- |\\n| 컨설팅-CNR(Consulting Requirement) | 업무 효율성과 생산성을 높이기 위한 정보시스템 구축, 업무프로세스 개선 방안 등의 도출을 위한 요구사항 | 2 |\\n| 시스템 장비구성-ECR(Equipment CompositionRequirement) | 목표사업수행을 위해 필요한 하드웨어, 소프트웨어, 네트워크 등의 도입 장비 내역 등 시스템 장비 구성에 대한 요구사항 | 4 |\\n| 기능-SFR(System FunctionRequirement) | 목표시스템이 반드시 수행하여야 하거나 목표시스템을 이용하여 사용자가 반드시 할 수 있어야 하는 기능에 대한 기술로, 전체 시스템의 계층적 구조분석을 통해 도출된 단위업무별 기능구조와 데이터 요구사항을 포함 | 6 |\\n| 성능-PER(PerformanceRequirement) | 처리속도, 처리량, 가용성 등 시스템의 성능에 대한 요구사항 | 2 |\\n| 인터페이스-SIR(System InterfaceRequirement) | 시스템과 외부 또는 사용자 간의 인터페이스 요구사항 | 1 |\\n| 데이터-DAR(Data Requirement) | 초기자료 구축, 데이터 변환, 보안 등 데이터 관련 요구사항 | 7 |' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 288, 'prompt_tokens': 3311, 'total_tokens': 3599, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_04d3664870', 'id': 'chatcmpl-CGKzR9NB68lZiEQEajOGhx9IwzgUx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--5145d9e8-b349-41b8-98d7-f347ef425e0c-0' usage_metadata={'input_tokens': 3311, 'output_tokens': 288, 'total_tokens': 3599, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "-------------------------\n",
            "실행 시간: 15.8112초\n",
            "요구사항 총괄표에 따른 내용은 다음과 같습니다.\n",
            "\n",
            "| 구 분 | 설 명 | 개수 |\n",
            "| --- | --- | --- |\n",
            "| 컨설팅-CNR(Consulting Requirement) | 업무 효율성과 생산성을 높이기 위한 정보시스템 구축, 업무프로세스 개선 방안 등의 도출을 위한 요구사항 | 2 |\n",
            "| 시스템 장비구성-ECR(Equipment CompositionRequirement) | 목표사업수행을 위해 필요한 하드웨어, 소프트웨어, 네트워크 등의 도입 장비 내역 등 시스템 장비 구성에 대한 요구사항 | 4 |\n",
            "| 기능-SFR(System FunctionRequirement) | 목표시스템이 반드시 수행하여야 하거나 목표시스템을 이용하여 사용자가 반드시 할 수 있어야 하는 기능에 대한 기술로, 전체 시스템의 계층적 구조분석을 통해 도출된 단위업무별 기능구조와 데이터 요구사항을 포함 | 6 |\n",
            "| 성능-PER(PerformanceRequirement) | 처리속도, 처리량, 가용성 등 시스템의 성능에 대한 요구사항 | 2 |\n",
            "| 인터페이스-SIR(System InterfaceRequirement) | 시스템과 외부 또는 사용자 간의 인터페이스 요구사항 | 1 |\n",
            "| 데이터-DAR(Data Requirement) | 초기자료 구축, 데이터 변환, 보안 등 데이터 관련 요구사항 | 7 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 멀티턴 벡터스토어 생성"
      ],
      "metadata": {
        "id": "T6M5I1k7q_T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.memory import ConversationBufferMemory # Import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain # Import ConversationalRetrievalChain\n",
        "from operator import itemgetter # Import itemgetter\n",
        "\n",
        "\n",
        "def create_context(df):\n",
        "    VERSION = 'v1'\n",
        "    EMB_NAME = 'intfloat/multilingual-e5-large-instruct'\n",
        "    STORED_FOLDER = f'faiss-{VERSION}'\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = load_secret(\"GOOGLE_API_KEY\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = load_secret(\"OPENAI_API_KEY\")\n",
        "    embedding = HuggingFaceEmbeddings(model_name=EMB_NAME, multi_process=True)\n",
        "\n",
        "    def save_vectorstore(documents):\n",
        "        # 새로운 문서가 있을 경우, 기존 인덱스에 추가\n",
        "        print(f\"{len(documents)}개의 새로운 문서를 vectorstore에 추가합니다.\")\n",
        "        vectorstore.add_documents(documents=documents)\n",
        "        vectorstore.save_local(STORED_FOLDER) # 변경된 인덱스 저장\n",
        "        print(f\"업데이트된 vectorstore를 '{STORED_FOLDER}' 폴더에 저장했습니다.\")\n",
        "        return vectorstore\n",
        "\n",
        "    def create_documents(df):\n",
        "        \"\"\"\n",
        "        DataFrame의 각 행을 순회하며 LangChain Document 객체를 생성합니다.\n",
        "        '텍스트' 컬럼을 page_content로 사용하고, 나머지 컬럼을 메타데이터로 추가합니다.\n",
        "        \"\"\"\n",
        "        documents = []\n",
        "\n",
        "        # NaN 값을 빈 문자열로 대체하여 메타데이터에 문제가 없도록 처리\n",
        "        df = df.fillna('')\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "            # page_content는 '텍스트' 컬럼의 내용으로 설정\n",
        "            print(f\"이건 {index + 1}번째 문서: {row['사업명']}\")\n",
        "            metadata = {\n",
        "                '공고 번호': row['공고 번호'],\n",
        "                '사업명': row['사업명'],\n",
        "                '사업 금액': row['사업 금액'],\n",
        "                '발주 기관': row['발주 기관'],\n",
        "                '공개 일자': row['공개 일자'],\n",
        "                '입찰 참여 시작일': row['입찰 참여 시작일'],\n",
        "                '입찰 참여 마감일': row['입찰 참여 마감일'],\n",
        "                '사업 요약': row['사업 요약'],\n",
        "                '파일명': row['파일명']\n",
        "            }\n",
        "\n",
        "            # Document 객체 생성\n",
        "            docs = load_documents(row['파일명'], metadata=metadata)\n",
        "            documents.extend(docs)\n",
        "\n",
        "        return documents\n",
        "\n",
        "    def print_pipe(x):\n",
        "        print(\"--- 랭체인 중간 결과 ---\")\n",
        "        print(x)\n",
        "        print(\"-------------------------\")\n",
        "        return x\n",
        "\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    def load_llm_gemini():\n",
        "        llm = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-2.5-flash\", temperature=0.2, thinking_budget=0,  # reasoning 비활성화\n",
        "            max_output_tokens=1000,  # HuggingFacePipeline의 max_new_tokens에 해당\n",
        "        )\n",
        "        return llm\n",
        "\n",
        "    # OpenAI LLM 로드 함수 (새로 추가)\n",
        "    def load_llm_openai():\n",
        "        llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2, max_tokens=1000)\n",
        "        return llm\n",
        "\n",
        "    # 기존 create_chain 함수 (유지)\n",
        "    def create_chain(retriever, llm):\n",
        "        prompt = PromptTemplate(\n",
        "            template=(\n",
        "                \"다음 문맥만을 근거로 질문에 답변하세요.\\n\"\n",
        "                \"- 반드시 한국어로 답변하세요.\\n\"\n",
        "                \"- 문맥에 없는 내용은 '모르겠습니다'라고 답하세요.\\n\"\n",
        "                \"- 금액/기한/요건은 원문과 일치하게 유지하세요.\\n\\n\"\n",
        "                \"문맥:\\n{context}\\n\\n\"\n",
        "                \"질문:\\n{question}\\n\\n\"\n",
        "                \"답변:\"\n",
        "            ),\n",
        "            input_variables=[\"context\", \"question\"]\n",
        "        )\n",
        "        chain = (\n",
        "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "            | prompt | llm | StrOutputParser()\n",
        "        )\n",
        "        return chain\n",
        "\n",
        "    # 기존 create_chat_chain 함수 (수정: memory 파라미터를 optional로 변경)\n",
        "    def create_chat_chain(memory=None): # Accept memory as an optional argument\n",
        "        if memory is None:\n",
        "            # 대화 기록을 위한 새로운 메모리 생성\n",
        "            memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "        # Conversational Retrieval Chain 생성\n",
        "        chain = ConversationalRetrievalChain.from_llm(\n",
        "            llm=llm, # Use llm from outer scope\n",
        "            retriever=retriever, # Use retriever from outer scope\n",
        "            memory=memory, # Use the provided or newly created memory\n",
        "            # combine_docs_chain_kwargs={\"prompt\": your_custom_prompt} # 필요에 따라 커스텀 프rompt 사용\n",
        "        )\n",
        "        return chain\n",
        "\n",
        "    # 새로운 runnable 형태의 대화형 체인 생성 함수 (유지)\n",
        "    def create_runnable_chat_chain(retriever, llm):\n",
        "        # 대화 기록을 위한 메모리 설정\n",
        "        memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "        # 사용자의 현재 질문과 대화 기록을 기반으로 검색할 쿼리를 생성하는 프롬프트\n",
        "        question_generator_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"주어진 대화 기록과 새로운 질문을 바탕으로 검색에 사용할 질문을 생성하세요.\"),\n",
        "            (\"human\", \"대화 기록:\\n{chat_history}\\n\\n새로운 질문: {question}\\n\\n검색 질문:\")\n",
        "        ])\n",
        "\n",
        "        # 검색된 문서와 사용자의 현재 질문을 바탕으로 답변을 생성하는 프롬프트\n",
        "        answer_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\",\n",
        "             \"다음 문맥만을 근거로 질문에 답변하세요.\\n\"\n",
        "             \"- 반드시 한국어로 답변하세요.\\n\"\n",
        "             \"- 문맥에 없는 내용은 '모르겠습니다'라고 답하세요.\\n\"\n",
        "             \"- 금액/기한/요건은 원문과 일치하게 유지하세요.\"\n",
        "            ),\n",
        "            (\"human\", \"문맥:\\n{context}\\n\\n질문:\\n{question}\")\n",
        "        ])\n",
        "\n",
        "        # 검색 질문 생성 체인\n",
        "        question_generator_chain = question_generator_prompt | llm | StrOutputParser()\n",
        "\n",
        "        # 답변 생성 체인\n",
        "        document_chain = (\n",
        "            {\"context\": itemgetter(\"context\"), \"question\": itemgetter(\"question\")}\n",
        "            | answer_prompt | llm | StrOutputParser()\n",
        "        )\n",
        "\n",
        "        # 최종 대화형 검색 체인\n",
        "        # 입력: {\"question\": \"...\", \"chat_history\": [...]}\n",
        "        chain = (\n",
        "            RunnablePassthrough.assign(\n",
        "                chat_history=RunnableLambda(lambda x: memory.load_memory_variables({})[\"chat_history\"])\n",
        "            ) |\n",
        "            {\n",
        "                \"context\": itemgetter(\"question\") | question_generator_chain | retriever,\n",
        "                \"question\": itemgetter(\"question\")\n",
        "            } |\n",
        "            document_chain\n",
        "        )\n",
        "\n",
        "        # 메모리에 대화 기록을 저장하는 함수 (체인 실행 후 호출)\n",
        "        def save_chat_history(inputs, outputs):\n",
        "            memory.save_context(inputs, {\"output\": outputs})\n",
        "            return outputs\n",
        "\n",
        "        # 체인 실행 함수와 메모리 저장 함수를 함께 반환\n",
        "        return chain, save_chat_history\n",
        "\n",
        "    # 1. 기존 FAISS 인덱스 로드 또는 새로 생성\n",
        "    if os.path.exists(STORED_FOLDER):\n",
        "        vectorstore = FAISS.load_local(STORED_FOLDER, embedding, allow_dangerous_deserialization=True)\n",
        "        print(f\"'{STORED_FOLDER}' 폴더에서 vectorstore를 로드했습니다.\")\n",
        "    else:\n",
        "        # 인덱스가 없을 경우, 더미 문서를 사용해 인덱스 초기 생성\n",
        "        dummy_docs = [Document(page_content=\"초기 생성을 위한 더미 문서입니다.\")]\n",
        "        vectorstore = FAISS.from_documents(documents=dummy_docs, embedding=embedding)\n",
        "        print(f\"새로운 vectorstore를 더미 문서로 생성했습니다.\")\n",
        "        documents = create_documents(df)\n",
        "        save_vectorstore(documents)\n",
        "\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    llm = load_llm_openai() # load_llm_gemini()\n",
        "\n",
        "    # Return save_vectorstore and create_chat_chain functions\n",
        "    # create_chat_chain now accepts an optional memory parameter\n",
        "    return save_vectorstore, create_chat_chain\n",
        "\n",
        "\n",
        "df = load_csv('data_list.csv')\n",
        "# Call create_context to get the necessary functions\n",
        "save_vectorstore, create_chat_chain = create_context(df)\n",
        "\n",
        "# Now you can create chat chains with separate memories as needed\n",
        "# Example 1: Start a new conversation (memory is created internally)\n",
        "# conversation1_chain = create_chat_chain()\n",
        "\n",
        "# Example 2: Start another new conversation\n",
        "# conversation2_chain = create_chat_chain()\n",
        "\n",
        "# Example 3: Continue an existing conversation with a specific memory (advanced use case)\n",
        "# existing_memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "# existing_conversation_chain = create_chat_chain(memory=existing_memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDaamEOGoere",
        "outputId": "28d0aea9-7c9c-4ee8-bc7d-c539f0bdb575"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] data_list.csv 로드 완료.\n",
            "'faiss-v1' 폴더에서 vectorstore를 로드했습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_chain = create_chat_chain()"
      ],
      "metadata": {
        "id": "kfY1Ed6k0j5d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 대화 시작 예시\n",
        "user_question = \"전북대학교 JST 공유대학(원) 사업에 대해 설명해 주세요.\"\n",
        "response = chat_chain.invoke({\"question\": user_question})\n",
        "\n",
        "print(\"Assistant:\", response['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whwFs1OD0py1",
        "outputId": "926a5caf-4b0b-40c5-87e7-70669d939f3f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: 전북대학교 JST 공유대학(원) 사업은 xAPI 기반의 LRS(학습 기록 저장소) 시스템 구축을 목표로 하고 있습니다. 이 사업은 전북지역혁신플랫폼 대학교육혁신본부가 주관하며, 학습 데이터의 통합 관리와 개인 맞춤형 학습 환경 구축을 목적으로 합니다. 이를 통해 학습자의 다양한 학습 데이터를 수집 및 분석하여 맞춤형 학습 경로를 제공하고, 데이터 기반의 의사결정을 지원하는 체계를 구축하려고 합니다. 사업 기간은 계약 체결일로부터 75일이며, 예산은 116,000,000원입니다. 이 시스템은 ADL의 xAPI 표준 체계를 지원하며, 학습자의 학습 활동 데이터를 실시간으로 저장 및 관리할 수 있는 기능을 갖추게 됩니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 대화를 이어서 질문하는 예시\n",
        "user_follow_up_question = \"그 사업의 예산은 얼마인가요?\"\n",
        "response = chat_chain.invoke({\"question\": user_follow_up_question})\n",
        "\n",
        "print(\"Assistant:\", response['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxYXqjve0pvA",
        "outputId": "7e79d696-134f-4567-e149-95b5d11842f1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: 전북대학교 JST 공유대학(원) xAPI 기반 LRS 시스템 구축 사업의 예산은 116,000,000원(금일억일천육백만원, 부가세 포함)입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 추가 질문 예시\n",
        "user_additional_question = \"그 사업 기간은 어떻게 되나요?\"\n",
        "response = chat_chain.invoke({\"question\": user_additional_question})\n",
        "\n",
        "print(\"Assistant:\", response['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXZoqDa-0plb",
        "outputId": "709ed72d-cb46-463c-c7b0-eb1ec6df3036"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: 전북대학교 JST 공유대학(원) xAPI 기반 LRS 시스템 구축 사업의 기간은 계약 체결일로부터 75일까지입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 작업파일 저장하기"
      ],
      "metadata": {
        "id": "NGWDEOMKqw_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def zip_folder(source_folder, output_filename):\n",
        "    \"\"\"\n",
        "    지정된 폴더를 ZIP 파일로 압축합니다.\n",
        "\n",
        "    Args:\n",
        "        source_folder (str): 압축할 원본 폴더 경로.\n",
        "        output_filename (str): 생성될 ZIP 파일의 이름 (확장자 제외).\n",
        "    \"\"\"\n",
        "    # 압축 파일을 저장할 경로와 이름 지정\n",
        "    # 예: 'archive_folder' 폴더를 압축하여 'archive.zip' 파일 생성\n",
        "    # make_archive()는 확장자를 자동으로 추가합니다.\n",
        "    shutil.make_archive(output_filename, 'zip', source_folder)\n",
        "    print(f\"'{source_folder}' 폴더가 '{output_filename}.zip'으로 압축되었습니다.\")\n",
        "\n",
        "# 사용 예시\n",
        "source_dir = 'temp_hwp_html'  # 압축할 폴더 이름\n",
        "output_name = 'hwp_html_archive'  # 생성될 ZIP 파일의 이름 (archive.zip)\n",
        "\n",
        "# 만약 temp_hwp_html 폴더가 존재한다면\n",
        "if os.path.exists(source_dir):\n",
        "    zip_folder(source_dir, output_name)\n",
        "else:\n",
        "    print(f\"'{source_dir}' 폴더가 존재하지 않습니다.\")\n",
        "\n",
        "\n",
        "# 사용 예시\n",
        "source_dir = 'outputs'  # 압축할 폴더 이름\n",
        "output_name = 'outputs_archive'  # 생성될 ZIP 파일의 이름 (archive.zip)\n",
        "\n",
        "# 만약 temp_hwp_html 폴더가 존재한다면\n",
        "if os.path.exists(source_dir):\n",
        "    zip_folder(source_dir, output_name)\n",
        "else:\n",
        "    print(f\"'{source_dir}' 폴더가 존재하지 않습니다.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T06:47:51.074372Z",
          "iopub.execute_input": "2025-09-16T06:47:51.074629Z",
          "iopub.status.idle": "2025-09-16T06:47:53.594975Z",
          "shell.execute_reply.started": "2025-09-16T06:47:51.074613Z",
          "shell.execute_reply": "2025-09-16T06:47:53.594217Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvzAKNl6Wv3Z",
        "outputId": "238e69fd-07fa-418b-de39-331dd84daff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'temp_hwp_html' 폴더가 존재하지 않습니다.\n",
            "'outputs' 폴더가 'outputs_archive.zip'으로 압축되었습니다.\n"
          ]
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": [
        "## llama index 사용하기"
      ],
      "metadata": {
        "id": "fkymIlUmWv3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from llama_index.core import VectorStoreIndex, Document, StorageContext\n",
        "from llama_index.vector_stores.faiss import FaissVectorStore\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.prompts.prompts import PromptTemplate\n",
        "import faiss\n",
        "\n",
        "# 전역 설정\n",
        "VERSION = 'v1'\n",
        "EMB_NAME_HF = 'intfloat/multilingual-e5-large-instruct'\n",
        "EMB_NAME_OAI = 'text-embedding-3-large'\n",
        "STORED_FOLDER = f'faiss-{VERSION}'\n",
        "\n",
        "# LangChain의 Document 객체를 LlamaIndex의 Document 객체로 변환하는 함수\n",
        "def convert_lc_to_llamaindex_docs(lc_documents):\n",
        "    llama_documents = []\n",
        "    for doc in lc_documents:\n",
        "        llama_doc = Document(text=doc.page_content, metadata=doc.metadata)\n",
        "        llama_documents.append(llama_doc)\n",
        "    return llama_documents\n",
        "\n",
        "def create_context_llamaindex(df):\n",
        "\n",
        "    # API 키 로드\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = load_secret(\"GOOGLE_API_KEY\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = load_secret(\"OPENAI_API_KEY\")\n",
        "\n",
        "    # 임베딩 모델 준비 (HuggingFace와 OpenAI)\n",
        "    embedding_hf = HuggingFaceEmbedding(model_name=EMB_NAME_HF, multi_process=True)\n",
        "    embedding_oai = OpenAIEmbedding(model=EMB_NAME_OAI)\n",
        "\n",
        "    def create_documents(df):\n",
        "        documents = []\n",
        "        df = df.fillna('')\n",
        "        for index, row in df.iterrows():\n",
        "            print(f\"이건 {index + 1}번째 문서: {row['사업명']}\")\n",
        "            metadata = {\n",
        "                '공고 번호': row['공고 번호'],\n",
        "                '사업명': row['사업명'],\n",
        "                '사업 금액': row['사업 금액'],\n",
        "                '발주 기관': row['발주 기관'],\n",
        "                '공개 일자': row['공개 일자'],\n",
        "                '입찰 참여 시작일': row['입찰 참여 시작일'],\n",
        "                '입찰 참여 마감일': row['입찰 참여 마감일'],\n",
        "                '사업 요약': row['사업 요약'],\n",
        "                '파일명': row['파일명']\n",
        "            }\n",
        "            # 이 함수는 LangChain Document를 반환한다고 가정\n",
        "            lc_docs = load_documents(row['파일명'], metadata=metadata)\n",
        "            llama_docs = convert_lc_to_llamaindex_docs(lc_docs)\n",
        "            documents.extend(llama_docs)\n",
        "        return documents\n",
        "\n",
        "    # 1. FAISS 인덱스 로드 또는 생성\n",
        "    if os.path.exists(STORED_FOLDER):\n",
        "        faiss_index = faiss.read_index(f\"{STORED_FOLDER}/faiss_index.bin\")\n",
        "        faiss_vector_store = FaissVectorStore.from_faiss_index(faiss_index)\n",
        "        storage_context = StorageContext.from_defaults(vector_store=faiss_vector_store)\n",
        "        index = VectorStoreIndex.from_documents(documents=[], storage_context=storage_context, service_context=embedding_hf)\n",
        "        print(f\"'{STORED_FOLDER}' 폴더에서 vectorstore를 로드했습니다.\")\n",
        "    else:\n",
        "        faiss_index = faiss.IndexFlatL2(embedding_hf.get_query_embedding_length())\n",
        "        faiss_vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
        "        storage_context = StorageContext.from_defaults(vector_store=faiss_vector_store)\n",
        "        index = VectorStoreIndex.from_documents(documents=[], storage_context=storage_context, service_context=embedding_hf)\n",
        "        print(f\"새로운 vectorstore를 생성했습니다.\")\n",
        "\n",
        "    # 2. 문서 생성 및 인덱스 업데이트\n",
        "    documents = create_documents(df)\n",
        "    index.insert_nodes(documents)\n",
        "\n",
        "    # 3. LLM 설정 및 쿼리 엔진 생성\n",
        "    llm_gemini = Gemini(temperature=0.2, model=\"gemini-2.5-flash\")\n",
        "    llm_openai = OpenAI(temperature=0.2, model=\"gpt-4o\")\n",
        "\n",
        "    def create_query_engine(llm, embedding_model):\n",
        "        index.service_context.embed_model = embedding_model\n",
        "        query_engine = index.as_query_engine(llm=llm, response_mode=\"compact\")\n",
        "        return query_engine\n",
        "\n",
        "    query_engine_gemini = create_query_engine(llm_gemini, embedding_hf)\n",
        "    query_engine_openai = create_query_engine(llm_openai, embedding_oai)\n",
        "\n",
        "    return query_engine_gemini, query_engine_openai\n",
        "\n",
        "# 사용 예시\n",
        "df = load_csv('data_list.csv')\n",
        "query_engine_gemini, query_engine_openai = create_context_llamaindex(df)\n",
        "\n",
        "# 질문\n",
        "response_gemini = query_engine_gemini.query(\"질문\")\n",
        "response_openai = query_engine_openai.query(\"질문\")\n",
        "\n",
        "print(\"Gemini 응답:\", response_gemini)\n",
        "print(\"OpenAI 응답:\", response_openai)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5MBLMP_dWv3a",
        "outputId": "0a425588-7784-4e92-93ea-973d1c199af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] data_list.csv 로드 완료.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SentenceTransformer.__init__() got an unexpected keyword argument 'multi_process'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-824625267.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# 사용 예시\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_list.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mquery_engine_gemini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_engine_openai\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_context_llamaindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# 질문\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-824625267.py\u001b[0m in \u001b[0;36mcreate_context_llamaindex\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# 임베딩 모델 준비 (HuggingFace와 OpenAI)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0membedding_hf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMB_NAME_HF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0membedding_oai\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMB_NAME_OAI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/llama_index/embeddings/huggingface/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, tokenizer_name, pooling, max_length, query_instruction, text_instruction, normalize, model, tokenizer, embed_batch_size, cache_folder, trust_remote_code, device, callback_manager, parallel_process, target_devices, show_progress_bar, **model_kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `model_name` argument must be provided.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         model = SentenceTransformer(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SentenceTransformer.__init__() got an unexpected keyword argument 'multi_process'"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 청킹작업시도 (Develop 필요)"
      ],
      "metadata": {
        "id": "wVxOxivRIaEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from typing import List, Dict, Set\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_pymupdf(filename: str, chunk_size: int = 1000, chunk_overlap: int = 150, top_percentile: float = 15.0, min_important_text_length: int = 20, min_chunk_length_to_merge: int = 50) -> List[Document]:\n",
        "    \"\"\"\n",
        "    폰트 크기, 최소 글자 수 필터링 및 문맥 기반 병합을 결합하여\n",
        "    순서를 보장하며 PDF 문서를 청킹합니다.\n",
        "\n",
        "    Args:\n",
        "        filename (str): 처리할 PDF 파일의 이름.\n",
        "        chunk_size (int): RecursiveCharacterTextSplitter의 청크 크기.\n",
        "        chunk_overlap (int): RecursiveCharacterTextSplitter의 청크 오버랩.\n",
        "        top_percentile (float): 상위 폰트 크기를 결정하는 퍼센타일 값 (예: 15.0).\n",
        "        min_important_text_length (int): 중요 텍스트로 간주될 최소 길이.\n",
        "        min_chunk_length_to_merge (int): 병합 대상이 될 최소 청크 길이.\n",
        "\n",
        "    Returns:\n",
        "        List[Document]: 청킹된 문서 리스트.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(f'{PDF_PATH}/{filename}')\n",
        "\n",
        "    # 1단계: 폰트 크기 분포 및 반복 텍스트 분석 (이전과 동일)\n",
        "    all_font_sizes = []\n",
        "    first_page_spans: Dict[str, bool] = {}\n",
        "    last_page_spans: Dict[str, bool] = {}\n",
        "\n",
        "    for page_num, page in enumerate(doc):\n",
        "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
        "        for block in blocks:\n",
        "            if block['type'] == 0:\n",
        "                for line in block['lines']:\n",
        "                    for span in line['spans']:\n",
        "                        text = span['text'].strip()\n",
        "                        if not text:\n",
        "                            continue\n",
        "                        all_font_sizes.append(round(span['size'], 2))\n",
        "\n",
        "                        if page_num == 0:\n",
        "                            first_page_spans[text] = True\n",
        "                        if page_num == len(doc) - 1:\n",
        "                            last_page_spans[text] = True\n",
        "\n",
        "    if not all_font_sizes:\n",
        "        doc.close()\n",
        "        return []\n",
        "\n",
        "    font_size_threshold = np.percentile(all_font_sizes, 100 - top_percentile)\n",
        "    common_texts: Set[str] = set(first_page_spans.keys()) & set(last_page_spans.keys())\n",
        "\n",
        "    # 2단계: 문서 순회하며 텍스트 덩어리 생성 및 병합 (순서 보장)\n",
        "    combined_texts = []\n",
        "    current_text = \"\"\n",
        "    is_current_important = False\n",
        "\n",
        "    for page in doc:\n",
        "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
        "        for block in blocks:\n",
        "            if block['type'] == 0:\n",
        "                for line in block['lines']:\n",
        "                    for span in line['spans']:\n",
        "                        text = span['text'].strip()\n",
        "                        if not text:\n",
        "                            continue\n",
        "\n",
        "                        # 반복 문구 필터링\n",
        "                        if text in common_texts:\n",
        "                            continue\n",
        "\n",
        "                        font_size = round(span['size'], 2)\n",
        "                        is_important = font_size >= font_size_threshold\n",
        "\n",
        "                        if not is_important and len(text) < 10:\n",
        "                            continue\n",
        "\n",
        "                        # 텍스트 유형이 바뀌는 지점을 청크 경계로 활용\n",
        "                        # 단, 새로 시작하는 텍스트 덩어리가 짧으면 이전 덩어리에 병합\n",
        "                        if current_text and is_important != is_current_important:\n",
        "                            # 새로 시작하는 중요 텍스트가 짧으면 이전 덩어리에 병합\n",
        "                            if is_important and len(text) < min_important_text_length:\n",
        "                                current_text += \" \" + text\n",
        "                                continue\n",
        "                            # 이전 덩어리가 너무 짧으면 새로 분리하지 않고 계속 병합\n",
        "                            elif len(current_text) < min_chunk_length_to_merge:\n",
        "                                current_text += \" \" + text\n",
        "                                is_current_important = is_important\n",
        "                                continue\n",
        "                            else:\n",
        "                                combined_texts.append(current_text)\n",
        "                                current_text = \"\"\n",
        "\n",
        "                        current_text += text + \" \"\n",
        "                        is_current_important = is_important\n",
        "\n",
        "    if current_text:\n",
        "        combined_texts.append(current_text)\n",
        "\n",
        "    doc.close()\n",
        "    print('큰 청킹 수: ', len(combined_texts))\n",
        "    # 3단계: 순차적 청킹 적용 및 메타데이터 추가 (이전과 동일)\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "    processed_docs = []\n",
        "    for text in combined_texts:\n",
        "        cleaned_text = \" \".join(text.split())\n",
        "        chunks = text_splitter.create_documents([cleaned_text])\n",
        "        for chunk in chunks:\n",
        "            chunk.metadata = {\"source\": filename}\n",
        "            processed_docs.append(chunk)\n",
        "\n",
        "    return processed_docs"
      ],
      "metadata": {
        "id": "c_bq4m1wIcoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 멀티턴 테스트 (문제 있음)"
      ],
      "metadata": {
        "id": "Op3YRWWDGS1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from operator import itemgetter\n",
        "from typing import Dict, Any\n",
        "from langchain_core.runnables import ConfigurableFieldSpec\n",
        "from datetime import datetime, timedelta\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, Runnable\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.chat_message_histories import FileChatMessageHistory\n",
        "# from langchain.schema.runnable.with_resources import RunnableWithMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "from config import Config\n",
        "\n",
        "class ChatBot:\n",
        "    def __init__(self, retriever: Any, llm: Any):\n",
        "        self.retriever = retriever\n",
        "        self.llm = llm\n",
        "        self.history_dir = Config.HISTORY_DIR\n",
        "        self.chain = self._create_chain()\n",
        "\n",
        "        # 스케줄러를 사용하여 오래된 파일 자동 삭제\n",
        "        # BackgroundScheduler 등을 사용하면 더 안정적이나, 여기서는 간단한 예시로\n",
        "        os.makedirs(self.history_dir, exist_ok=True)\n",
        "        # 매번 인스턴스 생성 시 파일을 정리하도록 구현\n",
        "        self._clean_old_history_files()\n",
        "\n",
        "    def _get_session_history(self, session_id: str) -> FileChatMessageHistory:\n",
        "        \"\"\"\n",
        "        세션 ID에 해당하는 FileChatMessageHistory 객체를 반환합니다.\n",
        "        \"\"\"\n",
        "        file_path = os.path.join(self.history_dir, f\"{session_id}.json\")\n",
        "        return FileChatMessageHistory(file_path=file_path)\n",
        "\n",
        "    def _create_chain(self) -> RunnableWithMessageHistory:\n",
        "        \"\"\"\n",
        "        자동으로 대화 기록을 관리하는 챗봇 체인을 생성합니다.\n",
        "        \"\"\"\n",
        "        question_generator_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"주어진 대화 기록과 새로운 질문을 바탕으로 검색에 사용할 질문을 생성하세요.\"),\n",
        "            (\"human\", \"대화 기록:\\n{chat_history}\\n\\n새로운 질문: {question}\\n\\n검색 질문:\")\n",
        "        ])\n",
        "\n",
        "        answer_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\",\n",
        "             \"다음 문맥만을 근거로 질문에 답변하세요.\\n\"\n",
        "             \"- 반드시 한국어로 답변하세요.\\n\"\n",
        "             \"- 문맥에 없는 내용은 '모르겠습니다'라고 답하세요.\\n\"\n",
        "             \"- 금액/기한/요건은 원문과 일치하게 유지하세요.\"\n",
        "            ),\n",
        "            (\"human\", \"문맥:\\n{context}\\n\\n질문:\\n{question}\")\n",
        "        ])\n",
        "\n",
        "        question_generator_chain = question_generator_prompt | self.llm | StrOutputParser()\n",
        "\n",
        "        document_chain = (\n",
        "            {\"context\": itemgetter(\"context\"), \"question\": itemgetter(\"question\")}\n",
        "            | answer_prompt | self.llm | StrOutputParser()\n",
        "        )\n",
        "\n",
        "        chain_without_history = (\n",
        "            RunnablePassthrough.assign(\n",
        "                # question_generator_chain은 chat_history와 question을 모두 받음\n",
        "                query=question_generator_chain\n",
        "            ) |\n",
        "            {\n",
        "                \"context\": itemgetter(\"query\") | self.retriever,\n",
        "                \"question\": itemgetter(\"question\")\n",
        "            } |\n",
        "            document_chain\n",
        "        )\n",
        "\n",
        "        chain_with_history = RunnableWithMessageHistory(\n",
        "            chain_without_history,\n",
        "            self._get_session_history,\n",
        "            input_messages_key=\"question\",\n",
        "            history_messages_key=\"chat_history\"\n",
        "        )\n",
        "\n",
        "        return chain_with_history\n",
        "\n",
        "    def _clean_old_history_files(self, days_to_keep: int = 10):\n",
        "        \"\"\"\n",
        "        10일보다 오래된 채팅 기록 파일을 삭제합니다.\n",
        "        \"\"\"\n",
        "        now = time.time()\n",
        "        for filename in os.listdir(self.history_dir):\n",
        "            file_path = os.path.join(self.history_dir, filename)\n",
        "            if os.path.isfile(file_path):\n",
        "                file_mtime = os.path.getmtime(file_path)\n",
        "                if file_mtime < now - (days_to_keep * 24 * 60 * 60):\n",
        "                    print(f\"Deleting old file: {file_path}\")\n",
        "                    os.remove(file_path)\n",
        "\n",
        "    def ask(self, chat_id: str, question: str) -> str:\n",
        "        \"\"\"\n",
        "        특정 채팅 세션 ID에 질문하고 답변을 받습니다.\n",
        "        \"\"\"\n",
        "        config = {\"configurable\": {\"session_id\": chat_id}}\n",
        "        inputs = {\"question\": question}\n",
        "        outputs = self.chain.invoke(inputs, config=config)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "eiemKGAcGT_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.2, max_tokens=1000)\n",
        "    embeddings = OpenAIEmbeddings(model=Config.EMBEDDING_MODEL,openai_api_key=Config.OPENAI_API_KEY)\n",
        "    vectorstore = FAISS.load_local(Config.VECTOR_DB_PATH, embeddings, allow_dangerous_deserialization=True)\n",
        "    chatbot = ChatBot(llm, vectorstore.as_retriever())\n",
        "\n",
        "    id = args.id if args.id is not None else str(uuid.uuid4())\n",
        "    print('현재 chat id: ', id)\n",
        "    response = chatbot.ask(id, args.query)\n",
        "    print(\"\\n[최종 답변]\")\n",
        "    print(f\"\\n{response}\")"
      ],
      "metadata": {
        "id": "KiR7EotVGZa9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}